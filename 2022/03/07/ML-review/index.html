<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="manifest" href="/images/manifest.json">
  <meta name="msapplication-config" content="/images/browserconfig.xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"despairl.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Chap1  机器学习主要研究的就是从计算机的数据当中产生模型的算法,亦即学习算法。这是一个归纳的过程，不同于基于基本事实推导出结论的演绎过程。也可以将该学习过程看成是一个在假设空间中进行搜索与训练集fit的假设的过程,换句话说，对于每一个特征，学习过程都是假设一个值，组合特征维度形成一个特征向量&#x2F;评判标准，看是否与训练集fit。 对于不同的学习任务，我们一般将预测对象按照值是否离散，区分分">
<meta property="og:type" content="article">
<meta property="og:title" content="chap.1&#x2F;2 ML基础概念 review">
<meta property="og:url" content="https://despairl.github.io/2022/03/07/ML-review/index.html">
<meta property="og:site_name" content="YQBlog | HaveFun!">
<meta property="og:description" content="Chap1  机器学习主要研究的就是从计算机的数据当中产生模型的算法,亦即学习算法。这是一个归纳的过程，不同于基于基本事实推导出结论的演绎过程。也可以将该学习过程看成是一个在假设空间中进行搜索与训练集fit的假设的过程,换句话说，对于每一个特征，学习过程都是假设一个值，组合特征维度形成一个特征向量&#x2F;评判标准，看是否与训练集fit。 对于不同的学习任务，我们一般将预测对象按照值是否离散，区分分">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-03-07T02:57:05.371Z">
<meta property="article:modified_time" content="2022-03-22T08:08:48.356Z">
<meta property="article:author" content="Yanquan Chen">
<meta property="article:tag" content="Note">
<meta property="article:tag" content="AML">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://despairl.github.io/2022/03/07/ML-review/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>chap.1/2 ML基础概念 review | YQBlog | HaveFun!</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">YQBlog | HaveFun!</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://despairl.github.io/2022/03/07/ML-review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Yanquan Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="YQBlog | HaveFun!">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          chap.1/2 ML基础概念 review
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-03-07 10:57:05" itemprop="dateCreated datePublished" datetime="2022-03-07T10:57:05+08:00">2022-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-03-22 16:08:48" itemprop="dateModified" datetime="2022-03-22T16:08:48+08:00">2022-03-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML-Note/" itemprop="url" rel="index"><span itemprop="name">ML Note</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="chap1">Chap1</h3>
<ul>
<li>机器学习主要研究的就是从计算机的<strong>数据</strong>当中<strong>产生模型的算法</strong>,亦即<strong>学习算法</strong>。这是一个<strong>归纳</strong>的过程，不同于<strong>基于基本事实推导出结论的演绎</strong>过程。也可以将该学习过程看成是一个<strong>在假设空间中进行搜索</strong>与<strong>训练集fit</strong>的假设的过程,换句话说，对于<strong>每一个特征</strong>，学习过程都是<strong>假设一个值</strong>，组合特征维度形成一个<strong>特征向量</strong>/<strong>评判标准</strong>，看<strong>是否与训练集fit</strong>。</li>
<li>对于不同的学习任务，我们一般将预测对象按照值是否离散，区分<strong>分类(离散值)</strong>、<strong>回归(连续值)</strong>,它们同属于监督学习。</li>
<li>无监督、半监督、监督学习、测试、聚类(无监督)概念不赘述。</li>
<li>归纳偏好(Inductive Bias):指的是<strong>机器学习的算法或者模型</strong>在学习过程中<strong>对于某种类型假设的偏好</strong>。<strong>如果一个机器学习算法没有归纳偏好，那它就没法告诉我们什么是确定有效的</strong>。如果是随机产生，那么，每次训练预测得到的结果都不一样，这显然不是我们想看到的。</li>
<li><strong>Occam剃刀</strong>:如果有多个假设的结果一致，就选最简单的那一个</li>
<li><strong>天下没有免费的午餐(NFL)</strong>:所有学习算法的期望都是一样的。</li>
</ul>
<h3 id="chap2">Chap2</h3>
<ul>
<li><strong>过拟合</strong>:模型的复杂程度超过了数据的复杂程度
<ul>
<li>想要解决比解决欠拟合要复杂地多。</li>
</ul></li>
<li><strong>欠拟合</strong>:模型的复杂程度未超过了数据的复杂程度
<ul>
<li>克服? : 增加训练轮数即可。</li>
</ul></li>
<li>测试集的划分:
<ul>
<li><strong>hold-out 留出法</strong> : <strong>直接将数据集划分为训练集与测试集</strong>。比例把控不当会导致测试或者训练效果不佳。</li>
<li><strong>k-fold Cross Validation 交叉验证法</strong> :将数据集对等地<strong>划分为n折</strong>。 取其中<strong>一折作为测试集</strong>，其余的作为训练集。</li>
<li><strong>Bootstrap Sampling 自助法</strong>: 为了解决<strong>划分测试集导致的训练集复杂度降低</strong>的问题。该方法是<strong>在m个样本的数据集中随机有放回地采样m次</strong>构成新数据集<span class="math inline">\(D^\prime\)</span> 作为训练集，将<span class="math inline">\(D/D^\prime\)</span>作为测试集。在数学上可以证明，大概有36.8%的数据被划入了测试集。</li>
<li>总结: 一般来说，Bootstrap Sampling用于<strong>集成学习或者数据量较小</strong>的情况，另外两种可用于<strong>数据量较大</strong>的情况。</li>
</ul></li>
<li>错误率、精度、查准、查全、PR曲线、平衡点(BER)、F1度量</li>
<li>偏差-方差分解(<strong>bias-varience decompose</strong>):
<ul>
<li>定义泛化误差为<span class="math inline">\(E = bias^2(x) + var(x) + noise^2\)</span></li>
<li><span class="math inline">\(bias(x)\)</span> 描述期望预测与实际结果之间的矛盾，即<strong>模型本身的学习能力</strong></li>
<li><span class="math inline">\(var(x)\)</span> 描述<strong>数据扰动带来的影响</strong></li>
<li><span class="math inline">\(noise^2\)</span> 描述了学习问题泛化误差的下界，表示<strong>问题自身的复杂度</strong></li>
<li>偏差与方差存在冲突，训练前期，<strong>学习能力较差，不足以学习数据的扰动</strong>，就会<strong>由偏差主导泛化误差</strong>；训练后期，<strong>模型能够学习数据中的扰动</strong>，就会由<strong>方差主导泛化误差</strong>；当学习能力强到一定程度，<strong>极小的数据扰动带来的局部性质都被模型学习到了</strong>，就会出现<strong>过拟合</strong>。</li>
</ul></li>
</ul>
<h3 id="chap3">Chap3</h3>
<ul>
<li>线性模型:
<ul>
<li>尝试学习一个<strong>线性组合函数</strong>作为预测函数。</li>
<li>具有<strong>良好的可解释性</strong>，通过权重矩阵<span class="math inline">\(w\)</span>,可以直观地看出哪个属性更为重要。</li>
<li>通过引入<strong>层级结构或者高维结构</strong>就可以完成非线性。</li>
</ul></li>
<li>线性回归 ： 尝试学习一个线性组合函数作为预测函数, 预测标签。
<ul>
<li>采用<strong>最小二乘法（MSE最小化）</strong>的优化方法。</li>
</ul></li>
<li><strong>对数线性</strong>回归：将线性回归预测的<span class="math inline">\(y-&gt;\ln y\)</span></li>
<li><strong>对数几率</strong>回归：用Sigmoid进行预测，实际上是<strong>分类模型</strong>。
<ul>
<li><strong>Sigmoid任意阶可导</strong>，可以<strong>获得近似概率分布</strong>，<strong>有利于求最优解</strong>与<strong>辅助决策</strong>。</li>
<li><strong>不需要直接对数据分布做出假设</strong>，线性回归就会假设数据分布满足线性，但是对数几率回归<strong>对于分类的可能建模</strong>，<strong>数据不敏感</strong>。</li>
<li>用<strong>极大似然法</strong>进行优化处理,<strong>梯度下降</strong>求最优解。</li>
</ul></li>
<li>线性判别分析(LDA):
<ul>
<li><strong>同类</strong>尽可能接近（<strong>协方差小</strong>），<strong>异类</strong>尽可能远离（<strong>距离大</strong>）。</li>
</ul></li>
<li>多分类：
<ul>
<li><strong>将若干个类作为正例，若干个作为反例</strong>。</li>
<li>常见分类策略: <span class="math inline">\(OvO,OvR,MvM\)</span></li>
</ul></li>
<li>类别不平衡:
<ul>
<li>欠采样（<strong>反例</strong>）、过采样（<strong>正例</strong>）、阈值移动（在决策阶段使用<strong>等式转换</strong>目标）
<ul>
<li>通过转换判断<span class="math inline">\(\frac{y}{1-y} &gt; \frac{m^+}{m^-}\)</span>,来判断时候预测为正例。</li>
</ul></li>
<li>改变loss函数</li>
</ul></li>
</ul>
<h3 id="chap4">Chap4</h3>
<ul>
<li>决策树：
<ul>
<li>缓解过拟合:
<ul>
<li>剪枝：预剪枝（<strong>展开子树</strong>是否会带来泛化性能的提升来决定）、后剪枝(先训练出一棵完整的树再考虑)。
<ul>
<li>预剪枝：<strong>时间开销少、容易欠拟合</strong></li>
<li>后剪枝：<strong>时间开销大、不容易欠拟合</strong></li>
</ul></li>
</ul></li>
<li>决策树要实现斜向划分是通过<strong>分段近似</strong>(对每一个区间段<strong>拟合一个线性函数</strong>)实现的。</li>
</ul></li>
</ul>
<h3 id="chap5">Chap5</h3>
<ul>
<li>MP神经元</li>
<li>感知机Perceptron : 由两层神经元组成,输出层为MP神经元，需要激活函数处理。</li>
<li>非线性：多层前馈神经网络(multi-layer feedforwaed neural network)
<ul>
<li>通过BP算法训练</li>
<li><strong>累计BP算法（用所有样本）与标准BP算法(只用一个样本)</strong>的区别类似于<strong>随机梯度下降(只用一个样本)与梯度下降（用所有样本）</strong>之间的区别。</li>
<li>折中：小批量的随机梯度下降/...</li>
</ul></li>
<li>跳出局部最优:
<ul>
<li><strong>模拟退火</strong> : 每一步<strong>以一定概率接受更差</strong>的结果、<strong>随机梯度下降</strong>、<strong>遗传算法</strong></li>
<li>这些算法基本都是启发式的，没有理论保证。</li>
</ul></li>
<li>DNN:
<ul>
<li>进行<strong>深度学习</strong>也可以理解为进行<strong>特征学习</strong>或者<strong>表示学习</strong>。</li>
<li><strong>增加隐藏层数目比增加隐藏层神经元个数往往更有效</strong>。</li>
<li>多隐藏层的神经网络<strong>难以用BP进行训练</strong>，<strong>梯度会发散不收敛</strong>。</li>
<li><strong>无监督逐层训练</strong>是一个有效手段:
<ul>
<li>每次训练一层隐藏节点，将<strong>上一层输出作为输入，本层输出作为下一层输入</strong>。上述过程也被称为“<strong>预训练</strong>”。预训练结束之后，再对整个网络进行<strong>微调(fine-tuning)</strong>。这就相当于<strong>基于局部较优的结果组合寻找全局最优</strong>。</li>
</ul></li>
<li>在<strong>CNN</strong>中采用了<strong>权值共享</strong>的策略，让<strong>一组神经元有相同的连接权值</strong>。</li>
</ul></li>
</ul>
<h3 id="chap6">Chap6</h3>
<ul>
<li>SVM:
<ul>
<li><p>基于训练集，找到一个超平面将不同的样本分开。</p></li>
<li><p>通过将超平面方程中的<span class="math inline">\(x\)</span>替换为<span class="math inline">\(\phi(x)\)</span>就可以实现非线性。</p></li>
<li><p><strong>软间隔</strong>: 为了解决 <strong>难以判断线性可分的结果是不是过拟合</strong>造成的， 提出<strong>软间隔</strong>来缓解这一问题。</p>
<ul>
<li>软间隔将<strong>允许SVM在一些样本上出错</strong></li>
<li>优化目标就变成 在<strong>最大化间隔</strong>的基础上，<strong>最小化出错样本</strong>。</li>
<li>引入的<strong>松弛变量</strong>是为了表述<strong>样本不满足约束</strong>的程度,其实就是每个样本的<strong>loss</strong></li>
<li>引入软间隔之后，仍然超平面仍然<strong>仅与支持向量有关</strong>，<strong>保持了稀疏性</strong>。</li>
</ul></li>
<li><p>如果将软间隔的SVM的<strong>惩罚函数</strong>换为<span class="math inline">\(l_{log}\)</span> ,那么SVM（未经过拓展的情况下）就是一个<strong>二分类的对率回归分类器</strong>。 区别在于，<strong>对率回归可以输出概率</strong>，<strong>SVM不能</strong>；<strong>SVM的解具有稀疏性</strong>，<strong>对率回归依赖于样本</strong>，<strong>训练开销更大</strong>。</p></li>
<li><p>从SVM可以引出正则化问题：</p>
<ul>
<li><p><span class="math display">\[
  \min_f \Omega(f) + C \sum_{i=1}^m l(f(x_i),y_i)
  \]</span></p></li>
<li><p><span class="math inline">\(\Omega(f)\)</span>为<strong>正则化项</strong>，亦称<strong>结构风险</strong>，<span class="math inline">\(C\)</span>为<strong>正则化系数</strong>，<span class="math inline">\(\sum_{i=1}^m l(f(x_i),y_i)\)</span>也被称为<strong>经验风险</strong>。</p>
<ul>
<li>结构风险主要描述的是模型的特质</li>
<li>经验风险描述模型的拟合程度</li>
<li>正则化其实<strong>就是一种惩罚措施</strong>，对不希望出现的结果<strong>添加了一个惩罚项</strong>。从贝叶斯估计的角度来看，正则化给模型<strong>提供了先验概率</strong>。</li>
</ul></li>
<li><p>常用的正则化项为<span class="math inline">\(l_p\)</span>范数</p>
<ul>
<li><span class="math inline">\(l_2\)</span>范数倾向于<strong>权重的取值尽量均衡</strong>，<strong>非零分量尽量稠密</strong>，彼此的距离尽量小；<span class="math inline">\(l_1\)</span>范数倾向于<strong>非零分量尽可能少</strong></li>
</ul></li>
</ul></li>
</ul></li>
<li>表示定理、核方法、KLDA</li>
</ul>
<h3 id="chap7">Chap7</h3>
<ul>
<li><p>贝叶斯判定准则:</p>
<ul>
<li>最小化总体风险，只需在每个样本上选择能<strong>最小化期望损失的标签</strong>即可</li>
<li>由此得到<strong>贝叶斯最优分类器</strong></li>
<li>其优化目标等价于最大化 后验概率<span class="math inline">\(P(c|x)\)</span>。
<ul>
<li>由贝叶斯定理，可以转换为最大化<span class="math inline">\(\frac{P(c)P(x|c)}{P(x)}\)</span></li>
</ul></li>
</ul></li>
<li><p>而<strong>概率模型训练的过程就是参数估计</strong>的过程，一般采用极大似然估计的方法。</p></li>
<li><p>朴素贝叶斯分类器:</p>
<ul>
<li><p>假设所有属性独立产生影响。</p></li>
<li><p>那么对于一个样本，优化目标为</p>
<ul>
<li><span class="math display">\[
  \arg\max_x P(c) \prod_i P(x_i|c)
  \]</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="chap8">Chap8</h3>
<ul>
<li>Bagging :
<ul>
<li>目标在于<strong>减少方差</strong></li>
<li>Bagging使用<strong>Bootstrap随机有放回的抽样来获取数据子集</strong>训练基础学习器。通常<strong>分类</strong>任务使用<strong>投票</strong>的方式集成，而<strong>回归</strong>任务通过<strong>平均</strong>的方式集成。</li>
<li>Bootstrap剩下的36.8%的数据可以用来<strong>包外估计</strong>，<strong>辅助决策树剪枝</strong>，<strong>提前结束神经网络训练</strong>等。</li>
<li>适合用于<strong>决策树、神经网络等容易受到样本扰动</strong>的学习器上。</li>
</ul></li>
<li>Boosting
<ul>
<li>目标在于<strong>减少偏差</strong></li>
<li><strong>通过算法集合将弱学习器转换为强学习器</strong></li>
<li><strong>训练一系列的弱学习器</strong>，所谓弱学习器是指仅比随机猜测好一点点的模型，例如较小的决策树，训练的方式是<strong>利用加权的数据</strong>。在训练的早期<strong>对于错分数据给予较大的权重</strong>。</li>
<li><strong>每一轮的训练集是不变的</strong>，<strong>改变的只是每一个样本的权重</strong>。</li>
<li><strong>样本权重</strong>：<strong>Bagging</strong>使用的是<strong>均匀取样</strong>，每个样本权重相等；<strong>Boosting根据错误率调整样本权重，错误率越大的样本权重越大</strong>。</li>
<li>因此，Boosting与Bagging的区分点在于 <strong>训练集以及样本权重</strong></li>
</ul></li>
<li><strong>串行集成方法</strong>: AdaBoost, 也就是说AdaBoost依次训练弱学习器，
<ul>
<li>学习器之间有强依赖。一般是Boosting。</li>
</ul></li>
<li><strong>并行集成方法</strong>: Random Forest
<ul>
<li>一般是Bagging、随机森林。</li>
</ul></li>
<li><strong>AdaBoost</strong>:
<ul>
<li>通过<strong>线性组合基学习器来最小化指数损失</strong>。</li>
<li>AdaBoost在经过一个时间步<span class="math inline">\(H_t\)</span>之后，<strong>样本分布将进行调整</strong>(<strong>序列采样</strong>)，<strong>使得下一轮基学习器能够纠正上一轮基学习器的错误</strong>。</li>
</ul></li>
<li><strong>随机森林</strong>:
<ul>
<li><strong>决策树作为基学习器</strong>，利用<strong>Bagging集成</strong>,引入了<strong>随机属性选择(只选择一个属性子集，与SGD/GD的区别类似)</strong>。</li>
<li><strong>训练效率、结果更好</strong>。</li>
</ul></li>
<li>集成的权重结合方法:
<ul>
<li>投票、平均、加权投票、加权平均、<strong>学习法（Stacking）</strong>。</li>
</ul></li>
<li><strong>Stacking:</strong>
<ul>
<li>它是一种<strong>“学习法”</strong>的代表，<strong>与Bagging,Boosting不在一条赛道</strong>上。</li>
<li>目标在于<strong>提升预测性能</strong></li>
<li><strong>异质集成,将多个不同类的学习器集合到一起</strong>。</li>
<li>先从<strong>初始数据集中训练出一个初级学习器</strong>，然后将<strong>初级学习器的输出融入特征</strong>作为<strong>次级学习器</strong>的输入。</li>
<li>其缺点在于<strong>次级</strong>学习器<strong>容易过拟合</strong>，因此常常使用<strong>交叉验证法</strong>或者<strong>留一法</strong>。</li>
</ul></li>
<li>多样性:
<ul>
<li>衡量<strong>不同学习器</strong>之间是否<strong>好而不同</strong>。</li>
<li>要增强多样性，可以在<strong>数据、参数、特征等</strong>不同角度进行调整。</li>
</ul></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Note/" rel="tag"><i class="fa fa-tag"></i> Note</a>
              <a href="/tags/AML/" rel="tag"><i class="fa fa-tag"></i> AML</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/27/ICSOS%E8%A1%A5%E7%9F%A5%E8%AF%86/" rel="prev" title="ICS and OS 杂项知识点">
      <i class="fa fa-chevron-left"></i> ICS and OS 杂项知识点
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/07/%E9%9D%A2%E8%AF%95%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/" rel="next" title="面试学习笔记">
      面试学习笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#chap1"><span class="nav-number">1.</span> <span class="nav-text">Chap1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap2"><span class="nav-number">2.</span> <span class="nav-text">Chap2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap3"><span class="nav-number">3.</span> <span class="nav-text">Chap3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap4"><span class="nav-number">4.</span> <span class="nav-text">Chap4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap5"><span class="nav-number">5.</span> <span class="nav-text">Chap5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap6"><span class="nav-number">6.</span> <span class="nav-text">Chap6</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap7"><span class="nav-number">7.</span> <span class="nav-text">Chap7</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chap8"><span class="nav-number">8.</span> <span class="nav-text">Chap8</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yanquan Chen"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Yanquan Chen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/DespairL" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;DespairL" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/Chen61723827" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;Chen61723827" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yanquan Chen</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
