<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Rambling Digression</title>
    <url>/2021/11/13/2021-11-13-By-talk/</url>
    <content><![CDATA[<h5 id="section">!!!!</h5>
]]></content>
      <tags>
        <tag>by-talk</tag>
      </tags>
  </entry>
  <entry>
    <title>Math Test</title>
    <url>/2021/11/13/2021-11-17-test-math/</url>
    <content><![CDATA[<p><span class="math inline">\(\frac{3}{4}\)</span></p>
<p><span class="math inline">\(\mathcal{F}\)</span></p>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>辉夜大小姐想让我告白~</title>
    <url>/2021/11/13/2021-11-13-%E8%BE%89-%E5%A4%9C-%E5%A4%A7-%E5%B0%8F-%E5%A7%90-%E6%83%B3-%E8%AE%A9-%E6%88%91-%E5%91%8A-%E7%99%BD/</url>
    <content><![CDATA[<h3 id="总体感受">总体感受</h3>
<h3 id="读漫画过程中的小触动">读漫画过程中的小触动</h3>
<h4 id="大佛">大佛</h4>
<ul>
<li>"会喜欢上做正确的事的人，那是件很理所当然的事。世界上有许多因为时机和状况的原因，而没能把[喜欢]变成恋爱感情的例子。请让我祝你幸福。毕竟并不是只有爱情才是[喜欢]。"</li>
<li><img src="../assets/img/posts/huiye/image-20211117105156460.png" alt="image-20211117105156460" style="zoom:33%;" /></li>
<li><img src="../assets/img/posts/huiye/image-20211117105334372.png" alt="image-20211117105334372" style="zoom:33%;" /></li>
</ul>
<h4 id="辉夜">辉夜</h4>
<ul>
<li>有的人，亲手为喜欢的人做了巧克力，最终，最终她真的送了出去！</li>
</ul>
<h4 id="白银御行">白银御行</h4>
<h4 id="石上优">石上优</h4>
<ul>
<li>有的人，嘴上喊着现充去死去死，最终自己活成了现充的模样</li>
</ul>
<h4 id="藤原千花">藤原千花</h4>
<ul>
<li>有的人，嘴上说着要减肥减肥，最终还是把巧克力当爆米花吃</li>
</ul>
<h4 id="早坂爱">早坂爱</h4>
<h4 id="小弥">小弥</h4>
<ul>
<li>有的人，嘴上强调着送义理巧克力，最终还是送了情人节特别款</li>
</ul>
<h4 id="子安燕">子安燕</h4>
<ul>
<li>为什么喜爱之情跟恋爱之情是不一样的呢?</li>
</ul>
]]></content>
      <tags>
        <tag>二次元desi</tag>
        <tag>辉夜大小姐想让我告白~</tag>
      </tags>
  </entry>
  <entry>
    <title>解决Mathjax与Markdown之间的冲突问题</title>
    <url>/2021/12/22/2021-11-19-Mathjax-Markdown/</url>
    <content><![CDATA[<p>由于最近刚刚开始搭建个人blog中遇到了“<strong>明明启用了Mathjax,但是markdown文档在上传之后仍然无法正确显示行间公式或者行内公式</strong>”的问题，因此，折腾了好一会之后，得到了一个个人的修复方案。</p>
<span id="more"></span>
<h2 id="blog搭建结构">Blog搭建结构</h2>
<p>Github自带的基于Jekyll的Github pages搭建方案。</p>
<h2 id="问题原因">问题原因</h2>
<p>举个例子来说，在 Markdown 中，下划线 _ 被保留，那么，当Markdown 在 MathJax 之前处理文档的时候，就会将下划线 _ 转为一个HTML tag&lt;i&gt;，导致MathJax无法正确识别公式。</p>
<h2 id="解决方案">解决方案</h2>
<ul>
<li><p>修改xx.github.io/**_config.yml** 中的markdown解析器为kramdown:</p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">markdown: kramdown</span><br></pre></td></tr></table></figure></p></li>
<li><p>在xx.github.io/**_include/header.html**中添加两行处理代码:</p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config(&#123;tex2jax: &#123;inlineMath: [[&#x27;$&#x27;,&#x27;$&#x27;], [&#x27;\\(&#x27;,&#x27;\\)&#x27;]]&#125;&#125;);&lt;/script&gt;</span><br><span class="line">&lt;script type=&quot;text/javascript&quot; async src=&quot;//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>
<p>直接放在<code>&lt;header class="main-header"&gt;</code>后两行即可。</p></li>
<li><p>这样以后，用$...$写行内公式，用$$...$$写行间公式应该都没有问题了。</p></li>
</ul>
]]></content>
      <tags>
        <tag>Problem</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n Assignment2</title>
    <url>/2021/12/22/2021-11-19-Record-CS224n-a2/</url>
    <content><![CDATA[<h3 id="前情提要-the-word2vec-skip-gram-prediction-model">前情提要 : The word2vec skip-gram prediction model</h3>
<p>这里对handout_Assignment2.Understanding word2vec进行一个个人梳理。</p>
<ul>
<li><p>word2vec诞生的idea在于，我们有一个“每个word都是通过它周围的words组成一个company，我们才能够理解the meaning”的想法而诞生的。</p></li>
<li><p>因此，在skip-gram word2vec的想法下，一个能表达词语意思的结构由一个中心词(center word) <span class="math inline">\(c\)</span>, 跟它周围的词语(限定在一个contextual window)组成。对于处在contextual window中的一个特定的词语(specific word)用符号<span class="math inline">\(o\)</span> 记。</p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202111191258141.png" alt="image-20211119125840081" /><figcaption aria-hidden="true">image-20211119125840081</figcaption>
</figure>
<p>在The word2vec skip-gram prediction model中的contextual window 的一个例子如上，对于一个center word banking,其contextual window 中的词为turing,into,crises,as。</p></li>
</ul>
<span id="more"></span>
<ul>
<li><p>在word2vec中，我们想要计算的条件概率采用如下形式进行求解: <span class="math display">\[
  P(O = o | C = c) =\frac{\exp(\mathbf{u_o^T} \mathbf{v_c})}{\sum_{\omega \in Vocabulary Set} \exp(\mathbf{u_\omega^T} \mathbf{v_c})}
  \]</span></p>
<ul>
<li><span class="math inline">\(\mathbf{u_o}\)</span> :表示的是一个outside vector,其代表了一个特定的outside word <span class="math inline">\(o\)</span></li>
<li><span class="math inline">\(\mathbf{v_c}\)</span> : 与<span class="math inline">\(\mathbf{u_o}\)</span>类似的，它表示的是一个center vector,代表了我们选定的一个中心词<span class="math inline">\(c\)</span></li>
<li>在实际应用中，通常都以矩阵形式<span class="math inline">\(\mathbf{U},\mathbf{V}\)</span>存储这两个参数。一般来说，这两个矩阵的每一列都记录了一个词<span class="math inline">\(w\)</span>在处于不同角色，即outside word或者center word下的不同向量表示。</li>
</ul></li>
<li><p>最naive的loss定义如下:对于一个特定的pair<span class="math inline">\((c,o)\)</span> : <span class="math display">\[
  \mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U}) = -\log P(O = o | C = c)
  \]</span></p>
<ul>
<li><p>注意到，在下面的书面题中，我们将会证明其与<span class="math inline">\(\mathbf{y}\)</span>与<span class="math inline">\(\mathbf{\hat{y}}\)</span>之间的交叉熵损失是一致的。</p>
<ul>
<li><p><span class="math inline">\(\mathbf{y}\)</span>: the ground truth,真实的标签。即一个one-hot编码,除特定的outside word<span class="math inline">\(o\)</span>下标处为1之外，均0.</p></li>
<li><p><span class="math inline">\(\mathbf{\hat{y}}\)</span>: 由之前定义的概率分布<span class="math inline">\(P(O = o | C = c)\)</span>给出的prediction</p></li>
<li><p>交叉熵损失(Cross Entropy) : <span class="math display">\[
  -\sum_{i}\mathbf{y_i} \log(\mathbf{\hat{y_i}})
  \]</span></p></li>
</ul></li>
</ul></li>
</ul>
<h3 id="前情提要2-negative-sampling-loss">前情提要2 ： Negative Sampling Loss</h3>
<p>Negative Sampling的大概想法:</p>
<ul>
<li><p>从vocabulary中采样出<span class="math inline">\(K\)</span>个negative samples(即words),<span class="math inline">\(w_1,w_2,...,w_k\)</span>,其相对应地就有outside vectors<span class="math inline">\(\mathbf{u_1},\mathbf{u_2},...,\mathbf{u_K}\)</span> 。定义negative sampling loss function如下:</p>
<ul>
<li><p><span class="math display">\[
  \mathbf{J}_{neg-sample}(\mathbf{v_c},o,\mathbf{U}) = \\
  -\log(\sigma(\mathbf{u_o^T} \mathbf{v_c})) - \sum_{k=1}^{K} \log(\sigma(\mathbf{-u_k^T} \mathbf{v_c}))
  \]</span></p>
<ul>
<li><span class="math inline">\(\sigma(\cdot)\)</span>可以是sigmoid 函数</li>
<li><span class="math inline">\(o\)</span>不在<span class="math inline">\(K\)</span>个negative samples当中</li>
</ul></li>
</ul></li>
<li><p>Negative Sampling loss由于每次只要计算<span class="math inline">\(K\)</span>个negative samples的相关信息，效率会比naive-softmax高很多。</p></li>
</ul>
<h3 id="前情提要3-skip-gram-loss">前情提要3 ： Skip-gram Loss</h3>
<p>由之前的介绍，我们就可以整理出skip-gram的大致想法:</p>
<ul>
<li><p>对于一个中心词<span class="math inline">\(c = w_t\)</span> ,其context window在window size为<span class="math inline">\(m\)</span>的情况下是<span class="math inline">\([w_{t-m},...,w_{t-1},w_{t},w_{t+1},...,w_{t+m}]\)</span> 。定义context window的total loss：</p>
<ul>
<li><p><span class="math display">\[
  \mathbf{J}_{skip-gram}(\mathbf{v_c},w_{t-m},...,w_{t+m},\mathbf{U}) = \\
  \sum_{-m\le j\le m,j\not=0} \mathbf{J}(\mathbf{v_c},w_{t+j},\mathbf{U})
  \]</span></p></li>
<li><p><span class="math inline">\(\mathbf{J}(\mathbf{v_c},w_{t+j},\mathbf{U})\)</span>可以是任意的一个loss function。</p></li>
</ul></li>
</ul>
<h3 id="计算">计算</h3>
<h4 id="在此之前">在此之前</h4>
<p>对于所有的推导，我们都应该尽可能地遵守shape convention,具体而言，任意一个函数<span class="math inline">\(f(x)\)</span>的偏导的shape都应该跟<span class="math inline">\(x\)</span>的shape保持一致。</p>
<ol type="a">
<li>Show that the naive-softmax loss is the same as the cross-entropy loss between <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span>; i.e., show that: <span class="math display">\[
-\sum_{\omega \in Vocab} y_{\omega} \log (\hat{y_{\omega}}) = -\log (\hat{y_{o}})
\]</span></li>
</ol>
<ul>
<li>这里注意到<span class="math inline">\(y_{\omega}\)</span>是one-hot编码形式的，因此容易得到: <span class="math display">\[
  -\sum_{\omega \in Vocab} y_{\omega} \log (\hat{y_{\omega}}) = y_{o} \log (\hat{y_{o}}) = \log (\hat{y_{o}})
  \]</span></li>
</ul>
<ol start="2" type="a">
<li>Compute the partial derivative of <span class="math inline">\(\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})\)</span> with respect to <span class="math inline">\(\mathbf{v_c}\)</span> :</li>
</ol>
<ul>
<li><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{v_c}} = \\ \frac{\exp(\mathbf{u_o^T}\mathbf{v_c})\mathbf{u_o}\sum_{\omega \in VS} \exp(\mathbf{u_\omega^T} \mathbf{v_c}) - \exp(\mathbf{u_o^T}\mathbf{v_c})\sum_{\omega \in VS} \exp(\mathbf{u_\omega^T} \mathbf{v_c}) \mathbf{u_\omega}}{-P(O = o | C = c) (\sum_{\omega \in VS} \exp(\mathbf{u_\omega^T} \mathbf{v_c}))^2} \\
  = - \mathbf{u_o} + \sum_{\omega \in VS} \frac{\exp(\mathbf{u_\omega^T} \mathbf{v_c}) \mathbf{u_\omega}}{\sum_{\omega \in VS} \exp(\mathbf{u_\omega^T} \mathbf{v_c})} \\
  = - \mathbf{u_o} + \sum_{\omega \in VS} P(O = \omega | C = c) \mathbf{u_\omega} \\
  = -\mathbf{U}^T \mathbf{y}+\mathbf{U}^T\mathbf{\hat{y}} \\
  = \mathbf{U}^T (\mathbf{\hat{y}} - \mathbf{y})
  \]</span></li>
</ul>
<p>(c),(d)Compute the partial derivatives of <span class="math inline">\(\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})\)</span> with respect to each of the ‘outside’ word vectors, <span class="math inline">\(\mathbf{u_w}\)</span>’s <span class="math inline">\(\mathbf{U}\)</span>’s</p>
<ul>
<li><p>注意到原式<span class="math inline">\(P(O = o | C = c)\)</span>中<span class="math inline">\(\mathbf{u_w},\mathbf{v_c}\)</span>是存在着一定对称性的，对<span class="math inline">\(\mathbf{u_w}\)</span>求偏导的形式与对<span class="math inline">\(\mathbf{v_c}\)</span>求偏导的形式基本一致,因此可以简单交换符号后得到:</p>
<ul>
<li><p><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{U}} = (\mathbf{\hat{y}} - \mathbf{y})^T \mathbf{v_c}
  \]</span></p></li>
<li><p><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{u_w}} = P(O=w|C=c) \mathbf{v_c}
  \]</span></p></li>
<li><p><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{u_w}} = (P(O=o|C=c)-1) \mathbf{v_c}
  \]</span></p></li>
</ul></li>
</ul>
<p>(e)Please compute the derivative of <span class="math inline">\(σ(x)\)</span> with respect to x, where x is a scalar: <span class="math display">\[
\sigma(x) = \frac{1}{1+e^{-x}}
\]</span></p>
<ul>
<li>sigmoid,softmax的导数均为<span class="math inline">\(\sigma(x)(1-\sigma(x))\)</span></li>
</ul>
<p>(f)for negtive sampling loss,repeat (b)(c):</p>
<ul>
<li><p>利用sigmoid函数的性质，容易得到: <span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{v_c}} = \\
  (\sigma(\mathbf{u_o^T} \mathbf{v_c}) - 1)\mathbf{u_o} + \sum_{k=1}^{K}(1-\sigma(-\mathbf{u_k^T} \mathbf{v_c}))\mathbf{u_k}
  \]</span></p>
<p><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{u_o}} = (\sigma(\mathbf{u_o^T} \mathbf{v_c}) - 1)\mathbf{v_c}
  \]</span></p>
<p><span class="math display">\[
  \frac{\partial\mathbf{J}_{naive-softmax}(\mathbf{v_c},o,\mathbf{U})}{\partial \mathbf{u_k}} = (1-\sigma(\mathbf{-u_k^T} \mathbf{v_c}) )\mathbf{v_c}
  \]</span></p></li>
</ul>
<p>(h)for skip-gram loss,repeat (b)(c):</p>
<ul>
<li><p><span class="math display">\[
  \frac{\partial \mathbf{J}_{skip-gram}(\mathbf{v_c},w_{t-m},...,w_{t+m},\mathbf{U})}{\partial \mathbf{v_c}} = \\
  \sum_{-m\le j\le m,j\not=0} \frac{\partial \mathbf{J}(\mathbf{v_c},w_{t+j},\mathbf{U})}{\partial \mathbf{v_c}}
  \]</span></p></li>
<li><p><span class="math display">\[
  \frac{\partial \mathbf{J}_{skip-gram}(\mathbf{v_c},w_{t-m},...,w_{t+m},\mathbf{U})}{\partial \mathbf{v_w}} = 0\\
  \]</span></p></li>
<li><p><span class="math display">\[
  \frac{\partial \mathbf{J}_{skip-gram}(\mathbf{v_c},w_{t-m},...,w_{t+m},\mathbf{U})}{\partial \mathbf{U}} = \\
  \sum_{-m\le j\le m,j\not=0} \frac{\partial \mathbf{J}(\mathbf{v_c},w_{t+j},\mathbf{U})}{\partial \mathbf{U}}
  \]</span></p></li>
</ul>
<h3 id="实验中的新知">实验中的新知</h3>
<ul>
<li>np.allclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False)
<ul>
<li>equal_nan控制是否判断相同位置的NaN是相等的。</li>
<li>根据以下式子判断是否return True。
<ul>
<li>absolute(a - b) &lt;= (atol+ rtol * absolute(b))</li>
</ul></li>
<li>a ,b 地位不同，因此np.allclose(a,b)与np.allclose(b,a)不一定相同。</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>Project Record</category>
      </categories>
      <tags>
        <tag>CS224n</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Jekyll theme Adam Blog 2.0</title>
    <url>/2021/12/22/2021-11-17-Adam-theme/</url>
    <content><![CDATA[<p><strong>本文的所有内容均搬运自<a href="https://github.com/the-mvm/the-mvm.github.io">the-mvm/the-mvm.github.io: The Minimum Viable Model website and Jekyll theme.</a></strong></p>
<p>demo site now <a href="https://weathered-bread-8229.on.fleek.co/">mirrored</a> in <a href="https://github.com/ipfs/ipfs#quick-summary">IPFS</a>!</p>
<h1 id="jekyll-theme-adam-blog-2.0">Jekyll theme: Adam Blog 2.0</h1>
<p>by <a href="https://github.com/amaynez">Armando Maynez</a> based on <a href="https://github.com/artemsheludko/adam-blog">V1.0</a> by <a href="https://github.com/artemsheludko">Artem Sheludko</a>.</p>
<p>Adam Blog 2.0 is a Jekyll theme that was built to be 100% compatible with <a href="https://pages.github.com/">GitHub Pages</a>. If you are unfamiliar with GitHub Pages, you can check out <a href="https://help.github.com/categories/github-pages-basics/">their documentation</a> for more information. <a href="http://jmcglone.com/guides/github-pages/">Jonathan McGlone's guide</a> on creating and hosting a personal site on GitHub is also a good resource.</p>
<h3 id="what-is-jekyll">What is Jekyll?</h3>
<p>Jekyll is a simple, blog-aware, static site generator for personal, project, or organization sites. Basically, Jekyll takes your page content along with template files and produces a complete website. For more information, visit the <a href="https://jekyllrb.com/docs/home/">official Jekyll site</a> for their documentation. Codecademy also offers a great course on <a href="https://www.codecademy.com/learn/deploy-a-website">how to deploy a Jekyll site</a> for complete beginners.</p>
<span id="more"></span>
<h3 id="never-used-jekyll-before">Never Used Jekyll Before?</h3>
<p>The beauty of hosting your website on GitHub is that you don't have to actually have Jekyll installed on your computer. Everything can be done through the GitHub code editor, with minimal knowledge of how to use Jekyll or the command line. All you have to do is add your posts to the <code>_posts</code> directory and edit the <code>_config.yml</code> file to change the site settings. With some rudimentary knowledge of HTML and CSS, you can even modify the site to your liking. This can all be done through the GitHub code editor, which acts like a content management system (CMS).</p>
<h2 id="features-of-v2.0">Features of v2.0:</h2>
<ul>
<li>SEO meta tags</li>
<li>Dark mode ([configurable in _config.yml file](https://github.com/the-mvm/the-mvm.github.io/blob/a8d4f781bfbc4107b4842433701d28f5bbf1c520/_config.yml#L10))</li>
<li>automatic <a href="http://the-mvm.github.io/sitemap.xml">sitemap.xml</a></li>
<li>automatic <a href="http://the-mvm.github.io/archive/">archive page</a> with infinite scrolling capability</li>
<li><a href="https://the-mvm.github.io/tag/?tag=Coding">new page</a> of posts filtered by a single tag (without needing autopages from paginator V2), also with infinite scrolling</li>
<li>click to tweet functionality (just add a <code>&lt;tweet&gt; &lt;/tweet&gt;</code> tag in your markdown.</li>
<li>custom and responsive <a href="https://the-mvm.github.io/404.html">404 page</a></li>
<li>responsive and automatic Table of Contents (optional per post)</li>
<li>read time per post automatically calculated</li>
<li>responsive post tags and social share icons (sticky or inline)</li>
<li>included linkedin, reddit and bandcamp icons</li>
<li><em>copy link to clipboard</em> sharing option (and icon)</li>
<li>view on github link button (optional per post)</li>
<li>MathJax support (optional per post)</li>
<li>tag cloud in the home page</li>
<li>'back to top' button</li>
<li>comments 'courtain' to mask the disqus interface until the user clicks on it ([configurable in _config.yml](https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/_config.yml#L13))</li>
<li><a href="https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/assets/css/main.css#L8">CSS variables</a> to make it easy to customize all colors and fonts</li>
<li>added several themes for code syntax highlight [configurable from the _config.yml file](https://github.com/the-mvm/the-mvm.github.io/blob/e146070e9348c2e8f46cb90e3f0c6eb7b59c041a/_config.yml#L44).</li>
<li>responsive footer menu and footer logo (<a href="https://github.com/the-mvm/the-mvm.github.io/blob/d4a67258912e411b639bf5acd470441c4c219544/_config.yml#L7">if setup in the config file</a>)</li>
<li>search shows results based on full post content, not just the description</li>
<li>smoother menu animations</li>
</ul>
<h2 id="features-preserved-from-v1.0">Features preserved from v1.0</h2>
<ul>
<li><a href="https://fonts.google.com/">Google Fonts</a></li>
<li><a href="http://fontawesome.io/">Font Awesome icons</a></li>
<li><a href="https://disqus.com/">Disqus</a></li>
<li><a href="https://mailchimp.com/">MailChimp</a></li>
<li><a href="https://analytics.google.com/analytics/web/">Analytics</a></li>
<li><a href="https://github.com/christian-fei/Simple-Jekyll-Search">Search</a></li>
</ul>
<h2 id="demo">Demo</h2>
<p><a href="https://the-mvm.github.io/">Check the theme in action</a></p>
<p>The main page looks like this:</p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/homepage-responsive.jpg?raw=true"></p>
<p>Dark mode selector in main menu:</p>
<p><img width="560px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/light-toggle.png?raw=true"></p>
<p>The post page looks like:</p>
<p><img width="540px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/post.jpg?raw=true"> <img width="540px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/post_bottom.jpg?raw=true"></p>
<p>Custom responsive 404:</p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/404-responsive.jpg?raw=true"></p>
<p>Dark mode looks like this:</p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/homepage-dark.png?raw=true"></p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/post-dark.png?raw=true"> <img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/post_bottom-dark.png?raw=true"></p>
<h1 id="installation">Installation</h1>
<h2 id="local-installation">Local Installation</h2>
<p>For a full local installation of Adam Blog 2.0, <a href="https://github.com/the-mvm/the-mvm.github.io/archive/refs/heads/main.zip">download your own copy of Adam Blog 2.0</a> and unzip it into it's own directory. From there, open up your favorite command line tool, enter <code>bundle install</code>, and then enter <code>jekyll serve</code>. Your site should be up and running locally at <a href="http://localhost:4000">http://localhost:4000</a>.</p>
<p>If you're completely new to Jekyll, I recommend checking out the documentation at <a href="https://jekyllrb.com/" class="uri">https://jekyllrb.com/</a> or there's a tutorial by <a href="https://www.smashingmagazine.com/2014/08/build-blog-jekyll-github-pages/">Smashing Magazine</a>.</p>
<p>If you are hosting your site on GitHub Pages, then committing a change to the <code>_config.yml</code> file (or any other file) will force a rebuild of your site with Jekyll. Any changes made should be viewable soon after. If you are hosting your site locally, then you must run <code>jekyll serve</code> again for the changes to take place.</p>
<p>Head over to the <code>_posts</code> directory to view all the posts that are currently on the website, and to see examples of what post files generally look like. You can simply just duplicate the template post and start adding your own content.</p>
<h2 id="github-pages-installation">GitHub Pages Installation</h2>
<h3 id="step-1."><strong>STEP 1.</strong></h3>
<p><a href="https://github.com/the-mvm/the-mvm.github.io/fork/">Fork this repository</a> into your own account.</p>
<h4 id="using-github-pages">Using Github Pages</h4>
<p>You can host your Jekyll site for free with Github Pages. <a href="https://pages.github.com/">Click here</a> for more information.</p>
<p>When forking, if you use as destination a repository named <code>USERNAME.github.io</code> then your url will be <code>https://USERNAME.github.io/</code>, else <code>https://USERNAME.github.io/REPONAME/</code>) and your site will be published to the gh-pages branch. Note: if you are hosting several sites under the same GitHub username, then you will have to use <a href="https://help.github.com/articles/user-organization-and-project-pages/">Project Pages instead of User Pages</a> - just change the repository name to something other than 'http://USERNAME.github.io'.</p>
<h5 id="a-configuration-tweak-if-youre-using-a-gh-pages-branch">A configuration tweak if you're using a gh-pages branch</h5>
<p>In addition to your github-username.github.io repo that maps to the root url, you can serve up sites by using a gh-pages branch for other repos so they're available at github-username.github.io/repo-name.</p>
<p>This will require you to modify the <code>_config.yml</code> like so:</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Site settings</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Repo</span> <span class="string">Name</span></span><br><span class="line"><span class="attr">email:</span> <span class="string">your_email@example.com</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Your</span> <span class="string">Name</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&quot;Repo description&quot;</span></span><br><span class="line"><span class="attr">baseurl:</span> <span class="string">&quot;/repo-name&quot;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">&quot;https://github-username.github.io&quot;</span></span><br></pre></td></tr></table></figure>
<p>This will ensure that the the correct relative path is constructed for your assets and posts.</p>
<h3 id="step-2."><strong>STEP 2.</strong></h3>
<p>Modify <code>_config.yml</code> file, located in the root directory, with your data.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Site settings</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">The</span> <span class="string">Title</span> <span class="string">for</span> <span class="string">Your</span> <span class="string">Website</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;A description of your blog&#x27;</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">&#x27;:title:output_ext&#x27;</span> <span class="comment"># how the permalinks will behave</span></span><br><span class="line"><span class="attr">baseurl:</span> <span class="string">&quot;/&quot;</span> <span class="comment"># the subpath of your site, e.g. /blog</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">&quot;&quot;</span> <span class="comment"># the base hostname &amp; protocol for your site, e.g. http://example.com</span></span><br><span class="line"><span class="attr">logo:</span> <span class="string">&quot;&quot;</span> <span class="comment"># the logo for your site</span></span><br><span class="line"><span class="attr">logo-icon:</span> <span class="string">&quot;&quot;</span> <span class="comment"># a smaller logo, typically squared</span></span><br><span class="line"><span class="attr">logo-icon-SEO:</span> <span class="string">&quot;&quot;</span> <span class="comment"># must be a non SVG file, could be the same as the logo-icon</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Night/Dark mode default mode is &quot;auto&quot;, &quot;auto&quot; is for auto nightshift (19:00 - 07:00), &quot;manual&quot; is for manual toggle, and &quot;on/off&quot; is for default on/off. Whatever the user&#x27;s choice is, it will supersede the default setting of the site and be kept during the visit (session). Only the dark mode setting is &quot;manual&quot;, it will be always kept on every visit (i.e. no matter the browser is closed or not)</span></span><br><span class="line"><span class="attr">night_mode:</span> <span class="string">&quot;auto&quot;</span></span><br><span class="line"><span class="attr">logo-dark:</span> <span class="string">&quot;/assets/img/branding/MVM-logo-full-dark.svg&quot;</span> <span class="comment">#if you want to display a different logo when in dark mode</span></span><br><span class="line"><span class="attr">highlight_theme:</span> <span class="string">syntax-base16.monokai.dark</span> <span class="comment"># select a dark theme for the code highlighter if needed</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Author settings</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Your</span> <span class="string">Name</span> <span class="comment"># add your name</span></span><br><span class="line"><span class="attr">author-pic:</span> <span class="string">&#x27;&#x27;</span> <span class="comment"># a picture of you</span></span><br><span class="line"><span class="attr">about-author:</span> <span class="string">&#x27;&#x27;</span> <span class="comment"># a brief description of you</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Contact links</span></span><br><span class="line"><span class="attr">email:</span> <span class="string">your@email.com</span> <span class="comment"># Add your Email address</span></span><br><span class="line"><span class="attr">phone:</span> <span class="comment"># Add your Phone number</span></span><br><span class="line"><span class="attr">website:</span>  <span class="comment"># Add your website</span></span><br><span class="line"><span class="attr">linkedin:</span>  <span class="comment"># Add your Linkedin handle</span></span><br><span class="line"><span class="attr">github:</span>  <span class="comment"># Add your Github handle</span></span><br><span class="line"><span class="attr">twitter:</span>  <span class="comment"># Add your Twitter handle</span></span><br><span class="line"><span class="attr">bandcamp:</span>  <span class="comment"># Add your Bandcamp username</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tracker</span></span><br><span class="line"><span class="attr">analytics:</span> <span class="comment"># Google Analytics tag ID</span></span><br><span class="line"><span class="attr">fbadmin:</span> <span class="comment"># Facebook ID admin</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Paginate</span></span><br><span class="line"><span class="attr">paginate:</span> <span class="number">6</span> <span class="comment"># number of items to show in the main page</span></span><br><span class="line"><span class="attr">paginate_path:</span> <span class="string">&#x27;page:num&#x27;</span></span><br><span class="line"><span class="attr">words_per_minute:</span> <span class="number">200</span> <span class="comment"># default words per minute to be considered when calculating the read time of the blog posts</span></span><br></pre></td></tr></table></figure>
<h3 id="step-3."><strong>STEP 3.</strong></h3>
<p>To configure the newsletter, please create an account in https://mailchimp.com, set up a web signup form and paste the link from the embed signup form in the <code>config.yml</code> file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Newsletter</span></span><br><span class="line"><span class="attr">mailchimp:</span> <span class="string">&quot;https://github.us1.list-manage.com/subscribe/post?u=8ece198b3eb260e6838461a60&amp;amp;id=397d90b5f4&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="step-4."><strong>STEP 4.</strong></h3>
<p>To configure Disqus, set up a <a href="https://disqus.com/admin/create/">Disqus site</a> with the same name as your site. Then, in <code>_config.yml</code>, edit the <code>disqus_identifier</code> value to enable.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Disqus</span></span><br><span class="line"><span class="attr">discus_identifier:</span>  <span class="comment"># Add your discus identifier</span></span><br><span class="line"><span class="attr">comments_curtain:</span> <span class="literal">yes</span> <span class="comment"># leave empty to show the disqus embed directly</span></span><br></pre></td></tr></table></figure>
<p>More information on <a href="http://www.perfectlyrandom.org/2014/06/29/adding-disqus-to-your-jekyll-powered-github-pages/">how to set up Disqus</a>.</p>
<h3 id="step-5."><strong>STEP 5.</strong></h3>
<p>Customize the site colors. Modify <code>/assets/css/main.css</code> as follows:</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">html</span> &#123;</span><br><span class="line">  --shadow:       <span class="built_in">rgba</span>(<span class="number">32</span>,<span class="number">30</span>,<span class="number">30</span>,.<span class="number">3</span>);</span><br><span class="line">  --accent:       <span class="number">#DB504A</span>;    <span class="comment">/* accent */</span></span><br><span class="line">  --accent-dark:  <span class="number">#4e3e51</span>;    <span class="comment">/* accent 2 (dark) */</span></span><br><span class="line">  --<span class="selector-tag">main</span>:         <span class="number">#326273</span>;    <span class="comment">/* main color */</span></span><br><span class="line">  --<span class="selector-tag">main</span>-dim:     <span class="number">#879dab</span>;    <span class="comment">/* dimmed version of main color */</span></span><br><span class="line">  --text:         <span class="number">#201E1E</span>;</span><br><span class="line">  --grey1:        <span class="number">#5F5E58</span>;</span><br><span class="line">  --grey2:        <span class="number">#8D897C</span>;</span><br><span class="line">  --grey3:        <span class="number">#B4B3A7</span>;</span><br><span class="line">  --grey4:        <span class="number">#DAD7D2</span>;</span><br><span class="line">  --grey5:        <span class="number">#F0EFED</span>;</span><br><span class="line">  --<span class="attribute">background</span>:   <span class="number">#ffffff</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">html</span><span class="selector-attr">[data-theme=<span class="string">&quot;dark&quot;</span>]</span>  &#123;</span><br><span class="line">  --accent:       <span class="number">#d14c47</span>;    <span class="comment">/* accent */</span></span><br><span class="line">  --accent-dark:  <span class="number">#CD8A7A</span>;    <span class="comment">/* accent 2 (dark) */</span></span><br><span class="line">  --<span class="selector-tag">main</span>:         <span class="number">#4C6567</span>;    <span class="comment">/* main color */</span></span><br><span class="line">  --<span class="selector-tag">main</span>-dim:     <span class="number">#273335</span>;    <span class="comment">/* dimmed version of main color */</span></span><br><span class="line">  --text:         <span class="number">#B4B3A7</span>;</span><br><span class="line">  --grey1:        <span class="number">#8D897C</span>;</span><br><span class="line">  --grey2:        <span class="number">#827F73</span>;</span><br><span class="line">  --grey3:        <span class="number">#76746A</span>;</span><br><span class="line">  --grey4:        <span class="number">#66645D</span>;</span><br><span class="line">  --grey5:        <span class="number">#4A4945</span>;</span><br><span class="line">  --<span class="attribute">background</span>:   <span class="number">#201E1E</span>;</span><br><span class="line">  --shadow:       <span class="built_in">rgba</span>(<span class="number">180</span>,<span class="number">179</span>,<span class="number">167</span>,.<span class="number">3</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="step-6."><strong>STEP 6.</strong></h3>
<p>Customize the site fonts. Modify <code>/assets/css/main.css</code> as follows:</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">  --font1: <span class="string">&#x27;Lora&#x27;</span>, charter, Georgia, Cambria, <span class="string">&#x27;Times New Roman&#x27;</span>, Times, serif;<span class="comment">/* body text */</span></span><br><span class="line">  --font2: <span class="string">&#x27;Source Sans Pro&#x27;</span>, <span class="string">&#x27;Helvetica Neue&#x27;</span>, Helvetica, Arial, sans-serif; <span class="comment">/* headers and titles   */</span></span><br><span class="line">  --font1-light:      <span class="number">400</span>;</span><br><span class="line">  --font1-regular:    <span class="number">400</span>;</span><br><span class="line">  --font1-bold:       <span class="number">600</span>;</span><br><span class="line">  --font2-light:      <span class="number">200</span>;</span><br><span class="line">  --font2-regular:    <span class="number">400</span>;</span><br><span class="line">  --font2-bold:       <span class="number">700</span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>If you change the fonts, you need to also modify <code>/_includes/head.html</code> as follows: Uncomment and change the following line with your new fonts and font weights:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">&quot;https://fonts.googleapis.com/css?family=Lora:400,600|Source+Sans+Pro:200,400,700&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Delete everything within <code>&lt;style&gt;&lt;/style&gt;</code> just before the line above:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="css"></span></span><br><span class="line"><span class="css"><span class="comment">/* latin */</span></span></span><br><span class="line"><span class="css"><span class="keyword">@font-face</span> &#123;</span></span><br><span class="line"><span class="css">  <span class="attribute">font-family</span>: <span class="string">&#x27;Lora&#x27;</span>;</span></span><br><span class="line"><span class="css">  ...</span></span><br><span class="line"><span class="css"></span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="step-7."><strong>STEP 7.</strong></h3>
<p>You will find example posts in your <code>/_posts/</code> directory. Go ahead and edit any post and re-build the site to see your changes, for github pages, this happens automatically with every commit. You can rebuild the site in many different ways, but the most common way is to run <code>jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>
<p>To add new posts, simply add a file in the <code>_posts</code> directory that follows the convention of <code>YYYY-MM-DD-name-of-post.md</code> and includes the necessary front matter. Take a look at any sample post to get an idea about how it works. If you already have a website built with Jekyll, simply copy over your posts to migrate to Adam Blog 2.0.</p>
<p>The front matter options for each post are:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">layout:</span> <span class="string">post</span> <span class="comment">#ensure this one stays like this</span></span><br><span class="line"><span class="attr">read_time:</span> <span class="literal">true</span> <span class="comment"># calculate and show read time based on number of words</span></span><br><span class="line"><span class="attr">show_date:</span> <span class="literal">true</span> <span class="comment"># show the date of the post</span></span><br><span class="line"><span class="attr">title:</span>  <span class="string">Your</span> <span class="string">Blog</span> <span class="string">Post</span> <span class="string">Title</span></span><br><span class="line"><span class="attr">date:</span>   <span class="string">XXXX-XX-XX</span> <span class="string">XX:XX:XX</span> <span class="string">XXXX</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&quot;The description of your blog post&quot;</span></span><br><span class="line"><span class="attr">img:</span> <span class="comment"># the path for the hero image, from the image folder (if the image is directly on the image folder, just the filename is needed)</span></span><br><span class="line"><span class="attr">tags:</span> [<span class="string">tags</span>, <span class="string">of</span>, <span class="string">your</span>, <span class="string">post</span>]</span><br><span class="line"><span class="attr">author:</span> <span class="string">Your</span> <span class="string">Name</span></span><br><span class="line"><span class="attr">github:</span> <span class="string">username/reponame/</span> <span class="comment"># set this to show a github button on the post</span></span><br><span class="line"><span class="attr">toc:</span> <span class="literal">yes</span> <span class="comment"># leave empty or erase for no table of contents</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
<p>Edit your blogpost using markdown. <a href="https://www.markdownguide.org/">Here is a good guide about how to use it.</a></p>
<h3 id="step-7.-1"><strong>STEP 7.</strong></h3>
<p>Delete images inside of <code>/assets/img/posts/</code> and upload your own images for your posts.</p>
<h3 id="step-8."><strong>STEP 8.</strong></h3>
<p>Make sure Github Pages are turned on in the repository settings, and pointing to the main or master branch (where you cloned this repo).</p>
<h2 id="additional-documentation">Additional documentation</h2>
<h3 id="directory-structure">Directory Structure</h3>
<p>If you are familiar with Jekyll, then the Adam Blog 2.0 directory structure shouldn't be too difficult to navigate. The following some highlights of the differences you might notice between the default directory structure. More information on what these folders and files do can be found in the <a href="https://jekyllrb.com/docs/structure/">Jekyll documentation site</a>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Adam Blog 2.0/</span><br><span class="line">├── _includes                  <span class="comment"># Theme includes</span></span><br><span class="line">├── _layouts                   <span class="comment"># Theme layouts (see below for details)</span></span><br><span class="line">├── _posts                     <span class="comment"># Where all your posts will go</span></span><br><span class="line">├── assets                     <span class="comment"># Style sheets and images are found here</span></span><br><span class="line">|  ├── css                     <span class="comment"># Style sheets go here</span></span><br><span class="line">|  |  └── _sass                <span class="comment"># Folder containing SCSS files</span></span><br><span class="line">|  |  └── main.css             <span class="comment"># Main SCSS file</span></span><br><span class="line">|  |  └── highlighter          <span class="comment"># Style sheet for code syntax highlighting</span></span><br><span class="line">|  └── img                     <span class="comment"># </span></span><br><span class="line">|     └── posts                <span class="comment"># Images go here</span></span><br><span class="line">├── _pages                     <span class="comment"># Website pages (that are not posts)</span></span><br><span class="line">├── _config.yml                <span class="comment"># Site settings</span></span><br><span class="line">├── Gemfile                    <span class="comment"># Ruby Gemfile for managing Jekyll plugins</span></span><br><span class="line">├── index.html                 <span class="comment"># Home page</span></span><br><span class="line">├── LICENSE.md                 <span class="comment"># License for this theme</span></span><br><span class="line">├── README.md                  <span class="comment"># Includes all of the documentation for this theme</span></span><br><span class="line">├── feed.xml                   <span class="comment"># Generates atom file which Jekyll points to</span></span><br><span class="line">├── 404.html                   <span class="comment"># custom and responsive 404 page</span></span><br><span class="line">├── all-posts.json             <span class="comment"># database of all posts used for infinite scroll</span></span><br><span class="line">├── ipfs-404.html              <span class="comment"># 404 page for IPFS</span></span><br><span class="line">├── posts-by-tag.json          <span class="comment"># database of posts by tag</span></span><br><span class="line">├── robots.txt                 <span class="comment"># SEO crawlers exclusion file</span></span><br><span class="line">├── search.json                <span class="comment"># database of posts used for search</span></span><br><span class="line">└── sitemap.xml                <span class="comment"># automatically generated sitemap for search engines</span></span><br></pre></td></tr></table></figure>
<h3 id="starting-from-scratch">Starting From Scratch</h3>
<p>To completely start from scratch, simply delete all the files in the <code>_posts</code>, <code>assets/img/posts</code> folders, and add your own content. Everything in the <code>_config.yml</code> file can be edited to suit your needs. Also change the <code>favicon.ico</code> file to your own favicon.</p>
<h3 id="click-to-tweet">Click to tweet</h3>
<p>If you have a tweetable quote in your blog post and wish to feature it as a click to tweet block, you just have to use the <code>&lt;tweet&gt;&lt;/tweet&gt;</code> tags, everything between them will be converted in a click to tweet box.</p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/ctt-markdown.png?raw=true"></p>
<p><img width="640px" src="https://github.com/the-mvm/the-mvm.github.io/blob/main/assets/img/template_screenshots/ctt-render.png?raw=true"></p>
<h3 id="google-analytics">Google Analytics</h3>
<p>It is possible to track your site statistics through <a href="https://www.google.com/analytics/">Google Analytics</a>. Similar to Disqus, you will have to create an account for Google Analytics, and enter the correct Google ID for your site under <code>google-ID</code> in the <code>_config.yml</code> file. More information on <a href="https://michaelsoolee.com/google-analytics-jekyll/">how to set up Google Analytics</a>.</p>
<h3 id="atom-feed">Atom Feed</h3>
<p>Atom is supported by default through <a href="https://github.com/jekyll/jekyll-feed">jekyll-feed</a>. With jekyll-feed, you can set configuration variables such as 'title', 'description', and 'author', in the <code>_config.yml</code> file.</p>
<p>Your atom feed file will be live at <code>https://your.site/feed.xml</code> <a href="https://the-mvm.github.io/feed.xml">example</a>.</p>
<h3 id="social-media-icons">Social Media Icons</h3>
<p>All social media icons are courtesy of <a href="http://fontawesome.io/">Font Awesome</a>. You can change which icons appear, as well as the account that they link to, in the <code>_config.yml</code> file.</p>
<h3 id="mathjax">MathJax</h3>
<p>Adam Blog 2.0 comes out of the box with <a href="https://www.mathjax.org/">MathJax</a>, which allows you to display mathematical equations in your posts through the use of <a href="http://www.andy-roberts.net/writing/latex/mathematics_1">LaTeX</a>. Just add <code>Mathjax: yes</code> in the frontmatter of your post.</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">p</span> <span class="attr">style</span>=<span class="string">&quot;text-align:center&quot;</span>&gt;</span></span></span><br><span class="line">\(\theta<span class="emphasis">_&#123;t+1&#125; = \theta_</span>&#123;t&#125; - \dfrac&#123;\eta&#125;&#123;\sqrt&#123;\hat&#123;v&#125;<span class="emphasis">_t&#125; + \epsilon&#125; \hat&#123;m&#125;_</span>t\).</span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<figure>
<img src="../../../assets/img/template_screenshots/MathjaxRendered.jpg" alt="rendered mathjax" /><figcaption aria-hidden="true">rendered mathjax</figcaption>
</figure>
<h3 id="syntax-highlighting">Syntax Highlighting</h3>
<p>Adam Blog 2.0 provides syntax highlighting through <a href="https://help.github.com/articles/creating-and-highlighting-code-blocks/">fenced code blocks</a>. Syntax highlighting allows you to display source code in different colors and fonts depending on what programming language is being displayed. You can find the full list of supported programming languages <a href="https://github.com/jneen/rouge/wiki/List-of-supported-languages-and-lexers">here</a>. Another option is to embed your code through <a href="https://en.support.wordpress.com/gist/">Gist</a>.</p>
<p>You can choose the color theme for the syntax highlight in the <code>_config.yml</code> file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">highlight_theme:</span> <span class="string">syntax-base16.monokai.dark</span> <span class="comment"># select a theme for the code highlighter</span></span><br></pre></td></tr></table></figure>
<p>See the <a href="https://github.com/the-mvm/the-mvm.github.io/tree/main/assets/css/highlighter">highlighter directory</a> for reference on the options.</p>
<h3 id="markdown">Markdown</h3>
<p>Jekyll offers support for GitHub Flavored Markdown, which allows you to format your posts using the <a href="https://guides.github.com/features/mastering-markdown/">Markdown syntax</a>.</p>
<h2 id="everything-else">Everything Else</h2>
<p>Check out the <a href="http://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll's GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>
<h2 id="contributing">Contributing</h2>
<p>If you would like to make a feature request, or report a bug or typo in the documentation, then please <a href="https://github.com/the-mvm/the-mvm.github.io/issues/new">submit a GitHub issue</a>. If you would like to make a contribution, then feel free to <a href="https://help.github.com/articles/about-pull-requests/">submit a pull request</a> - as a bonus, I will credit all contributors below! If this is your first pull request, it may be helpful to read up on the <a href="https://guides.github.com/introduction/flow/">GitHub Flow</a> first.</p>
<p>Adam Blog 2.0 has been designed as a base for users to customize and fit to their own unique needs. Please keep this in mind when requesting features and/or submitting pull requests. Some examples of changes that I would love to see are things that would make the site easier to use, or better ways of doing things. Please avoid changes that do not benefit the majority of users.</p>
<h2 id="questions">Questions?</h2>
<p>This theme is completely free and open source software. You may use it however you want, as it is distributed under the <a href="http://choosealicense.com/licenses/mit/">MIT License</a>. If you are having any problems, any questions or suggestions, feel free to <a href="https://github.com/the-mvm/the-mvm.github.io/issues/new">file a GitHub issue</a>.</p>
]]></content>
  </entry>
  <entry>
    <title>LeetCode</title>
    <url>/2022/02/27/LeetCode/</url>
    <content><![CDATA[<h5 id="最小栈">最小栈</h5>
<ul>
<li>要求pop(),push(),top(),min()操作均为O(1)。</li>
<li>思路：
<ul>
<li>利用一个辅助栈，专门记录最小值的变化。
<ul>
<li>在push进行的时候，比较栈顶与输入的大小关系，如果小于栈顶元素，则最小值发生变化，不然不会发生变化。</li>
<li>在pop的时候，如果pop的元素正好与辅助栈的栈顶相同，那么，就在辅助栈也进行pop。</li>
</ul></li>
<li>主栈按照正常栈的函数进行push()、pop()、top()。</li>
</ul></li>
<li>为什么是对的?
<ul>
<li>辅助栈记录了到目前为止的栈中元素的最小值，因此栈顶元素一定是min()的正确返回值。</li>
</ul></li>
</ul>
<span id="more"></span>
<h5 id="双栈实现队列">双栈实现队列</h5>
<ul>
<li>要求实现队列的头部删除以及尾部插入，O(1)。</li>
<li>思路：
<ul>
<li>一个栈只进行删除，一个栈只进行插入。</li>
<li>插入栈不必理会删除栈的情况。</li>
<li>删除栈在非空的情况下不必理会插入栈的情况，如果为空，则需要插入栈中的元素倾倒进来。
<ul>
<li>为什么？：保持输入元素的<strong>先后次序</strong>。插入栈中的元素一定是比删除栈后输入的，如果在删除栈非空的情况下也倒入，那么，进行头部删除的结果就是错误的了。</li>
</ul></li>
</ul></li>
</ul>
<h5 id="数组中的重复数字">数组中的重复数字</h5>
<ul>
<li>用 hashmap， c++ -&gt; unordered_map&lt;..,..&gt;使查找时间O(1)</li>
</ul>
<h5 id="二维数组递增-旋转转为二叉搜索树">二维数组递增-&gt;旋转转为二叉搜索树</h5>
<ul>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202231700060.png" alt="image-20220223170056962" /><figcaption aria-hidden="true">image-20220223170056962</figcaption>
</figure></li>
<li><p>由此一来就可以类似于二叉搜索树，根据大小关系单向遍历。</p></li>
</ul>
<h5 id="方向打印链表">方向打印链表</h5>
<ul>
<li>用一个栈中转即可。</li>
</ul>
<h5 id="二叉树前序中序遍历构建树">二叉树前序中序遍历构建树</h5>
<ul>
<li><p>首先在前序遍历序列中确定根节点，再在中序遍历序列中找到根节点的序号，划分其左子树以及右子树。</p></li>
<li><p>再通过左子树以及右子树返回到前序遍历序列中去寻找根节点。</p></li>
<li><p>分治思想! 对于划分后的左右子树，仍然可以通过调用该过程进行左右子树的划分。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202232249708.png" alt="image-20220223224937641" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202232254040.png" alt="image-20220223225415976" style="zoom: 50%;" /></p></li>
</ul>
<h5 id="旋转数组的最小数问题">旋转数组的最小数问题</h5>
<ul>
<li>对于一个已经排序的数组的查找问题,应该首先考虑使用 <strong>二分法</strong> 解决，其可将 <strong>遍历法</strong> 的 <strong>线性级别</strong> 时间复杂度降低至 <strong>对数级别</strong> 。</li>
<li>对于该问题，我们考虑的是比较二分点跟尾部点的大小关系，假设数组在index为i-&gt;j之间有值，那么二分点=(i+j)/2:
<ul>
<li>如果array[(i+j)/2] &gt; array[j],那么array[(i+j)/2]一定在左排序块当中,旋转点就在[mid+1,j]之间，此时应该执行i = mid + 1；</li>
<li>如果array[(i+j)/2] &lt; array[j],那么array[(i+j)/2]一定在右排序块当中,旋转点就在[i,(i+j)/2]之间，此时应该执行j = mid；；</li>
<li>如果array[(i+j)/2] = array[j],此时应该执行j -= 1；</li>
</ul></li>
</ul>
<h5 id="矩阵中的路径问题">矩阵中的路径问题</h5>
<ul>
<li><p>是典型的矩阵搜索问题，考虑用<strong>深度搜索</strong>加<strong>剪枝处理</strong>。</p></li>
<li><p><strong>剪枝：</strong> 在搜索中，遇到 <code>这条路不可能和目标字符串匹配成功</code> 的情况（<em>例如：此矩阵元素和目标字符不同、此元素已被访问）</em>，则应立即返回，称之为 <code>可行性剪枝</code> 。</p></li>
<li><p>class Solution { public: bool exist(vector&lt;vector<char>&gt;&amp; board, string word) { for (int i = 0 ; i &lt; board.size(); ++ i) { for (int j = 0 ; j &lt; board[0].size() ; ++ j) { if(dfs(board, word, i, j, 0)) return true; } } return false; }</p>
<p>private: bool dfs(vector&lt;vector<char>&gt;&amp; board, string word, int i,int j, int word_index){ if (i &gt;= board.size() || j &gt;= board[0].size() ) return false; if (word[word_index] != board[i][j]) return false; if (word_index == word.size() - 1) return true; board[i][j] = '\0'; // 不让再返回到已经检查过的节点了 bool ret = dfs(board, word, i + 1, j, word_index + 1) || dfs(board, word, i - 1, j, word_index + 1) || dfs(board, word, i , j - 1, word_index + 1) || dfs(board, word, i , j + 1, word_index + 1); // 往四个方向搜索 board[i][j] = word[word_index]; return ret; } };</p></li>
</ul>
<h5 id="机器人可移动路径">机器人可移动路径</h5>
<ul>
<li><p>是一个搜索加回溯的题目。</p>
<ul>
<li>思路与上一题是一样的，利用矩阵dfs然后进行可达性分析并剪枝即可。</li>
<li>注意的一点就是循环有时候用递归会方便而且显然。</li>
</ul></li>
<li><p>可达解分析： 根据数位和增量公式得知，数位和每逢 进位 突变一次。根据此特点，矩阵中 满足数位和的解 构成的几何形状形如多个 等腰直角三角形 ，每个三角形的直角顶点位于 0, 10, 20, ...0,10,20,... 等数位和突变的矩阵索引处 。</p>
<p>三角形内的解虽然都满足数位和要求，但由于机器人每步只能走一个单元格，而三角形间不一定是连通的，因此机器人不一定能到达，称之为 不可达解 ；同理，可到达的解称为 可达解 （本题求此解）</p></li>
</ul>
<h5 id="剪绳子">剪绳子</h5>
<ul>
<li><p>将一根绳子剪成几段，使绳子长度乘积最大。</p></li>
<li><p>一个想法是通过算术几何均值不等式,使绳子剪成相等长度的若干段。</p>
<ul>
<li>基于这种想法，我们可以通过数学证明最优的绳子长度为3。
<ul>
<li><span class="math inline">\(L(m)=(\frac{n}{m})^m\)</span></li>
<li>求导，<span class="math inline">\(m (\frac{n}{m})^{m-1} (-n) \frac{1}{m^2} = 0\)</span>
<ul>
<li>取对数, <span class="math inline">\(\ln m + (m-1) (\ln n - \ln m) + \ln(-n) -2 \ln m = 0\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>另一个想法是最优的绳子长度为3.</p>
<ul>
<li>尽可能将绳子以长度 3 等分为多段时，乘积最大</li>
<li>即将x = 3a + b，并对b进行分类讨论。</li>
</ul></li>
<li><p>int cuttingRope(int n) { int b = n % 3; int a = n / 3; if (n &lt;= 3) { return n - 1; } if (b == 0) { return pow(3,a); } else if (b == 1) { return (pow(3,a-1)) * 4; } else { return 2 * pow(3,a); } }</p></li>
</ul>
<h5 id="剪绳子2">剪绳子2</h5>
<ul>
<li><p>在剪绳子的基础上，要把结果对1e9+7进行取模。</p></li>
<li><p>就是一个大数取模的问题:</p>
<ul>
<li>当 <em>a</em> 增大时，最后返回的 3^a 大小以指数级别增长，可能超出 <code>int32</code> 甚至 <code>int64</code> 的取值范围，导致返回值错误</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202242242915.png" title="fig:" alt="image-20220224224245848" /></li>
</ul></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202242252908.png" alt="image-20220224225241864" /><figcaption aria-hidden="true">image-20220224225241864</figcaption>
</figure></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202271800513.png" alt="image-20220224225258269" /><figcaption aria-hidden="true">image-20220224225258269</figcaption>
</figure></li>
<li><p>大数不能当参数</p></li>
</ul>
<h5 id="斐波那契数列">斐波那契数列</h5>
<ul>
<li>可以考虑动态规划把递推式子演绎出来。</li>
<li>一般不是明写x^a,就用循环求余</li>
</ul>
<h5 id="青蛙跳台阶">青蛙跳台阶</h5>
<ul>
<li>求多少种可能性的问题一般都有递推性质.</li>
<li>青蛙跳台阶问题与斐波那契数列等价。</li>
</ul>
<h5 id="汉明重量二进制中1的个数">汉明重量(二进制中1的个数)</h5>
<ul>
<li>逐位判断是否为1 / 利用 n &amp; (n-1) 消去最后的1，判断是否为0</li>
</ul>
<h5 id="树的子结构">树的子结构</h5>
<ul>
<li><p>递归</p></li>
<li><p>先序遍历找根节点，判断以该节点为根的子树术后结构与值完全相同。</p></li>
<li><p>树的问题很容易可以递归到左子树、右子树进行相同的操作，递归到子树为NULL时需要留意判定。</p></li>
<li><p>对于两个输入A、B是否为空的判断可以直接用A and B进行处理。</p></li>
<li><p>思路:</p>
<ul>
<li>把对A的子结构判定问题转为判定左子树中有无与B相同的子结构、右子树中有无与B相同的子结构、原树是否与B相同。</li>
<li>而判断两棵树是否相同，我们又可以用递归，将问题转为，当前值相不相等，左子树相不相等，右子树相不相等。</li>
</ul></li>
</ul>
<h5 id="合并两个排序的链表">合并两个排序的链表</h5>
<ul>
<li><p>递归</p></li>
<li><p>递归的核心想法我认为就是把自己正在实现的这一个函数看成是一个功能的封装。</p>
<ul>
<li>在函数实现的过程中，直接调用自己，将其视为可以完成已定的任务。</li>
</ul></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202203011848322.png" alt="image-20220301184810237" /><figcaption aria-hidden="true">image-20220301184810237</figcaption>
</figure></li>
<li><p>某链表为空之后，返回另一个，其他并没有难点。</p></li>
</ul>
<h5 id="翻转二叉树">翻转二叉树</h5>
<ul>
<li>看树易知又是一道递归的料。</li>
<li>判断终结条件，左子树，右子树即可。</li>
</ul>
<h5 id="对称的二叉树">对称的二叉树</h5>
<ul>
<li><p>我一看，又是递归二叉树，只是这一次比较相等的是root-&gt;left,root-&gt;right还有left-&gt;left,right-&gt;right</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202203011924469.png" alt="image-20220301192412414" style="zoom:80%;" /></p></li>
</ul>
<h5 id="顺时针打印矩阵">顺时针打印矩阵</h5>
<ul>
<li>每次都打印第一行，然后删除第一行。再将剩下的矩阵进行逆时针旋转90度即可。</li>
<li>这样就构成了一个可递归或者循环的算法。</li>
</ul>
<h5 id="栈的压入弹出序列">栈的压入、弹出序列</h5>
<ul>
<li>题意为判断弹出序列是不是压入序列的一种pop方案。</li>
<li>我们只需要利用一个辅助栈，循环判断栈顶元素与pop序列的元素是否相等即可，相等就pop并增进pop序列，反之，push。</li>
</ul>
<h5 id="从上到下打印二叉树-ii">从上到下打印二叉树 II</h5>
<ul>
<li>大概就是二叉树的层序遍历，思路是用双端队列实现BFS。</li>
</ul>
]]></content>
      <categories>
        <category>Problem Sets Of Algorithm</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop Spark and Storm</title>
    <url>/2022/02/27/HadoopSharpStorm/</url>
    <content><![CDATA[<h4 id="关于hadoop">关于Hadoop</h4>
<ul>
<li><p>Hadoop现阶段主要用于数据存储，因为它是批处理的，因此，Hadoop的MapReduce一次只能处理一个作业。用HDFS磁盘进行存储。对于设备的要求较低。</p></li>
<li><p>Hadoop分为一个分布式的文件系统HDFS、一个分布式的计算框架MapReduce以及一个实时分布式数据库HBase.</p>
<ul>
<li>HDFS是由NameNode(主节点)、DataNode(副节点)以及Client(客户机)组成的。
<ul>
<li>NameNode是用于存储文件信息、文件块信息以及文件块在DataNode的信息</li>
<li>DataNode保存了Block的元数据Meta-data,并周期性地把所有Block信息发给NameNode</li>
</ul></li>
<li>HDFS的读写流程:
<ul>
<li>用户向Client客户机提出请求，然后由Client客户机将数据进行分块，然后将分块的方案传回给NameNode,NameNode查询各个块的地址传给DataNode并按照距离远近进行排序，然后DataNode对数据进行写入或者读取操作，完成后传信号给NameNode，由其进行善后保存。</li>
<li>读取操作也是类似的命令传递流程:Client-(order)-&gt;NameNode-(address)-&gt;DataNode(Client从最近的几个DataNode中下载数据)</li>
</ul></li>
</ul>
<p><span id="more"></span></p>
<ul>
<li><p>MapReduce(面向磁盘)原理:</p>
<ul>
<li>主要分为Map以及Reduce两个步骤:
<ul>
<li>接收到计算任务的时候，会先对计算任务进行拆分，分配到不同的DataNode当中执行，生成中间文件。</li>
<li>中间文件作为Reduce的输入，Reduce将多个Map的输出汇总到一起进行输出。</li>
<li>Map到Reduce之间的步骤称为Shuffling.Shuffling将相同的输入数据进行复制合并，再分别一起传给Reduce专门的一个处理模块.
<ul>
<li>具体来说，是利用了key-value键值对中key的哈希值，对Reducetask个数进行取余，按照余数去放置data</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>而为了实现任务调度以及管理,会需要一个主Node JobTracker以及几个TaskTracker，TaskTracker必须运行在DataNode上，负责执行任务。</p></li>
<li><p>Hadoop搭建流程:</p>
<ul>
<li>关闭防火墙-&gt;关闭SELINUX-&gt;修改主机名-&gt;ssh无密码拷贝-&gt;设置主机名与ip对应-&gt;jdk1.8-&gt;下载Hadoop .jar包-&gt;配置核心文件-&gt;格式化NameNode-&gt;启动</li>
</ul></li>
<li><p>Hadoop是一个能够<strong>对大量数据进行分布式处理</strong>的软件框架。以一种<strong>可靠、高效、可伸缩</strong>的方式进行数据处理,在广义上<strong>指一个生态圈</strong>，泛指<strong>大数据技术相关的开源组件或产品</strong>。</p></li>
<li><p>Hadoop版本：</p>
<ul>
<li>Apache社区版：开源免费，非商业，有兼容性问题</li>
<li>Cloudera:开源免费，商业and非商业，解决兼容性</li>
<li>Hortonworks版本:开源免费，商业and非商业,二次开发，功能更强</li>
</ul></li>
<li><p>Hadoop 1.0 由分布式存储系统HDFS和分布式计算框架MapReduce组成,容易导致单点故障，拓展性差，性能低，支持编程模型单一。</p></li>
<li><p>Hadoop 2.0 引入了Yarn、HDFS快照、append操作，解决了NameNode单点故障问题,支持了Windows操作系统</p></li>
<li><p>Hadoop3.0 是直接基于 JDK1.8 发布的一个新版本,引入了HDFS可擦除编码、多NameNode、MR Native Task优化、Yarn的内存隔离</p></li>
<li><p>Hadoop常见端口号:</p>
<ul>
<li><strong>dfs.namenode.http-address:50070</strong> <strong>dfs.datanode.http-address:50075</strong> <strong>SecondaryNameNode：50090</strong> dfs.datanode.address:50010 fs.defaultFS:8020 或者9000 yarn.resourcemanager.webapp.address:8088 历史服务器web访问端口：19888</li>
</ul></li>
<li><p>Hadoop压缩方式:</p>
<ul>
<li>Snappy,速度较快但不能切分。</li>
</ul></li>
<li><p>Hadoop数据倾斜(也就是大量数据汇集到一个ReduceTaskBlock当中):</p>
<ul>
<li>对于一般情况，我们可以对key先加上1-n的随机前缀，进行map-reduce局部聚合,再去掉随机前缀进行全局聚合。</li>
</ul></li>
</ul></li>
</ul>
<h4 id="关于spark">关于Spark</h4>
<ul>
<li><p>Spark是数据并行的计算框架，在不同的短时间间隔内进行连续的批处理。但是spark没有自己的分布式存储系统。因此，Hadoop与Spark有一种互补的意味。Spark主要是<strong>利用内存</strong>(<strong>面向内存</strong>)进行存储。</p></li>
<li><p>Spark利用RDD组成DAG，并把RDD的中间运算结果存放在内存当中，延迟小。</p>
<ul>
<li>RDD是弹性分布式数据集,代表一个不可变、可分区、可并行计算 的元素集合。</li>
</ul></li>
<li><p>并且Spark中的TASK以<strong>线程</strong>的方式进行维护，启动更快(<strong>Hadoop</strong>是以<strong>进程</strong>的方式)。</p></li>
<li><p>Spark针对的就是Hadoop计算缓慢的实时计算、迭代计算、交互式数据查询</p></li>
<li><p>特点:</p>
<ul>
<li>快</li>
<li>易用且通用</li>
<li>兼容性更好,可以处理hadoop计算的数据</li>
</ul></li>
<li><p>Narrow Dependencies :</p>
<ul>
<li>父RDD的一个分区只会被子RDD的一个分区依赖</li>
</ul></li>
<li><p>Wide Dependencies :</p>
<ul>
<li>父RDD的一个分区会被子RDD的多个分区依赖</li>
</ul></li>
<li><p>Stage的划分:</p>
<ul>
<li>根据RDD之间依赖关系的不同将Job划分为不同的Stage,遇到一个Wide Dependencies 就把它划分为一个Stage。</li>
<li>Stage是一个TaskSet，根据分区数划分成一个个的Task。</li>
</ul></li>
<li><p>常用的算子:</p>
<ul>
<li>transformation:
<ul>
<li>map,filter,flatMap,...</li>
</ul></li>
<li>action:
<ul>
<li>reduce,first,take...</li>
</ul></li>
<li>会引起Shuffle过程的Spark算子:
<ul>
<li>reduceByKey(shuffle之前combine,推荐使用),GroupByKey(直接shuffle),...</li>
</ul></li>
</ul></li>
<li><p>调优:</p>
<ul>
<li><p>num-executors,executor-memory,executor-cores,driver-memory</p></li>
<li><p>避免创建重复的RDD,尽可能复用同一个RDD;尽量避免使用shuffle类算子;</p></li>
<li><p>使用高性能的算子,example:</p>
<p>①使用reduceByKey/aggregateByKey替代groupByKey</p>
<p>②使用mapPartitions替代普通map</p></li>
</ul></li>
<li><p>作业提交流程:</p>
<ul>
<li><p>YarnClient<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202281130098.png" alt="img" /></p></li>
<li><p>在YARN Client模式下，Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster，随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存。</p>
<p>​ ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程，Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，之后执行到Action/transformation<a href="https://so.csdn.net/so/search?q=算子&amp;spm=1001.2101.3001.7020">算子</a>时，触发一个job，并根据宽依赖开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。</p></li>
<li><p>YarnCluster</p>
<figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202282143604.png" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>YarnCluster与YarnClient主要区别在于Driver一个放在了AM中进行，而另一个放在本地运行。</p></li>
</ul></li>
<li><p>Repartition和Coalesce :</p>
<ul>
<li>两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法,repartition<strong>一定会发生shuffle</strong>,coalesce方法<strong>不一定</strong>。</li>
<li>一般情况下<strong>增大rdd</strong>的partition数量使用<strong>repartition</strong>，<strong>减少partition</strong>数量时使用<strong>coalesce</strong>。</li>
</ul></li>
<li><p>Spark中的cache,persist(这两者都是<strong>内存机制</strong>),checkpoint:</p>
<ul>
<li>Persist 和 Cache将数据保存在<strong>内存</strong>，Checkpoint将<strong>数据保存在HDFS</strong></li>
<li>Persist 和 Cache 程序结束后<strong>会被清除或手动调用unpersist方法</strong>,Checkpoint永久存储<strong>不会被删除</strong>。</li>
<li>Persist 和 Cache,<strong>不会丢掉</strong>RDD间的<strong>依赖链/依赖关系</strong>，<strong>CheckPoint会斩断</strong>依赖链。</li>
</ul></li>
<li><p>Spark中共享变量的作用:</p>
<ul>
<li>累加器:原理与MapReduce类似，先进行分布式的改变，然后进行聚合。</li>
<li>广播变量:在每个机器上缓存一份，<strong>不可变，只读的，相同</strong>的变量，<strong>该节点每个任务都能访问</strong>，起到<strong>节省资源和优化</strong>的作用。</li>
</ul></li>
<li><p>Spark减少数据库连接数:</p>
<ul>
<li>使用foreachPartition代替foreach，在foreachPartition内获取数据库的连接。</li>
</ul></li>
</ul>
<h4 id="关于storm">关于Storm</h4>
<ul>
<li><p>storm 不处理静态数据,但它<strong>处理连续的流数据</strong>,特别适合实时数据,而Hadoop主要是离线计算。storm数据也保存在内存当中，且数据通过网络传播，编程方面与Hadoop类似。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202282202276.png" alt="image-20220228220250227" style="zoom:67%;" /></p></li>
<li><p>Storm的整体结构与Hadoop是类似的,相关调度信息都保存在Zookeeper集群当中。</p>
<p>如下图所示:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202282205672.png" alt="image-20220228220520536" style="zoom:50%;" /></p></li>
<li><p>各个结点的工作:</p>
<ul>
<li>Nimbus:<strong>分发用户代码</strong>，指派给具体的Supervisor节点上的<strong>Worker节点</strong>，去<strong>运行Topology对应的组件</strong>（Spout/Bolt）的Task</li>
<li>Supervisor:负责管理运行<strong>在Supervisor节点上</strong>的<strong>每一个Worker进程的启动和终止</strong>。通过端口号进行识别。</li>
<li>ZooKeeper是<strong>用来协调Nimbus以及Supervisor</strong>,如果Supervisor因故障出现问题而无法运行Topology，Nimbus会第一时间感知到，并重新分配Topology到其它可用的Supervisor上运行。storm<strong>所有的元数据信息</strong>保存在Zookeeper中</li>
<li>Topology：Storm中运行的一个实时应用程序的名称。<strong>将 Spout、 Bolt整合起来的拓扑图</strong>。定义了 Spout和 Bolt的结合关系、并发数量、配置等等。</li>
<li>Worker只有两个任务:Spout或者是Bolt</li>
<li>Worker中每一个spout/bolt的<strong>线程</strong>称为一个Task,executor是1个<strong>被worker进程启动的单独线程</strong>。<strong>每个executor只会运行1个topology的1个component(spout或bolt)的task</strong>（注：<strong>task可以是1个或多个</strong>，storm默认是1个component只生成1个task)。 Worker-&gt;executor-&gt;task。
<ul>
<li>通过调整worker、executor、task的数量也可以提高并发度。</li>
</ul></li>
</ul></li>
<li><p>运行机制:</p>
<ul>
<li><p>数据源从Spout开始，始终以tuple的形式传递给不同的Bolt,如下图:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202202282215393.png" alt="image-20220228221551311" style="zoom:80%;" /></p></li>
<li><p>Spout:在一个topology中获取源数据流的组件。通常情况下spout会从外部数据源中读取数据，然后转换为topology内部的源数据。</p></li>
<li><p>Bolt：接受数据然后<strong>执行处理的组件</strong>,换句话说，就是做相关运算的组件。</p></li>
<li><p>Stream:表示<strong>数据传递的走向</strong>。</p></li>
</ul></li>
<li><p>在Hadoop中，MapReduce任务<strong>最终会执行完成后结束</strong>；而<strong>在Storm中</strong>，<strong>Topology任务一旦提交后永远不会结束</strong>，除非你<strong>显式地去停止</strong>任务。</p></li>
<li><p>Storm Streaming Grouping的种类:</p>
<ul>
<li><strong>Shuffle Grouping :随机分组</strong>，尽量均匀地分配给Bolt</li>
<li><strong>Field Grouping:按字段分组</strong>，按数据中field值进行分组；相同field值的Tuple被发送到相同的Task这种grouping机制保证相同field值的tuple会去同一个task，这对于<strong>WordCount</strong>来说非常关键，如果<strong>同一个单词不去同一个task，那么统计出来的单词次数就不对了</strong>。</li>
<li><strong>All grouping</strong> ：广播，意思是<strong>每一个tuple数据对应于一个bolt</strong></li>
<li><strong>Global grouping</strong>:Tuple被分配到一个Bolt中的一个Task,Stream中的所有的tuple都会<strong>发送给同一个bolt任务处理</strong></li>
<li><strong>None grouping ：</strong>不分组，主要 用于不需要关注并行处理或者负载均衡的情况下。</li>
</ul></li>
<li><p>Spout的可靠性:</p>
<ul>
<li>Spout可以记录它发送的tuple,在发生故障时，可以保证发送相同的tuple。</li>
<li>这同时也隐含了Bolt的可靠性，也就是每一个Bolt都要在处理消息之后<strong>进行应答或者报错</strong>。</li>
<li>因此只有当每一个Bolt的回复都确认完毕的时候，spout才算是计算完了一条流</li>
</ul></li>
</ul>
<h5 id="stormsparkhadoop区别对比">Storm、Spark、Hadoop区别对比</h5>
<ul>
<li>Hadoop与Spark都是<strong>micro-batch</strong>处理的，数据注定是一批一批传递的。</li>
<li>不过Spark可以进行交互式计算、流计算、迭代计算.</li>
<li>而Storm是"<strong>native-stream</strong>"流式处理的，数据实时传递给计算单元再实时地传给数据存储单元。</li>
<li>Storm可以读写文件到HDFS,但是不能在Hadoop集群上运行。</li>
<li>当应用程序<strong>需要不到一秒的延迟</strong>而又<strong>不会丢失数据</strong>时，Storm是一个不错的选择。</li>
<li>Hadoop是一个集成性的平台(本地磁盘存储+离线计算)，而Spark只是一个分布式计算工具(内存+专门计算)，主要用于实时计算,Storm底层采用ZeroMQ，速度最快,主要是流式计算。</li>
<li>三者都是基于JVM实现的。</li>
</ul>
<h6 id="reference">Reference:</h6>
<p>[1]:<a href="https://jishuin.proginn.com/p/763bfbd2f819">Hadoop高频面试题(建议收藏)-技术圈 (proginn.com)</a></p>
]]></content>
      <categories>
        <category>Learn Hadoop Spark</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>ICS and OS 杂项知识点</title>
    <url>/2022/02/27/ICSOS%E8%A1%A5%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h5 id="进程与线程">进程与线程</h5>
<ul>
<li>进程是并发执行的程序在执行过程中分配和管理资源的基本单位。
<ul>
<li>各个进程之间<strong>有独立的地址空间</strong>,而<strong>线程没有</strong>。</li>
</ul></li>
<li>线程是进程的一个执行单元,多个线程共享一个进程中的资源。</li>
<li>协程是由程序员自己控制的，主要是用户态执行的单元。</li>
</ul>
<h5 id="cdn">CDN</h5>
<ul>
<li>CDN的全称是Content Delivery Network，即<a href="https://baike.baidu.com/item/内容分发网络/4034265">内容分发网络</a>。CDN是构建<strong>在现有网络基础之上的智能虚拟网络</strong>，依靠部署在各地的边缘服务器，通过<strong>中心平台的负载均衡、内容分发、调度等功能模块</strong>，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有<strong>内容存储和分发技术</strong>。</li>
<li>主要用于:
<ul>
<li>节省骨干网带宽，减少带宽需求量</li>
<li>提供服务器端加速，解决由于用户访问量大造成的服务器过载问题</li>
<li>降低“通信风暴”的影响，提高网络访问的稳定性</li>
</ul></li>
</ul>
<span id="more"></span>
]]></content>
      <categories>
        <category>Learn ICS and OS</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/2022/02/28/Redis/</url>
    <content><![CDATA[<h4 id="redis">Redis</h4>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/12/21/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>分布式架构</title>
    <url>/2022/02/27/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h3 id="分布式架构">分布式架构</h3>
<ul>
<li>基本内容:
<ul>
<li>分布式系统中的计算机不存在主从之分，可以任意分布。</li>
<li>并发访问导致对于并发性的处理至关重要</li>
<li>缺乏全局时钟</li>
<li>常常发生故障</li>
<li>分布式系统的请求会产生三态:成功、失败或者是延时。</li>
</ul></li>
<li><strong>CAP理论</strong>: 一个系统不可能同时满足一致性、可用性、分区容错性这三个性质，最多同时满足两个。
<ul>
<li><strong>一致性</strong>指的是一个系统在<strong>更新</strong>之后，系统的<strong>数据仍然处于一致</strong>的状态，亦即所有的用户都可以读取到最新的值。</li>
<li><strong>可用性</strong>指的是用户的<strong>每一个操作请求都可以在有限的时间内</strong>返回结果</li>
<li><strong>分区容错性</strong>指的是分布式系统<strong>遇到任何网络分区故障</strong>的时候，仍然需要能够<strong>保证对外提供满足一致性的可用性的服务</strong></li>
</ul></li>
<li><strong>BASE理论</strong>:BASE是指既然无法做到强一致性，那么我们可以让每个应用根据自身情况达成最终一致性。
<ul>
<li>这就涉及了基本可用以及弱状态这两个性质:
<ul>
<li><strong>基本可用</strong>指的是分布式系统在出现不可预知故障的时候，允许损失部分可用性,比如响应时间或者功能降级之类的。</li>
<li><strong>弱状态</strong>指的是允许存在达成一致性之前的中间状态。</li>
<li><strong>最终一致性</strong>指的是系统在一定时间的同步之后可以达成一致性。</li>
</ul></li>
</ul></li>
</ul>
<span id="more"></span>
<h5 id="复制模型">复制模型</h5>
<h6 id="同步">同步</h6>
<h6 id="异步">异步</h6>
]]></content>
      <categories>
        <category>Learn Distributed architecture</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络笔记</title>
    <url>/2022/01/02/NoteforNN/</url>
    <content><![CDATA[<h4 id="section">1</h4>
<p>What</p>
<p>​ 神经网络是一种<strong>模仿生物神经网络的结构、功能的数学模型</strong>，是一种自适应系统，具有学习功能，通过数据进行学习。<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<p>Why</p>
<p>​ 可以通过“学习”解决传统算法解决不了的问题<span class="math inline">\(\color{red}{(Key)}\)</span>。神经网络特别适合执行模式识别，用以识别语音、视觉和控制系统中的对象或信号并对其分类。它们还可以用于执行时序预测和建模。</p>
<span id="more"></span>
<p>与<strong>传统机器学习</strong>相比，神经网络的优势:<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<p>​ 1.<strong>特征提取的高效性</strong>:<strong>不需要做大量的特征工程</strong>，<strong>可以直接利用数据，让它自己训练</strong>，自我“修正”</p>
<p>​ 2.<strong>数据格式的简易性</strong>:<strong>传统机器学习分类问题</strong>中，需对数据进行<strong>如量纲的归一化</strong>，格式的转化等，<strong>在神经网络里不一定需要对数据做额外处理</strong></p>
<p>​ 3.<strong>参数数目的少量性</strong>:SVM：需要调整的参数有核函数、惩罚因子、松弛变量等，<strong>需要对背后理论知识的深入了解基本的三层神经网络(输入-隐含-输出)</strong>：<strong>只需初始化时给每一个神经元随机赋予一个权重w和偏置项b</strong>，对于调参的背后理论知识并不需要过于精通，<strong>需要的先验知识更少</strong>。</p>
<p>神经网络的目标:</p>
<p>​ 借助神经科学、脑科学与认知科学的研究成果，研究大脑信息表征、转换机理和学习规则，建立模拟大脑信息处理过程的智能计算模型，最终使机器掌握人类的认知规律<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<p>​ 首先，是为了弄清神经系统的运作机制</p>
<p>​ 其次，是在此基础上制造具有类似功能的信息处理系统</p>
<p>模拟人的智能行为，是技术系统或人工系统模拟生物系统的最高形式 使机器具有智能，是技术系统或人工系统模拟生物系统的最高目标</p>
<p>对脑的研究可以促进人工神经网络的研究,对人工神经网络的研究，也可以反过来促进对大脑的研究</p>
<p>神经网络的发展；</p>
<p>​ 对于具有单隐层、传递函数为sigmoid的连续型前馈神经网络可以以任意精度逼近任何复杂的连续映射</p>
<p>​ 多层结构可以使神经网络在理论上拟合任意函数</p>
<ul>
<li><strong>神经网络发展历史：</strong>
<ul>
<li>起源(1950s-1980s):
<ul>
<li>从传统线性回归过度到监督学习</li>
<li>从直接求解合适的平面去拟合点，到利用训练集(X是输入，Y是输出)和测试集去“学习”一个平面来拟合点。</li>
<li>《神经活动中所蕴含思想的逻辑活动》,1943心理学家McCulloch以及另一位数学家 Pitts:MP神经元</li>
<li>1949年，在《行为的组织》一书中心理学家Hebb对神经元之间连接强度的变化规则进行了分析，并基于此提出了著名的Hebb学习规则,受启发于巴浦洛夫的条件反射实验。</li>
<li>1974年，Werbos在他的博士论文里提出了用于神经网络学习的BP(Back Propagation)算法，才为多层神经网络的学习训练与实现提供了一种切实 可行的解决途径。</li>
<li>于1989年，Cybenko、Funahashi、Hornik等人相继对BP神经网络的非线 性函数逼近性能进行了分析，并证明了对于具有单隐层、传递函数为sigmoid的 连续型前馈神经网络可以以任意精度逼近任何复杂的连续映射</li>
<li>Broomhead和Lowe于1988年将径向基函数引入到了神经网络的设计中，形成了径向基神经网络RBF（ Radial basis functions）。后来，Jackson和Park分别于1989年和1991年对RBF在非线性连续函数上的一致逼近性能进行了论证</li>
</ul></li>
<li>神经网络的兴盛(1980s-2000s):
<ul>
<li>1989年在“Multilayer feedforward networks areuniversal approximators”一文中，作者给出了数学证明，即多层结构可以使神经网络在理论上拟合任意函数，当然，也包括异或（XOR）</li>
<li>YannLeCun和AT&amp;T Bell Labs中的其他研究者，将理论落在了实际问题中。他们利用多层神经网络和反传成功让计算机识别了手写邮政编码，发表了“Backpropagation Applied to HandwrittenZipCode Recognition”一文，奠定了现代神经网络学习的基础。除了反传的应用，他们提出对神经网络的改进：卷积（convolution）。卷积，通过“权值共享”大大加速了神经网络的学习过程。</li>
</ul></li>
<li>深度学习(2000s-2010s)</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201081032146.png" alt="image-20220108103214031" style="zoom:80%;" /></li>
</ul></li>
</ul>
<p>神经网络重要人物及团队：</p>
<p>​ 吴恩达，何恺明</p>
<p>​ 谷歌：Deep Mind，Google Brain</p>
<p>神经网络重要期刊：</p>
<p>​ <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201011909770.png" alt="image-20220101190937670" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201011910266.png" alt="image-20220101191003214" style="zoom:50%;" /></p>
<p>做什么研究：</p>
<p>​ 在理论研究和应用之间寻求平衡</p>
<p>​ 大部分针对实践的研究，都是在强调神经网络应用于特定任务后的优化问题</p>
<p>​ 理论研究一般是为了解释某种在实际应用中表现优异的方法是否在数学上具有解释性，用理论研究来指导优化现有的神经网络模型，破解“黑盒”效应</p>
<h4 id="section-1">2</h4>
<h5 id="神经元模型">神经元模型</h5>
<ul>
<li><p>生物神经元：由<strong>细胞体+树突+轴突</strong>（树突，轴突都是突触）构成</p></li>
<li><p>信息传递： <strong>树突-&gt;细胞体-&gt;轴突</strong></p></li>
</ul>
<h5 id="mp神经元">MP神经元</h5>
<ul>
<li><p>根据常规的神经元模型，构建出了一个可运算的模型。</p>
<p>​ <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201011947798.png" alt="image-20220101194738744" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201011948099.png" alt="image-20220101194803027" style="zoom:50%;" /></p></li>
<li><p>输出二值，大于阈值才会激活</p></li>
<li><p><strong>MP神经元</strong>简单的结构可以在一定程度上<strong>减少过拟合</strong>，并且具有<strong>很好的延展性</strong>，缺点在于<strong>没有学习</strong><span class="math inline">\(\color{red}{(Key)}\)</span>。<strong>感知机神经元</strong>修正了这一点。<span class="math inline">\(\color{red}{(Key)}\)</span> <strong>学习能力</strong>也就是<strong>自动调整权值</strong>的能力。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>常见的神经元结构数学模型：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201011958091.png" alt="image-20220101195838034" style="zoom:67%;" /></p></li>
</ul>
<h5 id="激活函数">激活函数</h5>
<ul>
<li><p>最初定义的阈值函数为</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012005249.png" alt="image-20220101200553195" style="zoom:50%;" /></p></li>
<li><p>但是这两个<strong>阈值函数并不连续</strong>，因此，后续设计了一些<strong>新的激活函数使输出值变为连续值</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>Sigmoid : <span class="math display">\[
  f(x) = \frac{1}{1 + \exp(-x)}
  \]</span> 可以将输出映射到(0,1)区间。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012008500.png" alt="image-20220101200800464" style="zoom:67%;" /></p></li>
<li><p>Sigmoid 存在的问题是：</p>
<ul>
<li><strong>输出恒定为正值，因此，随着层数增加，会产生累计偏差</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span></li>
<li>为了修正这一问题 ,诞生了<span class="math inline">\(Tanh\)</span></li>
</ul></li>
<li><p>Tanh函数:</p>
<ul>
<li><p><span class="math display">\[
  f(x) = \frac{2}{1+e^{-2x}} - 1
  \]</span></p></li>
<li><p>与sigmoid 不同的是，Tanh函数选择将输出限制在(-1,1)之间:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012012644.png" alt="image-20220101201258604" style="zoom:67%;" /></p></li>
</ul></li>
<li><p>但是Tanh函数以及Sigmoid函数<strong>都存在一个问题</strong>在于，当网络层数较多的时候，Tanh函数以及Sigmoid函数都会造成<strong>梯度消失</strong>，针对这一个问题，又设计了ReLu。<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li>为什么会梯度消失呢？ 梯度绝对值都小于1，使得最后的梯度会越来越趋向于0.</li>
</ul></li>
<li><p>ReLu函数<strong>只保留正数，并将负数清零，来缓解梯度消失</strong>问题。并且ReLu函数的<strong>收敛速度很快</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span> <span class="math display">\[
  f(x) = \max(0,x)
  \]</span> <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012013643.png" alt="image-20220101201312599" style="zoom:67%;" /></p></li>
<li><p>但是,ReLu也有其缺点，在于会出现<strong>神经元坏死</strong>的问题:某些神经元可能<strong>永远不会被激活</strong>，导致相应<strong>参数永远不会被更新</strong>。造成这一问题的原因一般是参数初始化问题或者learning rate太高。</p>
<ul>
<li>可以通过将函数修正为 <span class="math display">\[
  f(x) = \max(0.1x,x)
  \]</span> 解决。</li>
</ul></li>
</ul>
<h5 id="新的神经元结构">新的神经元结构</h5>
<p>为了提升神经元的表达能力，设计了一些新的神经元结构：</p>
<ul>
<li><p>乘法神经元：用累乘代替原来的累加，使<strong>拟合多项式分布的能力更好</strong>，时间序列预测效果更好，<strong>延展性差</strong></p></li>
<li><p>IC神经元：<strong>提升网络性能与非线性能力</strong>，基于物理启发，<strong>容易过拟合</strong>。</p></li>
<li><p>感知机神经元<span class="math inline">\(\color{red}{(Key)}\)</span>： <span class="math display">\[
  f(x) = sgn(w\cdot x + b)
  \]</span></p>
<ul>
<li><strong>这就是感知机</strong>。</li>
<li>也就是说，<strong>感知机</strong>就是采<strong>用sgn函数作为激活函数</strong>的<strong>MP神经元。</strong></li>
</ul></li>
<li><p>其中w,b为感知机模型参数，<strong>一个感知机由这两个参数确定</strong>。</p></li>
<li><p>感知机的运行过程就是寻找<span class="math inline">\(w\cdot x + b\)</span>所对应的分离超平面。</p></li>
</ul>
<p>感知机的过程：</p>
<pre><code>+ 初始化参数w,b
+ 抽取训练数据的样本计算实际输出
+ 判定是否与理想输出差不多，**并根据感知机规则调整**$\color&#123;red&#125;&#123;(Key)&#125;$ </code></pre>
<ul>
<li>多轮迭代，直至误差不超过指定范围。</li>
</ul>
<p><strong>常见的感知机规则/学习规则</strong>有：</p>
<ul>
<li><p>随机学习:</p>
<pre><code>  + 先给出**小范围内的随机赋值**，然后根据**输出与真实值的误差**慢慢对赋值进行**小幅度的随机修正**。
  + 在一个小范围(−𝛿, +𝛿) 内给𝑾 和𝑩 赋予初始值
  + 利用𝑾 和𝑩 算出输出𝑶，考虑它与真实值𝒀 的误差|𝑶−𝒀|&lt;𝜖 是否成立
  + 在𝑾 和𝑩 上加上一个很小的(−𝜉, +𝜉) 范围内的随机数，再重新判断</code></pre>
<ul>
<li><p>特点<span class="math inline">\(\color{red}{(Key)}\)</span> : + <strong>效率低</strong>，<strong>思想简单，容易实现</strong>，<strong>能找到全局最优</strong>。</p></li>
<li><p><strong>Hebb学习</strong>：</p>
<ul>
<li><p>其想法是当<strong>神经元i与神经元j同时处于兴奋状态</strong>时，两者之间的<strong>连接强度应增强</strong>。</p></li>
<li><p>其更新权值的方式为 <span class="math display">\[
  w_{new} = w_{old} + \eta o x
  \]</span> <span class="math inline">\(\eta\)</span>为学习率，<span class="math inline">\(o\)</span>是输出,<span class="math inline">\(x\)</span>为输入</p>
<p>该过程ppt有一个计算<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
</ul></li>
<li><p><strong>基于误差的学习</strong>:</p>
<ul>
<li><p>其计算期望输出与实际输出之间的误差 <span class="math display">\[
  r = y_i - o_i 
  \]</span> 其更新权值的方式为 <span class="math display">\[
  w_{new} = w_{old} + \eta r x
  \]</span> 该过程ppt有一个计算<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>其持续输入样本直至<span class="math inline">\(r\)</span>为0或很接近0</p></li>
</ul></li>
</ul></li>
</ul>
<h5 id="神经元的应用">神经元的应用</h5>
<ul>
<li><p>可以将一个机器学习问题概括如下:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012046076.png" alt="image-20220101204615037" style="zoom:67%;" /></p></li>
<li><p>其中，h为假设函数，如果输出值y为连续的，那么这个问题就是回归问题；如果y是有限离散的值，那么该问题是分类问题。</p></li>
<li><p><strong>线性回归</strong>：目标是要<strong>得到一条尽可能表示数据分布的线性函数</strong>。对应了<strong>单输入单输出</strong>神经元。</p>
<ul>
<li><p>当我们采用MSE来思想这一点的时候,可以借助<strong>最小二乘法</strong>来最小化MSE:<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li><p>最小二乘法的目标是<strong>输出与预测的MSE最小化</strong>，相当于去<strong>求解一个优化问题</strong>: <span class="math display">\[
  \arg\min_{w,b} \frac{1}{n}\sum_{i=1}^n(wx_i+b-y_i)^2
  \]</span> <strong>对w,b求偏导为0</strong>，求闭式解。最后结果如下: <span class="math display">\[
  w = \frac{\sum_{i=1}^n (x_i - \overline{x}) (y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x})^2}
  \]</span></p>
<p><span class="math display">\[
  b = \overline{y} - w \overline{x}
  \]</span></p></li>
</ul></li>
<li><p>或者用<strong>神经元</strong>来解决:<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li><p>采用MSEloss: <span class="math display">\[
  loss(w,b) = \frac{1}{2} (o_i - y_i )^2
  \]</span> 调整权值： <span class="math display">\[
  \frac{\partial loss}{\partial w} = \frac{\partial loss}{\partial o_i} \frac{\partial o_i}{\partial w} = (o_i - y_i)x_i
  \]</span></p>
<p><span class="math display">\[
  \frac{\partial loss}{\partial b} = \frac{\partial loss}{\partial o_i} \frac{\partial o_i}{\partial b} = (o_i - y_i)
  \]</span></p>
<p>更新权值： <span class="math display">\[
  w_{new} = w_{old} - \eta \frac{\partial loss}{\partial w}
  \]</span></p>
<p><span class="math display">\[
  b_{new} = b_{old} - \eta \frac{\partial loss}{\partial b}
  \]</span></p></li>
<li><p>与最小二乘法直接求闭式解不同的是，神经元是通过导数传递误差,再通过迭代方式一步一步<strong>（用近似解）逼近真实解</strong>。</p></li>
</ul></li>
</ul></li>
<li><p>多元线性回归：样本有不止一个输入，也即<strong>有多个维度的特征</strong>，即现实问题、编程练习中的形式。对应了<strong>多输入单输出</strong>神经元。 <span class="math display">\[
  ℎ (𝒙_i) = 𝒘^T𝒙_i + 𝑏
  \]</span> 为了方便，会书写成以下形式：<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012114226.png" alt="image-20220101211427163" style="zoom:67%;" /></p>
<p>对于权重中的b常用<span class="math inline">\(w_0\)</span>代表，x中的常数1可以直接写成1。</p></li>
<li><p>ppt中对于双月数据，研究了单个神经元以及多个神经元之间的差别：<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li><strong>单个神经元就可以较好处理线性可分</strong>问题</li>
<li><strong>而现实中的很多分类问题是线性不可分的</strong>，如XOR问题。
<ul>
<li>这时候就需要多个神经元进行处理。</li>
</ul></li>
</ul></li>
</ul>
<h4 id="section-2">3</h4>
<ul>
<li><strong>单个MP神经元</strong>的结构决定了它只能解决“<strong>多输入——单输出</strong>”的<strong>线性可分</strong>问题。由于结构限制，无论是单纯的分类问题，还是分类和回归相结合的问题，单个神经元都无法解答。因此，我们需要连接多个神经元。</li>
</ul>
<h5 id="神经元的连接">神经元的连接</h5>
<ul>
<li><p>连接的拓扑表示：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012129710.png" alt="image-20220101212934635" style="zoom:50%;" /></p></li>
<li><p>层级结构:<span class="math inline">\(\color{red}{(Key)}\)</span>通常<strong>同一层不具有连接、两个相邻层完全连接</strong>(每一层的每一个神经元到另一层的每个神经元)。<span class="math inline">\(\color{blue}{(drop)}\)</span>如果<strong>层内有连接</strong>，就是用来来加强和完成层内<strong>神经元之间的竞争，应用有限</strong>。</p></li>
<li><p>互联网式结构：<span class="math inline">\(\color{blue}{(drop)}\)</span></p>
<ul>
<li>Hopfield网络(HN):
<ul>
<li>每个神经元被连接到其他神经元。每个节点在训练前输入，然后在训练期间隐藏并输出。通过将神经元的值设置为期望的模式来训练网络，此后权重不变</li>
</ul></li>
<li>马尔可夫链</li>
</ul></li>
<li><p>卷积神经网络<span class="math inline">\(\color{blue}{(drop)}\)</span>：包含卷积计算且具有深度结构的前馈神经网络</p></li>
<li><p>竞争神经网络<span class="math inline">\(\color{blue}{(drop)}\)</span>：神经节点之间互相连接</p></li>
<li><p>循环神经网络<span class="math inline">\(\color{blue}{(drop)}\)</span>：以序列数据作为输入，在序列的演进方向进行递归且所有节点按链式连接的递归神经网络</p></li>
</ul>
<h5 id="单层感知机">单层感知机</h5>
<ul>
<li><p>线性可分（Linearly Separable）：训练样本可由直线完全分开</p></li>
<li><p>单层感知机的目标就是<strong>找到直线的权重、偏置,将一系列样本，正确的分成𝐶和𝐶'两类</strong><span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p><strong>单层感知机</strong>虽然只能够<strong>解决线性可分</strong>的问题（Linearly-Separable Problem），但<strong>相比单个神经元，它可以解决多输入多输出的问题</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>在该直线上方的点，输出为1， 下方，输出为0</p></li>
<li><p>没有偏置项的时候，直线必须过原点，<strong>不同的权重只调整斜率，偏置调整截距</strong>。</p></li>
<li><p>单层感知机的结构：只有输入层和输出层</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012143836.png" alt="image-20220101214358763" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201012145123.png" alt="image-20220101214520082" style="zoom:80%;" /></p>
<p>因此，注意权重项、输入项的形状变化。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
</ul>
<h5 id="学习算法-lms">学习算法-LMS</h5>
<ul>
<li><p>LMS算法也称为<strong>delta rule</strong></p>
<ul>
<li>我觉得LMS跟基于误差的感知机学习算法也没区别啊..</li>
</ul></li>
<li><p>LMS首次被用于<strong>Adaptive Filtering Problem</strong>，其分为两个过程：</p>
<ul>
<li><p>Filter Process : 由<strong>输入生成输出</strong> <span class="math display">\[
  y(i) = \mathbf{x}^T(i) \mathbf{w}(i)
  \]</span></p></li>
<li><p>Adaptive Process ： <strong>自动调整权重以减小误差</strong> <span class="math display">\[
  e(i) = d(i) - y(i)
  \]</span> 也就是<strong>理想输出减去预测输出</strong></p></li>
<li><p>调整𝒘(𝑖)来减小e(𝑖),<strong>Steepest Descent(梯度下降法)</strong>:<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<p>​ 对权重矩阵𝒘，最小化代价函数ℇ(𝒘)：找到最优解𝒘∗ <span class="math display">\[
  \nablaℇ(𝒘^*) = 0
  \]</span> ​ 那么<strong>对于迭代更新的算法</strong>，每一次迭代需要使得 <span class="math display">\[
  ℇ (𝒘 (𝑛 + 1)) &lt; ℇ(𝒘 (𝑛) )
  \]</span> ​ 即在每一次迭代之后的误差都要有所减小。</p>
<p>​ 定义∇ℇ(𝒘)为𝒈，则权重更新算法变为 <span class="math display">\[
  𝒘 (𝑛 + 1) = 𝒘 (𝑛) - \eta 𝒈(n)
  \]</span> ​ 其中<span class="math inline">\(\eta\)</span>是学习率，那么 <span class="math display">\[
  Δ𝒘 (𝑛) = 𝒘 (𝑛 + 1) − 𝒘 (𝑛) = −𝜂𝒈(𝑛)
  \]</span> ​ 对ℇ(<span class="math inline">\(\cdot\)</span>)在𝒘 (𝑛) 附近<strong>做泰勒公式一阶展开</strong>得 <span class="math display">\[
  ℇ (𝒘 (𝑛 + 1))≈ ℇ (𝒘 (𝑛))+ 𝒈^T(𝑛)Δ𝒘(𝑛)
  \]</span></p>
<p><span class="math display">\[
  ℇ (𝒘 (𝑛 + 1))≈ ℇ (𝒘 (𝑛)) -\eta 𝒈^T(𝑛)𝒈(𝑛) = ℇ (𝒘 (𝑛)) -\eta ||𝒈(𝑛)||^2
  \]</span></p>
<p>​ 因此 <span class="math display">\[
  ℇ (𝒘 (𝑛 + 1)) &lt; ℇ(𝒘 (𝑛) )
  \]</span> ​ 成立</p></li>
<li><p>LMS定义代价函数(其实就是MSE):<span class="math inline">\(\color{red}{(Key)}\)</span> <span class="math display">\[
  ℇ (𝒘) = \frac{1}{2} e^2 (𝒘)
  \]</span> 对𝒘求微分 <span class="math display">\[
  \frac{\partial ℇ (𝒘)}{\partial w} = e (𝒘) \frac{\partial e (𝒘)}{\partial w}
  \]</span></p>
<p><span class="math display">\[
  e (𝒘)=d-\mathbf{x}^T𝒘
  \]</span></p>
<p>在这里<span class="math inline">\(d\)</span>是真实样本标签。 <span class="math display">\[
  \frac{\partial ℇ (𝒘)}{\partial w} = -\mathbf{x} e (𝒘)
  \]</span></p>
<p>将以上代入steepest descent rule,即代入 <span class="math display">\[
  Δ𝒘 (𝑛) = 𝒘 (𝑛 + 1) − 𝒘 (𝑛) = −𝜂𝒈(𝑛)
  \]</span></p></li>
</ul>
<p><span class="math display">\[
      𝒘 (𝑛 + 1) =  𝒘 (𝑛)+𝜂\mathbf{x} e_n (𝒘)
  \]</span> <span class="math inline">\(\color{red}{(Pay\ attention)}\)</span>：上述权重更新只针对一个样本<span class="math inline">\((x_i,d_i)\)</span></p>
<ul>
<li><p>LMS优点：</p></li>
<li><p>简单易部署，不依赖于模型</p></li>
</ul></li>
<li><p>LMS缺点：</p>
<ul>
<li><p><strong>只使用单个样本进行更新，则梯度方向不一定符合steepest descent</strong></p></li>
<li><p><strong>收敛很慢</strong></p></li>
<li><p>对输入的相关矩阵（correlation matrix）的<strong>条件数</strong>（最大和最小的特征值之间的比值）<strong>敏感</strong></p></li>
<li><p>LMS的可收敛范围定义如下，𝜼是学习率，𝝀&lt;=&gt;是最大的特征值: <span class="math display">\[
      0&lt;\eta&lt;\frac{2}{\lambda_{max}}
      \]</span></p></li>
</ul></li>
<li><p><strong>将其加入感知机</strong>之后，感知机的学习过程为:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021341987.png" alt="image-20220102134119895" style="zoom:67%;" /></p></li>
<li><p>用<strong>梯度下降法的感知机</strong> 与<strong>标准感知机(逐样本进行更新)</strong>的区别在:</p>
<ul>
<li><p>对于ppt中的!两种写法:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021412481.png" alt="image-20220102141243353" style="zoom: 67%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021413098.png" alt="image-20220102141300983" style="zoom:67%;" /></p>
<p>区别在于</p>
<pre><code>  + 计算output的函数一个是net_input,也就是$wx+b$,一个是predict,也就是$sgn(f(x))$。
  + 误差评估也不一样，一个是**梯度不为0的维度数**，一个是**损失函数**。
  + **权重更新是直接作用于所有样本，而不同于之前的逐个样本更新**，这种方法也叫做“**批量梯度下降**”（batch gradient descent）
  + **批量梯度下降**的模型输出“o”是一个实数，而不是之前所用的一个类别标签。</code></pre></li>
</ul></li>
</ul>
<h5 id="思考题">思考题</h5>
<ul>
<li><p>权重更新有没有更简单的形式:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021352037.png" alt="image-20220102135206980" style="zoom: 80%;" /></p></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">self.w_ += update * np.array(np.ones((1,self.w_.shape[1])), xi)</span><br></pre></td></tr></table></figure>
<ul>
<li>标准的单层感知机会存在什么问题,在线性可分前提下：</li>
</ul>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021401469.png" alt="image-20220102140114385" style="zoom:67%;" /></p>
<h4 id="section-3">4</h4>
<h5 id="单层感知机的局限">单层感知机的局限</h5>
<ul>
<li><strong>无法解决线性不可分</strong>问题，比如异或问题。对于非线性问题，需要增加神经元，以拟合输入-输出关系。</li>
<li><strong>在正确分类之后就会停止更新</strong>。</li>
<li>因此，可以添加一些隐藏层，把输入数据的特征抽象到另一个维度空间，来展现其更抽象化的特征，这些特征能更好的进行线性划分。如果有多个隐藏层就能对输入特征进行多层次的抽象,这就诞生了多层感知机</li>
</ul>
<h5 id="多层感知机">多层感知机</h5>
<ul>
<li><p>多层感知机（Multilayer Perceptron，MLP）是<strong>至少有一个隐藏层</strong>的神经网络，<strong>具有以任意精度逼近神经元输入层和输出层之间的任何非线性关系的能力</strong></p></li>
<li><p>层级结构，各神经元分别属于不同的层，<strong>层内无连接</strong>，<strong>相邻两层之间的神经元全部两两连接</strong>。</p></li>
<li><p>每个神经元模型包含一个可微的非线性激活函数</p></li>
<li><p>运行过程:</p>
<ul>
<li><p>加权输入 <span class="math display">\[
  u = w^Tx + b
  \]</span></p></li>
<li><p>非线性处理 <span class="math display">\[
  y = f(u)
  \]</span></p></li>
</ul></li>
</ul>
<h5 id="多层感知机的学习">多层感知机的学习</h5>
<ul>
<li><p>为什么要学习： + 多层感知机的<strong>神经元个数很多</strong>，<strong>参数很多</strong>，<strong>不适合手工设计各个神经元的参数</strong>，需要神经元<strong>“自动”学习</strong>参数。</p></li>
<li><p>在多层感知机中，最初的权值设置为任意值。网络每处理一个输入，网络输出都与期望输出相比较，差值称为“误差”。</p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021440261.png" alt="image-20220102144039191" /><figcaption aria-hidden="true">image-20220102144039191</figcaption>
</figure></li>
<li><p>通过调整权重组合，<strong>得到产生最小的误差的网络</strong></p></li>
</ul>
<h6 id="梯度下降法">梯度下降法</h6>
<ul>
<li><p><strong>梯度的方向</strong>就是<strong>函数之变化最快的方向</strong></p>
<ul>
<li><p>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率</p></li>
<li><p>在<strong>多变量函数</strong>中，<strong>梯度是一个向量</strong>，如下式所示，向量有方向，<strong>梯度的方向</strong>就指出了<strong>函数在给定点的上升最快的方向</strong></p></li>
<li><p>而我们需要朝着<strong>下降最快的方向</strong>走，自然就是<strong>负的梯度的方向</strong>，所以梯度下降法需要加上负号<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
</ul></li>
<li><p>梯度下降法的基本公式：<span class="math inline">\(\color{red}{(Key)}\)</span> <span class="math display">\[
  Θ(1) = Θ(0) − α∇𝐽(Θ)
  \]</span></p>
<ul>
<li><p>𝐽 是关于Θ 的一个函数，我们当前所处的位置为$Θ_0 <span class="math inline">\(点，要**从这个点走到J 的最小值点**，也就是山底。首先我们先确定前进的方向，也就是**梯度的反向**，然后**走一段距离的步长**，也就是**α**，走完这个段步长，就到达了\)</span>Θ_1 $这个点。</p></li>
<li><p>其中𝛼 在梯度下降法中被称作为<strong>学习率或者步长</strong>，意味着我们可以通过α来控制每一步走的距离 <strong>𝛼 太小</strong>可能导致<strong>迟迟走不到最低点</strong>或者<strong>无法跳出局部极小点</strong>； <strong>𝛼 太大</strong>可能导致<strong>错过最低点，无法稳定收敛。</strong></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021456900.png" alt="image-20220102145625794" style="zoom:80%;" /></p></li>
</ul>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021457515.png" style="zoom:67%;" /></p></li>
<li><p>神经网络中常见的误差计量方式： <span class="math display">\[
  𝑬𝒓𝒓 =\frac{1}{2}(𝒀 − 𝑶)^2
  \]</span></p></li>
<li><p>此外，梯度下降法要遵循两个原则：</p>
<ul>
<li><p>每次更新权矩阵𝑾，都应该使得误差𝑬𝒓𝒓下降，或者说使得权矩阵𝑾向最优解靠近，如果误差无法下降了，就终止对于权重的更新；</p>
<ul>
<li><p>误差𝑬𝒓𝒓对于权矩阵𝑾的梯度为 <span class="math display">\[
  \frac{\partial 𝑬𝒓𝒓}{\partial 𝑾} = (𝒀 − 𝑶) (-𝑿)
  \]</span> 那么权矩阵𝑾的更新就是梯度的反方向上走<span class="math inline">\(\alpha\)</span>步 <span class="math display">\[
  \Delta 𝑾 = \alpha (𝒀 − 𝑶) 𝑿
  \]</span> 同理，对于偏置矩阵𝑩有 <span class="math display">\[
  \frac{\partial 𝑬𝒓𝒓}{\partial 𝑩} = -(𝒀 − 𝑶)
  \]</span></p>
<p><span class="math display">\[
  \Delta 𝑩 = \alpha (𝒀 − 𝑶)
  \]</span></p></li>
</ul></li>
<li><p>希望能够以最快的速度找到最优解。</p></li>
</ul></li>
</ul>
<h6 id="反向传播算法">反向传播算法</h6>
<ul>
<li><p>多层网络的学习能力比单层感知机强得多，想要训练多层网络，使用简单的感知机学习规则是远远不够的。</p></li>
<li><p>BP算法的学习过程由<strong>正向传播过程和反向传播过程</strong>组成</p>
<ul>
<li>在正向传播过程中，<strong>输入信息通过输入层经隐藏层，逐层处理并传向输出层</strong>,也就是得到输出的过程。</li>
<li>如果在输出层得不到期望的输出值，则取输出与期望的误差的平方和作为目标函数，转入反向传播，<strong>逐层求出目标函数对各神经元权值的偏导数</strong>，构成目标函数对权值向量的梯度，作为修改权值的依据，网络的学习在权值修改过程中完成。</li>
<li>误差达到所期望值时，网络学习结束</li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021532502.png" alt="image-20220102153226433" style="zoom:80%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021546064.png" alt="image-20220102154611984" style="zoom:80%;" /></p>
<p>损失<span class="math inline">\(\delta_n\)</span>是该神经元的损失函数对该神经元未经激活函数处理前的输入的梯度的相反数。 <span class="math display">\[
  \begin{align}
  \delta &amp;= - \frac{\partial ErrorFunction}{\partial x} \\
      &amp;= - \frac{\partial ErrorFunction}{\partial y} \frac{\partial y}{\partial x} \\
  \end{align}
  \]</span> <span class="math inline">\(y\)</span>是激活函数,<span class="math inline">\(x\)</span>是<strong>连接到输出层的隐藏层的加权和</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>对于上一层的误差<span class="math inline">\(\delta\)</span>的计算如下：</p>
<p><span class="math inline">\(x\)</span>是<strong>连接到输出层的隐藏层的加权和</strong>,<span class="math inline">\(x_{upper}\)</span>是<strong>上一隐藏层的加权和</strong> <span class="math display">\[
  \begin{align}
  \delta_{upper} =  &amp;= - \frac{\partial ErrorFunction}{\partial x} \\
      &amp;= - \frac{\partial ErrorFunction}{\partial y}  \frac{\partial y}{\partial x}  \frac{\partial x}{\partial x_{upper}} \\
      &amp;= - \frac{\partial ErrorFunction}{\partial y}  \frac{\partial y}{\partial x}  \frac{\partial x}{\partial o} \frac{\partial o}{\partial x_{upper}} \\
      &amp;= \delta W f(x_{upper}) (1-f(x_{upper})) \\
      &amp;= \delta W o (1-o)
  \end{align}
  \]</span></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021545006.png" alt="image-20220102154513922" style="zoom:80%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021549366.png" alt="image-20220102154932294" style="zoom:80%;" /></p></li>
<li><p>ppt有bp算法的计算<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021632670.png" alt="image-20220102163221571" style="zoom:67%;" /></p></li>
</ul>
<h5 id="改进bp算法">改进BP算法</h5>
<ul>
<li><p>BP算法的缺点:<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li>BP网络<strong>接受样本的顺序</strong>对训练结果有较大影响，它更<strong>“偏爱”较后出现的样本</strong></li>
<li><strong>不同样例的更新的效果</strong>可能"抵消"</li>
<li>每次学习后<strong>对当前实例的误差最小</strong>，可能导致<strong>网络震荡或不稳定</strong></li>
<li>给样本安排一个适当的顺序，是非常困难的</li>
</ul></li>
<li><p>对于上述问题改进后的版本就是累计BP算法,它使得<strong>在整个训练集上的全局误差</strong>以一个<strong>平均水平</strong>逐渐下降，采用了<strong>存储全部实例梯度并计算平均梯度</strong>，<strong>误差在这个梯度方向最小</strong> <span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li>针对累积误差最小化，<strong>读取整个训练集</strong>D后，<strong>才对参数进行更新</strong>，这样一来也就<strong>降低了参数更新的频率</strong>，在提升稳定性的同时，加快了算法速率。但是，沿着<strong>平均梯度的反向下降</strong>也就意味着<strong>需要更多的时间进行收敛</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span> 该问题可以通过<strong>给每一个神经元增加一个偏移量来加快收敛速度</strong>以缓解。</li>
<li>较好地解决了<strong>因样本的顺序引起的精度问题</strong>和<strong>训练的抖动问题</strong>。</li>
</ul></li>
<li><p>另一种改进方案是<strong>动量法</strong>（momentum）。在梯度下降过程中，动量法用之前<strong>积累动量代替真正的梯度</strong>,也是一种<strong>平均方法</strong>，有助于<strong>提升梯度下降法在寻找最优解时的稳定性</strong>。</p>
<ul>
<li><p><span class="math display">\[
  Δ𝑤_m = 𝜇Δ𝑤_{m-1} − (1 − 𝜇)𝜀𝑑_m^w
  \]</span></p></li>
<li><p><span class="math inline">\(Δ𝑤_m\)</span> 是权值变化， 𝜇是0和1之间的动量参数，<span class="math inline">\(𝑑_m^w\)</span> 是对权值𝑤的当前全导。</p></li>
<li><p><span class="math inline">\(𝜇Δ𝑤_{m-1}\)</span>表示过去权值对当前权值的影响。</p>
<ul>
<li>该项起到了稳定的作用，如果当前的变化方向跟其一致，那么，就会加速变化；反之，会抑制变化。</li>
</ul></li>
<li><p><span class="math inline">\((1 − 𝜇)𝜀𝑑_m^w\)</span>表示训练时间内的权值变化。</p></li>
</ul></li>
</ul>
<h5 id="rbf网络">RBF网络</h5>
<ul>
<li><p><span class="math inline">\(\color{blue}{(drop)}\)</span></p></li>
<li><p>径向基函数是某种<strong>沿径向对称</strong>的<strong>标量函数</strong>。通常定义为空间中任 一点x到某一中心c之间欧氏距离的<strong>单调函数</strong>，可记作k(||x-c||)，其作用往往是<strong>局部</strong>的，即<strong>当x远离c时函数取值很小</strong>。</p></li>
<li><p>径向基函数RBF神经网络是一种三层神经网络，其包括输入层、隐层、输出层。<strong>从输入空间到隐层空间的变换是非线性的</strong>，而<strong>从隐层空间到输出层空间变换是线性的</strong>。</p></li>
<li><p>求解的参数有3个：基函数的中心、方差以及隐含层到输出层的权值:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021911245.png" alt="image-20220102191108134" style="zoom:67%;" /> 有三种方法可以求解:</p>
<ul>
<li>自组织选取中心学习方法</li>
<li>直接计算法</li>
<li>有监督学习算法</li>
</ul></li>
</ul>
<h5 id="多层感知机的分析">多层感知机的分析</h5>
<h6 id="激活函数的相关分析">激活函数的相关分析</h6>
<ul>
<li><p>对于多层感知机，<strong>如果没有激活函数，那么多层感知机仍然等效于单层感知机</strong>：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021915884.png" alt="image-20220102191556795" style="zoom:67%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021916215.png" alt="image-20220102191635137" style="zoom:67%;" /> <span class="math display">\[
  Tanh(x) = 2 Sigmoid(2x) - 1 
  \]</span></p></li>
<li><p>而Logistic(Sigmoid)函数和Tanh函数的<strong>导数的值域都小于或等于1</strong>，在<strong>反向传播</strong>的过程中，<strong>在每一层都要乘以这一层激活函数的导数</strong>，这就会导致如果是很多层的网络，<strong>梯度就会趋于0</strong>，这就是<strong>梯度消失问题</strong>。</p>
<ul>
<li><p>一种<strong>减轻梯度消失问题</strong>的方法就是<strong>使用导数较大的激活函数</strong>，比如ReLU函数</p></li>
<li><p>ReLU函数计算速度非常快，只需要判断输入是否大于0,收敛速度远快于Sigmoid和Tanh,但是正如在前面激活函数一节中提到的ReLU函数存在Dead ReLU Problem：</p>
<ul>
<li><p>在训练时，如果参数在一次<strong>不恰当的更新</strong>后，<strong>隐藏层中的某个神经元在所有的训练数据上都不能被激活</strong>，那么<strong>这个神经元自身参数的梯度永远都会是0</strong>，在<strong>以后的训练过程中也永远不能被激活</strong>。</p></li>
<li><p>为了解决这一点，会使用ReLu的变体:Leaky ReLU等: <span class="math display">\[
  Leaky ReLU = \max(0.1x,x)
  \]</span></p></li>
<li><p>实验中<strong>一般可以从ReLU函数开始</strong>，如果ReLU函数没有提供较好结果，再尝试其他激活函数</p></li>
</ul></li>
</ul></li>
</ul>
<h6 id="通用近似定理">通用近似定理</h6>
<ul>
<li>通用近似定理(Universal approximation theorem)：如果一个<strong>神经网络具有线性输出层和至少一层隐藏层</strong>，<strong>只要给予网络足够数量的神经元</strong>，便可以实现以<strong>足够高精度</strong>来逼近<strong>任意一个在ℝn 的紧子集(Compact subset)上的连续函数</strong>。
<ul>
<li>紧凑（有限、封闭）集合上的任何连续函数<strong>都可以用分段函数逼近</strong>,这一点也可以佐证通用近似定理</li>
</ul></li>
</ul>
<h5 id="网络结构超参数选择">网络结构超参数选择</h5>
<ul>
<li>网络结构超参数：<strong>输入、隐藏层的层数以及隐藏层神经元的个数</strong></li>
<li>一般来说，<strong>输入层的神经元数量等于待处理数据中输入变量的数量，输出层的神经元的数量等于与每个输入关联的输出的数量</strong>。困难之处在于<strong>确定合适的隐藏层的层数</strong>以及<strong>隐藏层神经元的个数</strong>。</li>
<li>一般情况下，更深更宽的结构<strong>可以模拟更复杂的分布</strong>，但增加隐藏层的层数和隐藏层神经元个数也<strong>不一定</strong>总能够提高网络精度和表达能力。</li>
<li>隐藏层神经元个数增加到一定数量后，<strong>训练难度增大但对准确率的提升变得很小</strong>，过多的神经元会<strong>增加训练时间</strong>，<strong>增大计算负担</strong>,造成<strong>计算负担与结果提升不对等</strong>的现象；</li>
<li>如果隐藏层神经元<strong>个数过多</strong>，出现<strong>过拟合</strong>，反而会使测试集<strong>准确率下降</strong>;隐藏层中使用<strong>太少</strong>的神经元，网络<strong>从样本中获取的信息能力较差</strong>，不足以概况和体现训练集中的样本规律，导致<strong>欠拟合</strong>(underfitting)</li>
<li>隐藏层个数的变化也大致相同。</li>
</ul>
<h5 id="多层感知机的应用">多层感知机的应用</h5>
<ul>
<li>分类</li>
<li>拟合函数</li>
<li>拟合曲面</li>
</ul>
<h5 id="思考题-1">思考题</h5>
<p>更深的网络和更广的网络哪一个更好?</p>
<p>根据本章知识，哪些改进可以帮助该MLP提升分类准确率?</p>
<h4 id="section-4">5</h4>
<h5 id="学习率调整策略">学习率调整策略</h5>
<ul>
<li>𝜂 太小可能迟迟走不到最低点或无法跳出局部极小点 𝜂 太大的话会导致错过最低点，无法稳定收敛</li>
<li>常用的学习率调整方法:
<ul>
<li><strong>固定衰减</strong>
<ul>
<li>一开始我们会把学习率设置的大一些来保证收敛速度，<strong>当收敛到最优点附近时</strong>，应该<strong>让学习率变小一些</strong>，避免震荡</li>
<li>分段常数衰减:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021950615.png" alt="image-20220102195020516" style="zoom:67%;" /></li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201021950963.png" alt="image-20220102195041852" style="zoom:67%;" /></li>
</ul></li>
<li><strong>学习率预热</strong>
<ul>
<li>由于刚开始训练时，模型的权重是<strong>随机初始化</strong>的，此时若选择一个较大的学习率，<strong>可能带来模型的不稳定(振荡)</strong>，为了让初始阶段的学习<strong>更加稳定</strong>，一种学习率预热（Learning Rate Warmup）的方法被提出。</li>
<li>在<strong>初始的几轮，采用较小的学习率</strong>.梯度<strong>下降到一定程度</strong>之后，再<strong>恢复到初始设置的学习率</strong></li>
</ul></li>
<li>周期变化
<ul>
<li><strong>梯度下降方法容易陷入局部最小值或鞍点</strong>，这个时候根据经验应当<strong>适当增加学习率</strong>来逃离。虽然这有可能<strong>损失网络的收敛稳定性</strong>，但是长远来看能找到<strong>更好的局部最优解</strong>。</li>
<li>循环学习率(CLR)：让学习率在一个区间内周期性的增大和缩小</li>
<li>带热重启的随机梯度下降(SGDR)：学习率会每间隔一定迭代后重新初始化为预先设定好的值，并继续衰减。</li>
<li><strong>可以减少迭代次数</strong>，并能达到与学习率衰减方法相似的或者更好的性能</li>
</ul></li>
<li>自适应
<ul>
<li>如果参数过多，<strong>对每个参数设置不同的学习率未免太过繁琐且不切实际</strong>，但相同学习率又不一定适合所有参数，所以可以通过参数空间的不同而自适应的调整学习率。</li>
<li><strong>AdaGrad</strong>:在训练过程中动态调整学习率，对不同参数根据累计梯度平方和更新不同学习率。</li>
<li><strong>RMSProp</strong>:通过指数加权移动平均替代累计平方梯度和，可以在有些情况下避免AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点</li>
<li><strong>Adam</strong> 算法则融合了动量法和RMSProp算法的思想，不但使用动量作为参数更新方向，而且可以自适应调整学习率，大家可以课后自行了解。</li>
</ul></li>
</ul></li>
</ul>
<h5 id="损失函数">损失函数</h5>
<ul>
<li><p>回归损失函数</p>
<ul>
<li><p><strong>平方误差损失</strong>(MSE)</p></li>
<li><p><strong>绝对值误差损失</strong>(MAE)</p></li>
<li><p><strong>MAE 对于异常点更加鲁棒</strong>：<strong>在有异常点的情况下，平方误差会扩大误差</strong>，因此<strong>平方误差损失函数对异常点更敏感</strong>。 <strong>MSE 通常比MAE 可以更快地收敛</strong>：<strong>绝对值误差损失函数更新梯度始终一样，不利于模型收敛</strong></p></li>
<li><p>Huber损失结合了平方误差损失和绝对值误差损失优点,误差较小时：平方误差损失误差较大时：绝对值误差损失:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022005273.png" alt="image-20220102200507179" style="zoom:67%;" /></p></li>
</ul></li>
<li><p>分类损失函数:</p>
<ul>
<li><p>交叉熵损失:</p>
<p>通常在网络的<strong>最后一层经过softmax</strong> 函数得到每个类别的 预测概率，通过交叉熵损失函数公式计算交叉熵损失。交叉熵损失越小表示预测概率分布越接近真实概率分布 <span class="math display">\[
  loss = \sum (-\sum y_{true} \log y_{pred}) / N
  \]</span> 对每个样例计算交叉熵再取平均</p></li>
<li><p>估计会有计算交叉熵损失的计算<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p><strong>神经元权重和偏置的学习速度基本上是由损失函数的偏导数决定的</strong>。所以如果“<strong>学习缓慢</strong>”，可能是由这些<strong>偏导数很小</strong>所导致的</p></li>
<li><p><strong>交叉熵更大的误差</strong>带来<strong>更快的学习速度</strong>，避免了<strong>均方差“学习缓慢”</strong>的问题</p>
<ul>
<li>交叉熵比均方差学习更快。</li>
</ul></li>
</ul></li>
</ul>
<h5 id="正则化">正则化</h5>
<ul>
<li><strong>偏差</strong>：衡量模型<strong>预测值和实际值之间的偏离关系</strong></li>
<li><strong>方差</strong>：描述<strong>模型在整体数据上表现的稳定情况</strong>，在<strong>训练集和验证集/测试集上表现是否一致</strong>。</li>
<li>一个好模型的<strong>偏差、方差都应该比较小</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span>
<ul>
<li>双高是差模型</li>
<li>偏差高、方差低-&gt;欠拟合</li>
<li>偏差低、方差高-&gt;过拟合</li>
</ul></li>
<li>可以通过减小权重w的值来缓解过拟合。<span class="math inline">\(\color{red}{(Key)}\)</span></li>
<li>基于这一点，我们可以使用<strong>正则化方法</strong>来<strong>降低模型的复杂程度</strong>:
<ul>
<li>L1和L2正则化
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022044261.png" alt="image-20220102204431183" style="zoom:33%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022045049.png" alt="image-20220102204502981" style="zoom:67%;" /></p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022045013.png" alt="image-20220102204520909" /><figcaption aria-hidden="true">image-20220102204520909</figcaption>
</figure></li>
<li><p>这与上面提到的<strong>减小权重w的值来缓解过拟合</strong>的办法是相通的。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>L1正则化<strong>会使参数更接近0值</strong>，L2正则化单单使参数减小。原因在于，每次梯度更新时，<strong>L1正则梯度为1或-1，导致L1稳定向0靠近</strong>.对于L2正则，<strong>随着变量靠近0，其梯度逐渐减小</strong>。最终， <strong>L1正则可能为0， L2正则却几乎不可能</strong>，所以<strong>带L1正则项训练的模型更容易得到稀疏解</strong>。<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
</ul></li>
<li>dropout丢弃法
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022049397.png" alt="image-20220102204943281" style="zoom:67%;" /></li>
<li>为了保持整体值在一个水平，丢弃之后，对于没有丢弃的结点的值需要乘以<span class="math inline">\(\frac{1}{p}\)</span>,<span class="math inline">\(p\)</span>为丢弃的概率</li>
<li>避免过拟合原因：<span class="math inline">\(\color{red}{(Key)}\)</span>
<ul>
<li>相当于<strong>取平均</strong>的作用，取每次丢弃后<strong>子网络的平均结果</strong>。</li>
<li><strong>降低神经元之间的敏感度</strong>，增加整体鲁棒性。</li>
</ul></li>
</ul></li>
<li>提前停止:
<ul>
<li>验证集错误率基本不下降时或有反增趋势时，<strong>可以提前停止训练</strong></li>
</ul></li>
</ul></li>
</ul>
<h5 id="归一化">归一化</h5>
<ul>
<li><p>Why 归一化?<span class="math inline">\(\color{red}{(Key)}\)</span></p>
<ul>
<li><strong>特征差距过大,不利于收敛</strong></li>
<li>如果前面发生了一个<strong>小偏移</strong>，到了<strong>越深的层这个偏移就会被扩大</strong>。这样是<strong>不利于网络的训练</strong>。因此后面介绍的归一化方法<strong>主要</strong>为了<strong>稳定层输入的分布</strong>，来<strong>改善神经网络训练</strong>。</li>
</ul></li>
<li><p>min-max归一化:将结果映射到[0,1]之间</p>
<ul>
<li><span class="math display">\[
  x^\prime = \frac{x - \min(x)}{\max(x) - \min(x)}
  \]</span></li>
</ul></li>
<li><p>z-score归一化</p>
<ul>
<li><p><span class="math display">\[
  x^\prime = \frac{x - \mu}{\sigma}
  \]</span></p></li>
<li><p><span class="math inline">\(\mu\)</span>为均值，<span class="math inline">\(\sigma\)</span>为方差</p></li>
</ul></li>
<li><p>批归一化:<strong>对每一批数据进行归一化</strong></p>
<ul>
<li>BatchNorm版本：在基础版本的基础上，每个隐藏层后面添加一个BatchNorm层。
<ul>
<li>BatchNorm能够<strong>有效加快网络收敛速度</strong>，并能够<strong>提高网络泛化性能</strong>。</li>
</ul></li>
<li>缺点:
<ul>
<li><strong>当batch值很小</strong>时，计算的<strong>均值和方差不稳定</strong></li>
</ul></li>
</ul></li>
<li><p>层归一化（LN）:</p>
<ul>
<li>对中间层的所有神经元进行归一化</li>
</ul></li>
<li><p>实例归一化（IN）:</p>
<ul>
<li><p>主要用于依赖于某个图像实例的任务</p></li>
<li><p>对每个样本的H和W的数据求均值和标准化，保留N、C维度</p>
<figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022107089.png" alt="image-20220102210746016" /><figcaption aria-hidden="true">image-20220102210746016</figcaption>
</figure></li>
</ul></li>
<li><p>组归一化（GN）:</p>
<ul>
<li>主要用于依赖于某个图像实例的任务,把特征通道分为G组，每组有C/G个特征通道，在组内进行归一</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022108288.png" title="fig:" alt="image-20220102210830215" /></li>
</ul></li>
</ul>
<h5 id="参数初始化">参数初始化</h5>
<ul>
<li><p>Why init?</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022109830.png" alt="image-20220102210910710" style="zoom:67%;" /></li>
</ul></li>
<li><p>好的初始化值能够帮助网络<strong>更快地计算得到最优值</strong>，<strong>更容易收敛</strong>到目标函数。</p></li>
<li><p><strong>全零初始化</strong>:</p>
<ul>
<li>参数初始化最简单的方式：把神经网络参数全部初始化为0</li>
<li>但是这样子是<strong>无法进行学习</strong>的<span class="math inline">\(\color{red}{(Key)}\)</span></li>
</ul></li>
<li><p>目前<strong>没有发现一种初始化方式可以适用于任何网络结构</strong>。初始化需要<strong>避免“对称权重”</strong>现象（唯一确知的特性）<span class="math inline">\(\color{red}{(Key)}\)</span></p></li>
<li><p>梯度消失与梯度爆炸:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022112437.png" alt="image-20220102211205359" style="zoom:67%;" /></li>
<li>基本可以说<strong>不论梯度绝对值大于1还是小于1</strong>都会造成<strong>无法正常学习</strong>的现象。</li>
</ul></li>
<li><p>因此，<strong>权重矩阵需要保持在一个合适的范围</strong>。</p></li>
<li><p>基于固定方差的参数初始化:</p>
<ul>
<li>想法是从一个<strong>固定均值</strong>(通常为0)和<strong>方差</strong>的分布中采样来生成参数的初始值</li>
<li>对于任意网络权值<span class="math inline">\(w_{ij}\)</span>，从区间<strong>[−r, r]</strong> 的<strong>均匀分布</strong>中随机选取初始值。</li>
<li>对于任意网络权值<span class="math inline">\(w_{ij}\)</span>，从<strong>均值为0、方差为常数𝑘</strong> 的<strong>高斯分布</strong>中随机选取初始值。</li>
<li>缺点:下图是采用基于固定方差的参数初始化后每层的激活函数输出值的分布，可以看出当神经网络的层数增多时，会发现越往后面层的激活函数的<strong>输出值几乎都接近于0</strong>，<strong>极易出现梯度消失</strong></li>
</ul></li>
<li><p>基于方差缩放的参数初始化:</p>
<ul>
<li>初始化一个深度网络时，为了缓解梯度消失或爆炸问题，我们<strong>尽可能保持每个神经元的输入和输出的方差一致</strong>，<strong>根据神经元的连接数量来自适应地调整初始化分布的方差</strong>，这类方法称为<strong>方差缩放</strong>(Variance Scaling)。</li>
<li><strong>Xavier初始化</strong>:
<ul>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022202773.png" alt="image-20220102220220662" /><figcaption aria-hidden="true">image-20220102220220662</figcaption>
</figure></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022203552.png" alt="image-20220102220303450" style="zoom:67%;" /></p></li>
<li><p>采用Xavier初始化之后，<strong>深层的激活函数输出值还是非常服从标准高斯分布</strong>，但是，对于ReLu函数，<strong>当达到5、6层后梯度又开始逐渐趋向于0</strong>。</p></li>
</ul></li>
<li>对于ReLu，更为合理的初始化方式为He初始化:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022206884.png" title="fig:" alt="image-20220102220613755" /></li>
</ul></li>
<li>正交初始化:正交初始化可以避免<strong>训练开始时就出现梯度消失或梯度爆炸现象</strong>
<ul>
<li>用<strong>均值为0方差为1的高斯分布</strong>初始化一个矩阵</li>
<li>将这个矩阵用<strong>奇异值分解</strong>得到<strong>两个正交矩阵</strong>，使用<strong>其中之一作为权重矩阵</strong></li>
<li>实际使用中<strong>通常需要将正交矩阵乘以一个缩放系数</strong></li>
</ul></li>
</ul></li>
<li><p>对于偏置矩阵，通常我们可以把偏置矩阵初始化为全0矩阵。</p>
<ul>
<li><p>除非:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022209002.png" alt="image-20220102220912920" style="zoom:80%;" /></p></li>
</ul></li>
<li><p><strong>即使采用了合理的初始化</strong>，<strong>梯度爆炸或消失</strong>的问题<strong>也会出现</strong>。</p></li>
</ul>
<h5 id="网络预训练">网络预训练</h5>
<ul>
<li>网络预训练是<strong>采用相同结构的，并且已经训练好的网络权值作</strong> <strong>为初始值</strong>，在当前任务上再次进行训练。
<ul>
<li>为了能够<strong>在更短时间内训练得到更好的网络性能</strong></li>
<li><strong>相似的任务</strong>之间，<strong>训练好的神经网络可以复用</strong>，通常作为特征提取器。</li>
</ul></li>
<li>常用的预训练方法:
<ul>
<li><strong>无监督预训练:</strong>
<ul>
<li>玻尔兹曼机（Boltzmann Machines，BM）：一种对称连接的，神经元根据能量函数计算概率进行激活的网络结构
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022213277.png" alt="image-20220102221305181" style="zoom:80%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022214555.png" alt="image-20220102221453448" style="zoom:80%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022215721.png" alt="image-20220102221508592" style="zoom:80%;" /></li>
</ul></li>
<li><strong>自编码器</strong>（Auto-encoder，AE）：是<strong>无监督的全连接网络结构</strong>，其训练目标为<strong>重构误差最小化</strong>
<ul>
<li>​ <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022216063.png" alt="image-20220102221604958" style="zoom:80%;" /></li>
<li>用encoder（降维重构）-decoder（还原）进行预训练。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022217276.png" alt="image-20220102221707127" style="zoom:80%;" /></li>
</ul></li>
</ul></li>
<li>神经网络的使用梯度下降法之所以训练困难，主要原因在于<strong>它的目标函数对于参数来说是非凸函数</strong>，因此在参数空间中<strong>存在多个局部极小值</strong>。
<ul>
<li>对于无监督的预训练所起到的作用，有这样的两个猜想:
<ul>
<li><strong>预训练相当于在优化过程中加入了限制条件</strong>，将参数放置在更适合监督训练的优化空间中;</li>
<li><strong>初始化</strong>将参数<strong>放置</strong>到了一个<strong>能够优化到更小极值的初始点</strong>上。</li>
</ul></li>
</ul></li>
<li><strong>有监督预训练</strong>
<ul>
<li><strong>迁移学习</strong>:已经训练好的网络作为自己网络的权重初始值
<ul>
<li><strong>通过大量带标签的数据集，大幅减少网络收敛的训练时间。</strong>已经训练好的网络权重作为特征提取器也是有可能可以复用的。</li>
<li><strong>更高的起点(初始模型性能更好),更高的斜率(学习快),更高的渐进(性能强)</strong></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h5 id="思考题colorredkey">思考题<span class="math inline">\(\color{red}{(Key)}\)</span></h5>
<ul>
<li>过拟合的时候，拟合函数的系数（W）往往非常大，为什么?
<ul>
<li>过拟合，就是拟合函数需要顾忌每一个点，最终形成的<strong>拟合函数波动很大</strong>。在某些很小的区间里，<strong>函数值的变化很剧烈</strong>。这就意味着函数在某些小区间里的<strong>导数值（绝对值）非常大</strong>，由于<strong>自变量值可大可小</strong>，所以<strong>只有系数足够大，才能保证导数值很大</strong>。</li>
</ul></li>
<li>Batch normalization的输出服从什么样的分布（指出分布中的 具体参数）：
<ul>
<li>使得每一层的输出都可以规范化到一个<strong>标准高斯分布</strong>上.</li>
<li>其参数为<span class="math inline">\(\mu=0,\sigma=1\)</span></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201022243911.png" alt="image-20220102224310836" style="zoom:80%;" /></li>
</ul></li>
<li>Batch normalization为什么归一化后还有放缩（γ）和平移 （β）？
<ul>
<li>Batch Normalization在<strong>标准归一化</strong>之后，<strong>减弱了神经网络的非线性表示</strong>，需要<strong>附加缩放和平移来变换取值区间</strong> ,<strong>在一定程度上恢复网络的非线性表示能力</strong>。</li>
</ul></li>
<li>目前有一批病人的身体数据（体重变化，血液指标等）和他们是否患有肺癌的真实标签，其中<strong>患肺癌的样本只占非常小的比例</strong>。数据直接送入一个神经网络中，求问应该使用什么样的初始化？数据中不同的<strong>特征数值差异过大</strong>，求问如何改进能够让网络更好地学习数据中的分布？
<ul>
<li>正交初始化，防止梯度消失</li>
<li>进行归一化处理</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>NN</tag>
      </tags>
  </entry>
  <entry>
    <title>chap.16 强化学习</title>
    <url>/2021/12/22/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="强化学习">强化学习</h4>
<ul>
<li><p>强化学习的过程概括些说就是做一个动作action，环境给予你一个反馈r:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221600231.png" alt="image-20211222160057193" style="zoom:50%;" /></p></li>
<li><p>强化学习任务通常用马尔可夫决策过程(MDP)来描述：</p>
<ul>
<li><p>对于一个环境<span class="math inline">\(E\)</span>,其由状态空间<span class="math inline">\(X\)</span>,动作空间<span class="math inline">\(A\)</span>,状态转移概率<span class="math inline">\(P\)</span>以及奖励函数<span class="math inline">\(R\)</span>组成，通常的P,R函数形式如下：<span class="math inline">\(P: X\times A\times X -&gt; \mathbb{R}\)</span> 指定一个概率,<span class="math inline">\(R: X\times A\times X -&gt; \mathbb{R}\)</span> 指定一个奖赏。</p></li>
<li><p>因此，强化学习的内容就是让机器通过在环境中不断尝试从而学到一个策略<span class="math inline">\(\pi\)</span> ,根据这个策略本<span class="math inline">\(\pi\)</span> ,我们可以确定在状态<span class="math inline">\(x\)</span>下要执行的动作<span class="math inline">\(a = \pi(x)\)</span> ,并且使得长期累积的奖赏可以最大化。</p></li>
<li><p>常用的长期累计奖赏的计算方式有：</p>
<ul>
<li><p>T步累计奖赏 ： <span class="math inline">\(\mathbb{E}[\frac{1}{T} \sum_{t=1}^T r_t]\)</span></p></li>
<li><p><span class="math inline">\(\gamma\)</span>折扣累计奖赏 ： <span class="math inline">\(\mathbb{E}[ \sum_{t=0}^{+\infty} \gamma^t r_{t}]\)</span></p></li>
<li><p>马尔可夫回报过程（MRP）计算的就是： <span class="math display">\[
  V(x) = \sum_{x^\prime\in X} P(x^\prime|x) (R(x^\prime) + V(x^\prime))
  \]</span> 描述的就是从一个状态<span class="math inline">\(x\)</span>转移到其他所有状态<span class="math inline">\(x^\prime\)</span>之后的累计回报。</p></li>
</ul></li>
</ul></li>
</ul>
<span id="more"></span>
<h5 id="k-摇臂赌博机">K-摇臂赌博机</h5>
<ul>
<li>强化学习任务需要在多步动作之后，才能看到最终奖赏，考虑简单情况，就是最大化单步奖赏。要最大化单步奖赏，我们不仅要知道每个动作带来的奖赏，还要执行奖赏最大的动作。但是动作的奖赏通常都是取自一个概率分布，无法通过单次尝试获得平均奖赏值。</li>
<li>K-摇臂赌博机描述了单步强化学习任务的过程：K-摇臂赌博机有k个摇臂，投入一个硬币可以按下一个摇臂，每个摇臂以一定概率（不可知）吐出硬币。</li>
<li>对于这种情况，一般有两种策略：
<ul>
<li>探索——估计摇臂的优劣：即平均给每个摇臂投硬币，得到概率的近似解</li>
<li>利用——选择当前最优的摇臂。</li>
<li>由于总尝试次数有限，因此，侧重于任何一方都会削弱另外一方。这也就是强化学习面临的“探索-利用窘境”。想要达到最大的累计奖赏，就必须在探索与利用之间达成较好的折中。</li>
</ul></li>
</ul>
<h5 id="epsilon贪心策略"><span class="math inline">\(\epsilon\)</span>贪心策略</h5>
<ul>
<li><p><span class="math inline">\(\epsilon\)</span>贪心法基于一个概率来对探索以及利用过程进行折中：</p>
<ul>
<li><p>每次尝试时，以<span class="math inline">\(\epsilon\)</span>概率进行探索，选择一个摇臂；以<span class="math inline">\(1-\epsilon\)</span> 的概率选择当前平均奖赏最高的摇臂（多个采取随机选择）。</p></li>
<li><p>则平均奖赏可以记录为 <span class="math display">\[
  Q(k) = \frac{1}{n} \sum_{i=1}^n v_i
  \]</span> <span class="math inline">\(v_i\)</span>为每次返回的奖赏,需要记录n个奖赏值。</p></li>
<li><p>一种更为高效的办法是对均值进行增量式计算，即每尝试一次就更新<span class="math inline">\(Q\)</span>,设定用下标记录尝试次数,<span class="math inline">\(Q_i\)</span>表示i次尝试之后的平均奖赏，更新公式如下: <span class="math display">\[
  Q_n(k) = \frac{1}{n} ((n-1)\times Q_{n-1}(k) + v_n)
  \]</span> 也就只需要记录每个摇臂的尝试次数n，以及平均奖赏<span class="math inline">\(Q_i(k)\)</span></p></li>
<li><p>其中，通过调整<span class="math inline">\(\epsilon\)</span>的大小，可以调整探索以及利用的比率。当迭代较多次之后，可以考虑增大利用的比率。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221700300.png" alt="image-20211222170052246" style="zoom:50%;" /></p></li>
</ul></li>
</ul>
<h5 id="softmax算法">Softmax算法</h5>
<ul>
<li><p>Softmax算法基于已知的摇臂平均奖赏来对探索以及利用进行折中，通过摇臂平均奖赏计算摇臂被选取的概率(基于Boltzmann分布)，且正相关： <span class="math display">\[
  P(k) = \frac{e^{\frac{Q(k)}{\tau}}}{\sum_{i=1}^K e^{\frac{Q(i)}{\tau}}}
  \]</span> 其中<span class="math inline">\(\tau\)</span>是可以自设定的参数，越高则平均奖赏越高的摇臂被选取的概率越高，也就是越趋向于“仅利用”。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221700202.png" alt="image-20211222170036149" style="zoom:50%;" /></p></li>
<li><p>Softmax算法以及<span class="math inline">\(\epsilon\)</span>贪心法孰优孰劣看具体应用。</p></li>
</ul>
<h5 id="有模型学习">有模型学习</h5>
<ul>
<li>有模型学习描述的是指马尔可夫决策过程总环境<span class="math inline">\(E=&lt;X,A,P,R&gt;\)</span>已知的情况,也就是说一个状态<span class="math inline">\(x\)</span>经过动作<span class="math inline">\(a\)</span>转移到<span class="math inline">\(x^\prime\)</span>的概率<span class="math inline">\(P_a\)</span>,以及reward<span class="math inline">\(R_a\)</span>都是已知的。</li>
</ul>
<h6 id="策略评估">策略评估</h6>
<ul>
<li><p>在模型已知的情况下，对于任意的策略<span class="math inline">\(\pi\)</span>,都可以估计出该策略带来的期望累计奖赏。</p></li>
<li><p>定义一些函数如下：</p>
<ul>
<li><span class="math inline">\(V^{\pi}(x)\)</span>表示从状态<span class="math inline">\(x\)</span>出发采用策略<span class="math inline">\(\pi\)</span>带来的累计奖赏
<ul>
<li><span class="math inline">\(V(\cdot)\)</span>是状态值函数</li>
</ul></li>
<li><span class="math inline">\(Q^{\pi}(x,a)\)</span>表示从状态出发，执行动作a之后再使用策略<span class="math inline">\(\pi\)</span>的累计奖赏
<ul>
<li><span class="math inline">\(Q(\cdot)\)</span>是一个状态-动作值函数</li>
</ul></li>
<li>累计奖赏都用T步累计奖赏、<span class="math inline">\(\gamma\)</span>折扣累计奖赏进行计算。</li>
</ul></li>
<li><p>由于MDP具有马尔可夫性质，因此系统下一时刻的状态仅有当前的状态决定，不依赖任何以往的状态，也就是说，我们可以将上述函数写成递归等式的形式（这也被称为Bellman等式）:</p>
<ul>
<li>对于T步累计奖赏有</li>
</ul>
<p><span class="math display">\[
  V^{\pi}_T(x) = \sum_{a\in A} \pi(x,a)\sum_{x^\prime\in X}P^a_{x\rightarrow x^\prime} (\frac{1}{T} R^a_{x\rightarrow x^\prime} + \frac{T-1}{T}V^{\pi}_{T-1}(x^\prime)) (16.7)
  \]</span></p>
<ul>
<li>对于<span class="math inline">\(\gamma\)</span>折扣累计奖赏有 <span class="math display">\[
  V^{\pi}_{\gamma}(x) = \sum_{a\in A} \pi(x,a)\sum_{x^\prime\in X}P^a_{x\rightarrow x^\prime} ( R^a_{x\rightarrow x^\prime} + \gamma V^{\pi}_{\gamma}(x^\prime))   (16.8)
  \]</span></li>
</ul></li>
<li><p>那么对于策略评估算法有</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221835924.png" alt="image-20211222183501861" style="zoom:50%;" /></p></li>
<li><p>对于<span class="math inline">\(\gamma\)</span>折扣累计奖赏,可以作出更改如下:</p>
<p>需要设定阈值的原因是，基于T步累计奖赏的策略评估算法的动态规划过程是从T-&gt;0,而基于<span class="math inline">\(\gamma\)</span>折扣累计奖赏的策略评估算法的动态规划过程是从<span class="math inline">\(0-&gt;+\infty\)</span></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221835754.png" alt="image-20211222183558680" style="zoom:50%;" /></p></li>
</ul>
<h5 id="策略改进">策略改进</h5>
<ul>
<li><p>评估完某一个策略的累计奖赏之后，我们希望对其进行改进，即求解下列优化问题 <span class="math display">\[
  \pi^* = \arg\max_{\pi} \sum_{x\in X} V^{\pi} (x)
  \]</span> 对于最优策略，定义最优值函数<span class="math inline">\(V^*(x) = V^{\pi^*}(x),\forall x\in X\)</span> ,不过对于策略空间含有约束的情况下，还需要考虑在最优值函数尽可能大的情况下，满足约束。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221843751.png" alt="image-20211222184325665" style="zoom:50%;" /></p></li>
<li><p>最优bellman等式的含义就是在每一次策略选择的时候，都选择当前最优的动作，其理论保证在于下图推导，不妨假设选择最优动作之后的策略是<span class="math inline">\(\pi^\prime\)</span> ,而改变动作的条件在于<span class="math inline">\(Q^\pi(x,\pi^i(x)) \ge V^\pi (x)\)</span>：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221848055.png" alt="image-20211222184846009" style="zoom:50%;" /> <span class="math display">\[
   = V^{\pi^\prime}(x)
  \]</span> 也就是说，<strong>每一步动作的选择都保证了值函数的增大,因此可以已知选取当前的最优动作</strong>，直到<span class="math inline">\(\pi^\prime = \pi\)</span>。</p></li>
</ul>
<h5 id="策略迭代">策略迭代</h5>
<ul>
<li><p>将策略评估以及策略优化结合起来，就可以得到策略迭代过程。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221857066.png" alt="image-20211222185737994" style="zoom:50%;" /></p>
<p>上述的策略迭代过程由于每次改进策略之后，都要重新进行策略评估，因此比较耗时。</p>
<p>注意到策略改进的过程与值改善的过程是一致的，因此可以更改成为以下的值迭代算法。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221859783.png" alt="image-20211222185928712" style="zoom:50%;" /></p></li>
</ul>
<h5 id="免模型学习">免模型学习</h5>
<h6 id="蒙特卡洛强化学习"><strong>蒙特卡洛强化学习</strong></h6>
<ul>
<li><p>免模型学习是指环境并不完全知悉，导致无法进行有模型学习时的策略迭代过程。针对这样的环境，我们可以通过多次采样，求取平均累计奖赏来作为期望累积奖赏的近似，这也就是蒙特卡洛强化学习的过程。</p></li>
<li><p>由于<strong>采样有限次，因此适合使用<span class="math inline">\(T\)</span>步累计奖赏的强化学习</strong>。</p></li>
<li><p>另外，蒙特卡洛强化学习的估计对象从值函数<span class="math inline">\(V(\cdot)\)</span>转变为了状态动作函数<span class="math inline">\(Q(\cdot)\)</span></p></li>
<li><p>为了能够多次采样出不同的轨迹，可以引入<span class="math inline">\(\epsilon\)</span>-贪心策略进行策略选取，将原来确定性的策略<span class="math inline">\(\pi\)</span>转变为了<span class="math inline">\(\pi^{\epsilon}\)</span> 策略。</p></li>
<li><p>注意到引入<span class="math inline">\(\epsilon\)</span>-贪心策略并不会影响选取当前最优的动作构成的策略优化算法的正确性，因为，从已经最大化了值函数的原始策略<span class="math inline">\(\pi^\prime\)</span>中分出<span class="math inline">\(\epsilon\)</span>的概率给其他动作，仍然是原始策略<span class="math inline">\(\pi^\prime\)</span>中的最优动作可以最大化值函数。</p></li>
<li><p>如果评估与优化的都是同一个值函数，就可以得到同策略蒙特卡洛强化学习</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221917760.png" alt="image-20211222191729674" style="zoom:50%;" /></p></li>
<li><p>但是，由于同策略蒙特卡洛强化学习最终产生的是<span class="math inline">\(\epsilon\)</span>-贪心策略,我们更希望在策略评估的过程中引入<span class="math inline">\(\epsilon\)</span>-贪心策略，而在策略改进时只改进原始策略。</p></li>
<li><p>这里插入一个重要性采样(importance sampling)的概念：</p>
<p>对于另一个分布<span class="math inline">\(q\)</span>,函数<span class="math inline">\(f\)</span>在概率<span class="math inline">\(p\)</span>下的期望为： <span class="math display">\[
  \mathbb{E}[f] = \int_x q(x) \frac{p(x)}{q(x)} f(x)dx
  \]</span> 用采样离散化： <span class="math display">\[
  \hat{\mathbb{E}}[f] = \frac{1}{m} \sum_{i=1}^m \frac{p(x_i^\prime)}{q(x_i^\prime)} f(x_i^\prime)
  \]</span> 那么，对于贪心策略<span class="math inline">\(\pi^\prime\)</span>以及原始策略<span class="math inline">\(\pi\)</span>给出的两条轨迹<span class="math inline">\(i\)</span>的概率<span class="math inline">\(P_i^\pi,P_i^{\pi^\prime}\)</span>, <span class="math display">\[
  P^\pi = \prod_{i=0}^{T-1} \pi(x_i,a_i) P_{x_i \rightarrow x_{i+1}}^{a_i}\\
  P_i^{\pi^\prime} = \prod_{i=0}^{T-1} \pi^\prime(x_i,a_i) P_{x_i \rightarrow x_{i+1}}^{a_i}\\
  Q(x,a) = \frac{1}{m} \sum_{i=1}^m \frac{P^\pi}{P_i^{\pi^\prime}} r_i\\
      = \frac{1}{m} \sum_{i=1}^m \prod_{i=0}^{T-1} \frac{\pi(x_i,a_i)}{\pi^\prime(x_i,a_i)} r_i \\
      \pi(x_i,a_i) = 1\\
      \pi^\prime(x_i,a_i) =\frac{\epsilon}{|A|} \ or\ 1-\epsilon + \frac{\epsilon}{|A|}
  \]</span> <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221930008.png" alt="image-20211222193032924" style="zoom:50%;" /></p></li>
</ul>
<h6 id="时序差分学习">时序差分学习</h6>
<ul>
<li><p>蒙特卡洛强化学习在进行完整的采样之后再进行状态-动作对的更新，可以将这个过程化为增量化的更新。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221940826.png" alt="image-20211222194010746" style="zoom:50%;" /></p></li>
<li><p>Sarsa算法(同策略算法，评估执行的都是<span class="math inline">\(\epsilon\)</span>贪心策略):</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221941491.png" alt="image-20211222194118419" style="zoom:50%;" /></p></li>
<li><p>Q-learning算法(异策略算法,评估<span class="math inline">\(\epsilon\)</span>贪心策略,执行原始策略):</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221941783.png" alt="image-20211222194130693" style="zoom:50%;" /></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>chap.13 半监督学习</title>
    <url>/2021/12/22/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="半监督学习">半监督学习</h4>
<h5 id="未标记样本">未标记样本</h5>
<ul>
<li><p>显然，现实问题有很多没有label的数据，这些数据的数量明显大于有label的数据量。</p></li>
<li><p>为了将这些没有label的数据利用起来，有个平凡的想法，就是人工对所有的unlabel的数据激进行label，但是这是耗费大量人力物力的。</p></li>
<li><p>基于此，主动学习就被提出了。主动学习的流程是想使用有label的数据<span class="math inline">\(D_l\)</span>训练出一个学习器，然后让这个学习器对unlabel的数据进行预测，将预测结果人工检查好不好，再加入到有标记样本中进行训练。每次我们都挑选出对改善模型性能有帮助的瓜，那么，就只需要人工检查较少次数就可以构建出性能比较好的模型，从而降低成本。这也符合了它的目的：用尽量少的查询获得尽量好的性能。</p></li>
<li><p>但是主动学习仍然借助了专家的知识，如果能让学习器不依赖外界知识，自动利用<span class="math inline">\(D_u\)</span> 数据，那就是半监督学习(semi-supervised learning)的学习目标了。</p>
<p><span id="more"></span></p></li>
<li><p>想要做到这一点，一个问题就浮现了：如何揭示未标记样本所包含的数据分布信息并将其与label相联系？</p>
<ul>
<li>为了解决这个问题，提出了几个假设：
<ul>
<li>聚类假设（cluster assumption）:
<ul>
<li>假设数据有簇结构，同一个簇的样本属于同一个类别</li>
</ul></li>
<li>流形假设（manifold assumption）:
<ul>
<li>假设数据分布在一个流形结构上，邻近的样本拥有相似的输出值</li>
<li>它与聚类假设的本质都是相似的样本有相似的输出</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>半监督学习又可以进一步划分为纯半监督学习、直推学习。</p>
<ul>
<li>纯半监督学习认为未标记样本并不一定是待预测的数据。（open-world assumption）这个认定也就意味着纯半监督学习可以对测试样本进行预测。</li>
<li>而直推学习则认为未标记样本就是待预测的数据。（closed-world assumption）</li>
</ul></li>
</ul>
<h5 id="生成式方法">生成式方法</h5>
<ul>
<li><p>基于生成式模型，认为所有数据都是同一个潜在模型生成的，未标记样本的label是模型的缺失参数，可以基于EM算法进行极大似然法求解。</p></li>
<li><p>给定一个样本<span class="math inline">\(x\)</span>,其真实类别标记为<span class="math inline">\(y \in \mathcal{Y}\)</span> ,假设样本由高斯混合模型生成，并且每个类别对应一个高斯混合成分，也就是说： <span class="math display">\[
  p (x) = \sum_{i=1}^N \alpha_i \cdot p(x|\mu_i,\Sigma_i)
  \]</span> 其中<span class="math inline">\(\alpha_i \ge 0,\sum_{i=1}^k \alpha_i = 1\)</span>,<span class="math inline">\(p(x|\mu_i,\Sigma_i)\)</span>表示样本<span class="math inline">\(x\)</span>属于第<span class="math inline">\(i\)</span>个高斯混合成分。</p></li>
<li><p>如果接着假设<span class="math inline">\(f(x)\)</span>是模型<span class="math inline">\(f\)</span>对样本<span class="math inline">\(x\)</span>的预测标记，用<span class="math inline">\(\Theta\in\{1,2,...,N\}\)</span>表示样本隶属的高斯混合成分，按照最大化后验概率的想法，有： <span class="math display">\[
  f(x) = \arg\max_{j\in\mathcal{Y}} p(y=j|x) \\
   = \arg\max_{j\in\mathcal{Y}} \sum_{i=1}^N p(y=j,\Theta=i|x) \\
   = \arg\max_{j\in\mathcal{Y}} \sum_{i=1}^N p(y=j|\Theta=i,x) \cdot p(\Theta=i|x) \\
   p(\Theta=i|x) = \frac{\alpha_i \cdot p(x|\mu_i,\Sigma_i)}{\sum_{i=1}^N \alpha_i \cdot p(x|\mu_i,\Sigma_i)}
  \]</span> <span class="math inline">\(p(\Theta=i|x)\)</span>表示的是样本<span class="math inline">\(x\)</span>由第i个高斯混合成分生成的后验概率</p>
<p><span class="math inline">\(p(y=j|\Theta=i,x)\)</span>表示的是样本<span class="math inline">\(x\)</span>由第i个高斯混合成分生成且属于类别j的概率。</p>
<p>再假设类别与高斯混合成分相对应的情况下，只有当<span class="math inline">\(i=j\)</span>的时候，<span class="math inline">\(p(y=j|\Theta=i,x)=1\)</span> ,otherwise,为0.</p></li>
<li><p>对于上面的式子，由于<span class="math inline">\(p(y=j|\Theta=i,x)\)</span>与样本挂钩，<span class="math inline">\(p(\Theta=i|x)\)</span>与样本无关。因此估计<span class="math inline">\(p(\Theta=i|x)\)</span>的时候可以使用未标记样本,也就可以辅助预测<span class="math inline">\(f(x)\)</span>。</p></li>
<li><p>极大似然法求解过程：</p>
<ul>
<li><p><span class="math display">\[
  LL(D_l \cup D_u) =  \sum_{x} \ln(\sum_{i=1}^N p(y=j|\Theta=i,x) \cdot p(\Theta=i|x)) \\
  = \sum_{(x_j,y_j)\in D_l} \ln \sum_{i=1}^N \alpha_i  \cdot p(x|\mu_i,\Sigma_i) \cdot p(y=j|\Theta=i,x) + \\
      \sum_{x_j\in D_u} \ln \sum_{i=1}^N \alpha_i  \cdot p(x|\mu_i,\Sigma_i)
  \]</span></p>
<p>拆分为了与数据label有关的一项以及与数据label无关的一项。</p>
<p>与数据label有关的一项利用<span class="math inline">\(D_l\)</span>进行训练，与数据label无关的一项利用<span class="math inline">\(D_u\)</span>进行训练</p></li>
<li><p>接下来就需要用EM算法进行求解。</p></li>
</ul></li>
<li><p>但是这种方法存在一个缺陷就是只有在假设的数据分布与真实的数据分布吻合的情况下才有效，否则利用未标记数据会降低泛化性能，这也是现实中很难做到的事情。</p></li>
<li><p>(*)高斯混合分布：</p>
<ul>
<li><p><span class="math display">\[
  p_M(x) = \sum_{i=1}^k \alpha_i \cdot p(x|\mu_i,\Sigma_i)
  \]</span></p></li>
<li><p>k个混合成为组成，每个混合成分对应一个高斯分布。<span class="math inline">\(\alpha_i \ge 0,\sum_{i=1}^k \alpha_i = 1\)</span>是混合系数。</p></li>
<li><p>高斯分布:</p>
<ul>
<li><span class="math display">\[
  p(x) = \frac{1}{(2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}}} e^{-\frac{1}{2}(x - \mu)^T \Sigma^{-1} (x-\mu)}
  \]</span></li>
</ul></li>
</ul></li>
<li></li>
<li><p>(*)EM算法 review:</p>
<ul>
<li><p>在西瓜书的推导中，将上述提到的<span class="math inline">\(p(\Theta=i|x)\)</span>记为<span class="math inline">\(\gamma_{i}\)</span> ,显然由最大化后验概率可知，对于样本<span class="math inline">\(x_j\)</span>的簇标记<span class="math inline">\(\lambda_j\)</span>由<span class="math inline">\(\arg\max \gamma_{ji}\)</span>确定。计算<span class="math inline">\(\gamma_{ji}\)</span>的过程,即计算样本<span class="math inline">\(x_j\)</span>属于各个高斯混合概率的概率就是E步。</p>
<p>下面根据计算的<span class="math inline">\(\gamma_{ji}\)</span>更新参数<span class="math inline">\(\alpha_i,\mu_i,\Sigma_i\)</span>,就是M步。</p></li>
<li><p>由极大似然可推知: <span class="math display">\[
  LL(D) = \ln(\prod_{j=1}^m p_M(x_j)) \\ 
       = \sum_{j=1}^m \ln (\sum_{i=1}^k \alpha_i \cdot p(x|\mu_i,\Sigma_i))
  \]</span> 我们要学习的是<span class="math inline">\(\alpha_i,\mu_i,\Sigma_i\)</span></p>
<p>由<span class="math inline">\(\frac{\partial LL(D)}{\partial \mu_i} = 0\)</span>可知 <span class="math display">\[
  \frac{d (\frac{1}{(2\pi)^{\frac{n}{2}} |\Sigma|^{\frac{1}{2}}} e^{-\frac{1}{2}(x - \mu)^T \Sigma^{-1} (x-\mu)})}{d \mu_i} \sum_{j=1}^m \frac{\alpha_i \cdot p(x_j|\mu_i,\Sigma_i)}{\sum_{l=1}^k \alpha_l \cdot p(x|\mu_l,\Sigma_l)} = 0 \ (1)\\ 
  \sum_{j=1}^m \frac{\alpha_i \cdot p(x_j|\mu_i,\Sigma_i)}{\sum_{l=1}^k \alpha_l \cdot p(x|\mu_l,\Sigma_l)} (x_j - \mu_i) = 0 \ (2)\\
  \sum_{j=1}^m \gamma_{ji} (x_j - \mu_i) = 0 \\
  \mu_i = \frac{\sum_{j=1}^m \gamma_{ji} x_j}{\sum_{j=1}^m \gamma_{ji}}
  \]</span> 注意的是，(1)式的导数在约去所有大于零的部分以及参数部分就可以转换为(2)式。</p>
<p>同理，按照<span class="math inline">\(\frac{\partial LL(D)}{\partial \Sigma_i} = 0\)</span>可知 <span class="math display">\[
  \Sigma_i = \frac{\sum_{j=1}^m \gamma_{ji} (x_j - \mu_i)(x_j - \mu_i)^T}{\sum_{j=1}^m \gamma_{ji}}
  \]</span> 对于混合系数<span class="math inline">\(\alpha_i\)</span>,我们需要用拉格朗日乘子法， <span class="math display">\[
  LL(D) + \lambda(\sum_{i=1}^k \alpha_i -1)
  \]</span> 对上式进行对<span class="math inline">\(\alpha_i\)</span>进行求偏导为0 <span class="math display">\[
  \sum_{j=1}^m \gamma_{ji} + \alpha_i \lambda = 0 \\
  \sum_{i=1}^m(\sum_{j=1}^m \gamma_{ji} + \alpha_i \lambda) = m + \lambda = 0\\
  \lambda = -m \\
  \alpha_i = \frac{\sum_{j=1}^m \gamma_{ji}}{m}
  \]</span></p></li>
</ul></li>
</ul>
<h5 id="半监督svm">半监督SVM</h5>
<ul>
<li><p>半监督SVM是在SVM的基础上，将两类有标记样本切开并且倾向于穿过数据低密度区域。</p></li>
<li><p>半监督SVM最著名的TSVM,TSVM针对二分类，想法是尝试将每个未标记样本作为正例或者反例，在所有可能的结果中，找到一个在所有样本中间隔最大化的划分超平面。划分超平面确定，则样本的划分标签确定。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241422176.png" alt="image-20211224142255110" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241424262.png" alt="image-20211224142452187" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241425218.png" alt="image-20211224142549165" style="zoom:50%;" /></p>
<ul>
<li><p>对于类别不平衡问题：</p>
<ul>
<li>可以将优化目标中的<span class="math inline">\(C_u\)</span>拆分为<span class="math inline">\(C_u^+,C_u^-\)</span>分别表示基于伪标签的 当作正反例使用的未标记样本，在初始化时: <span class="math display">\[
  C_u^+ = \frac{u_-}{u_+} C_u^-
  \]</span></li>
</ul></li>
<li><p>对于如何判别伪标签最可能错的两个示例:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241430760.png" alt="image-20211224143010715" style="zoom:50%;" /></li>
</ul></li>
</ul></li>
</ul>
<h5 id="图半监督学习">图半监督学习</h5>
<ul>
<li><p>图半监督学习的想法是给定一个数据集，将其映射为一个图，每个样本对应于图中的一个结点，如果两个样本之间的相似度很高，那么两个节点之间不仅有边，并且边的权重也很高。</p>
<p>并且，对于有标记样本，我们将其建模为染过色的结点，未标记样本则是未染色的结点。那么，半监督学习的过程就是颜色在图上传播的过程。</p></li>
<li><p>要让图可训练，我们需要将其构建为一个矩阵，通常根据高斯函数定义affinity matrix(亲和矩阵): <span class="math display">\[
  (\mathbf{W})_{ij} = \left\{
  \begin{aligned}
  &amp; \exp (\frac{-||x_i - x_j||_2^2}{2\sigma^2}) , if\ i\not=j\\
  &amp; 0, otherwise
  \end{aligned} 
  \right.
  \]</span> 同时基于相似的样本有相似的输出可以定义能量函数： <span class="math display">\[
  E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} (f(x_i) - f(x_j))^2 \\
  = \mathbf{f}^T (\mathbf{D} - \mathbf{W}) \mathbf{f} \\
  \mathbf{f} = (\mathbf{f}^T_l \mathbf{f}^T_u)^T \\
  \mathbf{D} = diag(d_1,d_2,...,d_{u+l}),d_i = \sum_{j=1}^{l+u} (\mathbf{W})_{ij}
  \]</span></p>
<ul>
<li>能量函数最小时获得最优结果。</li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241451674.png" alt="image-20211224145142617" style="zoom:50%;" /></p></li>
</ul>
<h5 id="基于分歧的方法">基于分歧的方法</h5>
<ul>
<li><p>基于分歧的方法常使用多个学习器，而学习器之间的分歧对于未标记数据的利用有很大的借鉴意义。</p></li>
<li><p>其重要代表是协同训练，它也是多视图学习的代表。</p>
<ul>
<li><p>其假设数据有两个充分且条件独立的视图。</p>
<ul>
<li>充分是指每个视图都包含足以产生最优学习器的信息。</li>
<li>条件独立是指在给定类别条件的情况下，两个视图独立。</li>
</ul></li>
<li><p>其想法是在每个视图上基于有标记样本分别训练出一个分类器，然后挑选每个分类器对未标记样本正确概率最大的样本作为另一个分类器的有标记样本加入下一轮训练。但是这种想法需要在每轮学习中都考察分类器在所有未标记样本上的置信度，计算开销大。这个问题可以借助未标记样本缓冲池（一开始选择s个<span class="math inline">\(D_u\)</span>中的样本加入，每轮循环结束后，再选一些加入）进行解决。</p></li>
<li><p>总过程伪代码：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221451878.png" alt="image-20211222145112704" style="zoom:50%;" /></p></li>
<li><p>在数据有两个充分且条件独立的视图的条件下，弱学习器的泛化能力可以提升到任意高。</p></li>
</ul></li>
<li><p>在后续研究中发现，数据拥有两个视图的假设并不重要，只需要弱学习器之间有明显差异即可，算法、视图、不同采样方式、不同参数都可以产生差异。</p></li>
</ul>
<h5 id="半监督学习-1">半监督学习</h5>
<ul>
<li>在现实聚类的过程中，我们常常可以获得一些额外的监督信息，因此，我们可以使用半监督聚类来利用监督信息以获得更好的聚类效果。</li>
<li>监督信息大致有以下两类：
<ul>
<li>必连：样本必定属于同一个簇。</li>
<li>勿连：样本必定不属于同一个簇。</li>
<li>少量的有标记样本，即事先已经找到少量样本属于哪一个簇当中。</li>
</ul></li>
<li>典型代表是约束k均值算法：
<ul>
<li>其是k-mean是算法的拓展，是第一类监督信息的代表（勿连与必连）。需要保证勿连集合<span class="math inline">\(\mathcal{C}\)</span>以及必连集合<span class="math inline">\(\mathcal{M}\)</span>中的约束，即如果有<span class="math inline">\((x_i,x_j)\in\mathcal{M}\)</span>，那么<span class="math inline">\(x_i\)</span>和<span class="math inline">\(x_j\)</span>必定是同一类别的。</li>
<li>其实就是k-mean算法的基础上加上判断每次样本<span class="math inline">\(x\)</span>与哪个均值向量<span class="math inline">\(u_i\)</span>最近，在划入之前，检查是否满足约束，如果不满足，就将样本<span class="math inline">\(x\)</span>加入次近的簇当中，再进行检查。</li>
<li>如果始终找不到可以容纳样本<span class="math inline">\(x\)</span>的簇，则认为无法完成聚类，输出error。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221527153.png" alt="image-20211222152740069" style="zoom:50%;" /></li>
</ul></li>
<li>利用第二类监督信息的代表是约束种子的k-means算法：
<ul>
<li>它的利用方式很容易理解，就是直接将已知簇标记的样本作为种子，初始化k-means的k个聚类中心，并且再聚类簇迭代的过程中始终不改变种子的标记。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112221537526.png" alt="image-20211222153753446" style="zoom:50%;" /></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>chap.14 概率图模型</title>
    <url>/2021/12/23/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h4 id="概率图模型">概率图模型</h4>
<h5 id="隐马尔可夫模型">隐马尔可夫模型</h5>
<ul>
<li><p>inference 推断指的是利用已知变量推测未知变量的分布。</p></li>
<li><p>生成式模型建模联合分布$P(Y,R,O) $</p></li>
<li><p>判别式模型建模条件分布<span class="math inline">\(P(Y,R|O)\)</span></p>
<p><span id="more"></span></p></li>
<li><p>概率图模型是用图来表达变量相关关系的概率模型。</p>
<ul>
<li><p>有向无环图-&gt;贝叶斯网 (适合有显式的因果关系)</p></li>
<li><p>无向图-&gt;马尔可夫网 （适合有相关性，但不知道因果性）</p></li>
<li><p>($$)有向图转变为一个无向图,使用有向分离技术：</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112231702012.png" alt="image-20211223170205953" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112231703912.png" alt="image-20211223170319868" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112231705108.png" alt="image-20211223170509065" style="zoom:50%;" /></p></li>
<li><p>有向分离技术指的是</p>
<ul>
<li>找出有向图中的所有<span class="math inline">\(V\)</span>型结构，在<span class="math inline">\(V\)</span>型结构的两个父节点之间加一个无向边(该过程为道德化)。</li>
<li>将所有的有向边改成无向边。</li>
<li>之后，该图称为道德图。</li>
<li>对于道德图中的变量<span class="math inline">\(x,y\)</span>和变量集合<span class="math inline">\(z = \{z_i\}\)</span>,如果变量<span class="math inline">\(x,y\)</span>能够被<span class="math inline">\(z\)</span>分开，也就是将<span class="math inline">\(z\)</span>去掉之后，<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>同属于两个连通分量，那么<span class="math inline">\(x,y\)</span>被<span class="math inline">\(z\)</span>有向分离，<span class="math inline">\(x\perp y|z\)</span> 。基于这个就可以找出所有的条件独立关系。</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>隐马尔可夫模型HMM是结构最简单的动态贝叶斯网。</p>
<ul>
<li><p>其有状态变量（又称隐变量）<span class="math inline">\(y\)</span>表示系统第i时刻的状态以及观测变量<span class="math inline">\(x_i\)</span></p></li>
<li><p>观测变量仅依赖于同时刻的状态变量，并且t时刻的状态变量<span class="math inline">\(y_t\)</span>仅依赖于t-1时刻的状态<span class="math inline">\(y_{t-1}\)</span>,这就是马尔可夫链，即系统的下一时刻的状态仅由当前状态决定，因此，所有变量的联合概率分布为: <span class="math display">\[
  P(x_1,y_1,..,x_n,y_n) = P(y_1)P(x_1|y_1)\prod_{i=2}^nP(y_{i+1}|y_i)P(x_i|y_i)
  \]</span></p></li>
<li><p>除此之外，HMM还需要知道状态转移概率、输出观测概率、初始状态概率：</p>
<ul>
<li>状态转移概率：<span class="math inline">\(a_{ij} = P(y_{t+1}=s_j|y_t = s_i)\)</span></li>
<li>输出观测概率: $ b_{ij}=P(x_t=o_j|y_t=s_i)$</li>
<li>初始状态概率: <span class="math inline">\(\pi_i = P(y_1 = s_i)\)</span></li>
</ul></li>
<li><p>其产生观测序列<span class="math inline">\(\{x_1,x_2,...,x_n\}\)</span>的过程为：</p>
<ul>
<li><span class="math inline">\(t=1\)</span>时，根据初始状态概率<span class="math inline">\(\pi\)</span>选择初始状态<span class="math inline">\(y_1\)</span> 。</li>
<li>根据状态<span class="math inline">\(y_t\)</span>以及输出观测概率<span class="math inline">\(b_{ij}\)</span>选择观测变量取值<span class="math inline">\(x_t\)</span>。</li>
<li>根据状态<span class="math inline">\(y_t\)</span>以及状态转移概率<span class="math inline">\(a_{ij}\)</span>选择下一个状态<span class="math inline">\(y_{t+1}\)</span>。</li>
<li>如果<span class="math inline">\(t&lt;n\)</span>,<span class="math inline">\(t+=1\)</span> ,反之，stop</li>
</ul></li>
</ul></li>
</ul>
<h5 id="马尔可夫随机场">马尔可夫随机场</h5>
<ul>
<li><p>马尔可夫随机场（MRF）是典型的无向图模型，典型的马尔科夫网。</p></li>
<li><p>马尔可夫随机场定义了一些势函数（也称为因子）用来表达模型对于变量的偏爱。</p></li>
<li><p>对于任意一个子集，如果子集中的任意两点都有边连接，那么就称这个子集构成了一个团，如果这个团加入任意点都不再构成团，那么这个团就是一个极大团。</p></li>
<li><p>对于n个变量<span class="math inline">\(x_1,x_2,...,x_n\)</span>,假设所有的团构成的集合是<span class="math inline">\(Q\)</span>,马尔可夫随机场定义的联合概率为： <span class="math display">\[
  P(x) = \frac{1}{Z} \prod_{Q\in\mathcal{C}}\psi_{Q}(x_Q)
  \]</span> 其中<span class="math inline">\(\psi_Q(x)\)</span>是一个势函数，<span class="math inline">\(Z\)</span>是规范化因子，<span class="math inline">\(\mathcal{C}\)</span>为所有团构成的集合</p></li>
<li><p>但是，上述定义对于有很多变量的情况下，团数量较多，会有大量乘积项导致计算繁琐。因此，可以对于每个极大团定义一个势函数，假设极大团构成的集合为<span class="math inline">\(\mathcal{C}^*\)</span>,那么上式转换为： <span class="math display">\[
  P(x) = \frac{1}{Z^*} \prod_{Q\in\mathcal{C}^*}\psi_{Q}(x_Q)
  \]</span></p></li>
<li><p>跟有向分离类似的，马尔可夫随机场也可以获得变量之间的条件独立性：</p>
<ul>
<li>如果结点集A中的点想要连接到结点集B中的点都需要通过结点集C中的点，那么就称结点集A和结点集B被结点集C分离，结点集C为分离集，可以与有向分离类似表示为<span class="math inline">\(x_A \perp x_B | x_C\)</span> :
<ul>
<li>全局马尔可夫性：有分离集的两个结点集互相条件独立。</li>
<li>局部马尔可夫性：对于一个结点，给定其邻接变量，该点与其他非邻接变量的点条件独立。</li>
<li>成对马尔可夫性：任意两个非邻接的结点条件独立。</li>
</ul></li>
</ul></li>
<li><p>对于马尔可夫随机场中要求的势函数，其首先需要是一个非负实函数，并且对于其偏好的变量的取值较大。</p></li>
</ul>
<h5 id="条件随机场">条件随机场</h5>
<ul>
<li><p>条件随机场(CRF)是一种判别式无向图模型，HMM以及MRF都是生成式模型。</p>
<p>其目标是在给定一个观测序列<span class="math inline">\(x_1,x_2,...,x_n\)</span>,<span class="math inline">\(y = y_1,y_2,...,y_n\)</span>,构建出条件概率<span class="math inline">\(P(y|x)\)</span>,这里的<span class="math inline">\(y\)</span>可以含有结构型变量。</p></li>
<li><p>如果假设<span class="math inline">\(y_v\)</span>为与结点<span class="math inline">\(v\)</span>对应的标记变量，用<span class="math inline">\(n(v)\)</span>表示结点<span class="math inline">\(v\)</span>的邻接结点，如果无向图<span class="math inline">\(G(V,E)\)</span>满足马尔可夫性： <span class="math display">\[
  P(y_v|x,y_{V\backslash \{v\}}) = P(y_v|x,y_{n(v)})
  \]</span> 那么<span class="math inline">\((x,y)\)</span>构成了一个条件随机场。</p></li>
<li><p>最常用的条件随机场结构如下:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112232148448.png" alt="image-20211223214829373" style="zoom:50%;" /></p>
<p>注意到上述结构中，构成团的标记变量为<span class="math inline">\(y_i,y_{i+1}\)</span>以及单个标记变量<span class="math inline">\(y_i\)</span>。</p>
<p>条件随机场也采用指数势函数以及团的结构来定义条件概率，并且额外增加了特征函数。 <span class="math display">\[
  P(y|x) = \frac{1}{Z} \exp(\sum_j \sum_{i=1}^{n-1}\lambda_jt_j(y_{i+1},y_i,x,i) + \sum_k \sum_{i=1}^{n}\mu_k s_k(y_i,x,i))
  \]</span> 其中<span class="math inline">\(t_j(y_{i+1},y_i,x,i)\)</span>是定义在两个相邻标记变量上的特征函数，用来刻画相邻变量之间的相关性以及观测序列对他们的影响；<span class="math inline">\(s_k(y_i,x,i)\)</span>定义在标记<span class="math inline">\(i\)</span>上的状态特征函数，用来刻画观测序列对于标记变量的影响。</p>
<ul>
<li><p>特征函数的作用是刻画一些数据很可能成立或者期望成立的经验特性。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112232159701.png" alt="image-20211223215936642" style="zoom:50%;" /></p></li>
</ul></li>
<li><p>条件随机场以及马尔可夫随机场的区别主要就在于一个对条件概率建模，而另一个对联合概率建模。</p></li>
</ul>
<h5 id="学习与推断">学习与推断</h5>
<ul>
<li><p>基于概率图模型定义的联合概率分布，我们可以对目标变量的边际分布或者是以某些可观测变量为条件的条件分布进行推断。</p>
<ul>
<li>边际分布是指<strong>对联合分布中的其他无关变量进行积分或者求和的过程，也称该过程为边际化</strong>。</li>
</ul></li>
<li><p>并且，对于概率图模型，还需要确定一些具体分布的参数，该参数估计过程也可以被吸收到参数推断问题当中。</p>
<ul>
<li>具体而言，假设图模型有变量集<span class="math inline">\(x =\{x_1,x_2,...,x_N\}\)</span>能够分为<span class="math inline">\(x_E,x_F\)</span>两个不相交的变量集，推断问题的目标就是计算边际概率<span class="math inline">\(P(x_F)\)</span>或者条件概率<span class="math inline">\(P(x_F|x_E)\)</span>: <span class="math display">\[
  P(x_F|x_E) = \frac{P(x_E,x_F)}{P(x_E)} = \frac{P(x_E,x_F)}{\sum_{x_F}P(x_E,x_F)}
  \]</span> 而联合概率<span class="math inline">\(P(x_E,x_F)\)</span>可以通过概率图模型获得，因此重点就是计算边际分布: <span class="math display">\[
  P(x_E) = \sum_{x_F}P(x_E,x_F)
  \]</span> 对于该边际分布的计算，既可以采取精确计算的方式，但是其有指数时间复杂度，也可以采取近似推断的方式,其用较短的时间得到近似解。</li>
</ul></li>
<li><p>精确推断:</p>
<ul>
<li><p>变量消去:</p>
<ul>
<li>变量消去是<strong>通过先计算部分变量的加法来整合部分变量</strong>：</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112232229774.png" alt="image-20211223222947706" style="zoom:50%;" /></li>
</ul></li>
<li><p>不管是有向图还是无向图，该方法都是适用的。其缺点在于会造成大量冗杂运算。</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292139328.png" alt="image-20211229213951278" style="zoom:80%;"  /></li>
</ul></li>
<li><p>信念传播：</p>
<ul>
<li>主要用来解决变量消去算法中大量的重复计算过程。</li>
<li><strong>信念传播基于的现实就是每次消息传播的过程都是在邻接结点之间进行的</strong>，因此，我们可以规定一个结点只有在接受完所有结点的信息之后才能发送消息给其他结点。
<ul>
<li>以上面图片中的例子来说，<span class="math inline">\(x_3\)</span>必须接收到<span class="math inline">\(m_{23}(x_3),m_{43}(x_3)\)</span>两个信息，才能发送信息给<span class="math inline">\(x_5\)</span>。</li>
</ul></li>
<li>对于无环的图，信念传播只需要经过两步就可以了:
<ul>
<li><strong>指定</strong>一个根节点，<strong>让所有的叶节点传递信息给根节点，直到根节点的所有邻接结点都已经给根节点传了信息。</strong></li>
<li><strong>让根节点传递信息给所有的叶节点</strong></li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292140961.png" alt="image-20211229214016912" style="zoom: 80%;" /></li>
</ul></li>
</ul></li>
<li><p>近似推断</p>
<ul>
<li><p>近似推断有两种方案，一是通过采样(MCMC采样)来进行，使用<strong>随机化</strong>来完成近似,由大数定律保证近似可行；第二种确定性近似方法——<strong>变分推断</strong>。</p></li>
<li><p>MCMC采样:</p>
<ul>
<li><p>给定连续变量<span class="math inline">\(x\in X\)</span>的概率密度函数<span class="math inline">\(p(x)\)</span>,<span class="math inline">\(x\)</span>在某区间<span class="math inline">\(A\)</span>中的概率可以计算为: <span class="math display">\[
  P(A) = \int_A p(x) dx
  \]</span> 对于一个函数<span class="math inline">\(f(x)\)</span>: <span class="math display">\[
  p(f) = \mathbb{E}[f(X)] = \int_x f(x)p(x)dx
  \]</span> 通过采样构造出服从<span class="math inline">\(p\)</span>分布的独立同分布随机变量<span class="math inline">\(x_1,x_2,..,x_N\)</span>，得到一个无偏估计: <span class="math display">\[
  \hat{p}(f) = \frac{1}{N} \sum_{i=1}^N f(x_i)
  \]</span> 但是如果概率密度函数<span class="math inline">\(p(x)\)</span>很复杂，那么构造出<span class="math inline">\(p\)</span>分布的独立同分布采样也十分困难。MCMC采样的关键就是构造“平稳分布为p的马尔可夫立链",在假定马尔可夫链的状态转移概率为<span class="math inline">\(T(x^\prime|x)\)</span>,<span class="math inline">\(t\)</span>时刻的分布为<span class="math inline">\(p(x^t)\)</span> ,则马尔可夫链稳定的判定条件如下: <span class="math display">\[
  p(x^t) T(x^{t-1}|x^t) = p(x^{t-1}) T(x^t|x^{t-1})
  \]</span> 意为<strong>在t时刻的分布下状态转移到t-1时刻分布的概率与在t-1时刻的分布下状态转移到t时刻分布的概率相同</strong>。</p></li>
<li><p>MCMC采样的代表算法是Metropolis-Hastings:</p>
<ul>
<li><p>算法每次根据上一轮采样结果<span class="math inline">\(x^{t-1}\)</span>来采样获得候选状态样本<span class="math inline">\(x^*\)</span>,但是这个候选状态样本还会有一定概率被拒绝掉，假设状态<span class="math inline">\(x^{t-1}\)</span>到状态<span class="math inline">\(x^*\)</span>的转移概率为<span class="math inline">\(Q(x^*|x^{t-1})A(x^*|x^{t-1})\)</span>,其中<span class="math inline">\(Q(x^*|x^{t-1})\)</span>是用户给定的先验概率，<span class="math inline">\(A(x^*|x^{t-1})\)</span>是被拒绝的概率: <span class="math display">\[
  p(x^{t-1})Q(x^*|x^{t-1})A(x^*|x^{t-1})=p(x^*)Q(x^{t-1}|x^*)A(x^{t-1}|x^*)
  \]</span> <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241032616.png" alt="image-20211224103211514" style="zoom:50%;" /></p></li>
<li><p>为了到达平稳状态，接受概率需要设置为: <span class="math display">\[
  A(x^*|x^{t-1}) = \min (1,\frac{p(x^*)Q(x^{t-1}|x^*)}{p(x^{t-1})Q(x^*|x^{t-1})})
  \]</span></p></li>
<li><p>另外，吉布斯采样也是MH算法的特例，它也用了马尔科夫链获取样本，而该马尔可夫链的平稳分布也是目标分布：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241040128.png" alt="image-20211224104047071" style="zoom:50%;" /></p>
<p>具体而言:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241056226.png" alt="image-20211224105633164" style="zoom:50%;" /></p>
<p>实质上，吉布斯采样是对贝叶斯网的所有变量的联合状态空间中与证据<span class="math inline">\(E=e\)</span>一致的子空间中进行"随机漫步"(random walk)。</p></li>
</ul></li>
</ul></li>
<li><p>变分推断:</p>
<ul>
<li><p>变分推断使用已知的简单分布逼近需要推断的复杂分布，生成一个局部最优但是具有确定解的近似后验分布。</p></li>
<li><p>盘式记法:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241101773.png" alt="image-20211224110126700" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241104149.png" alt="image-20211224110402065" style="zoom:50%;" /></p>
<p>在E步中为了解决z模型复杂的问题，可以借助变分推断，假设z服从分布: <span class="math display">\[
  q(z) = \prod_{i=1}^M q_i(z_i)
  \]</span> 也就是说，假设复杂变量z能够被拆分成一系列独立的多变量<span class="math inline">\(z_i\)</span>，并且采用一些具有良好性质的<span class="math inline">\(q_i(\cdot)\)</span>。这一步就是关键了，通过对隐变量<span class="math inline">\(z\)</span>进行拆分，假设各个变量子集<span class="math inline">\(z_j\)</span>服从的分布，套用其说能满足的最优分布<span class="math inline">\(q_j^*\)</span>公式,然后用EM算法求解即可: <span class="math display">\[
  q_j^* = \frac{\exp(\mathbb{E}_{i\not=j}[\ln p(x,z)])}{\int \exp(\mathbb{E}_{i\not=j}[\ln p(x,z)])dz_j}
  \]</span> <span class="math inline">\(\mathbb{E}_{i\not=j}[\ln p(x,z)]\)</span>往往有闭式解(解析解、数值解、可以由表达式求出),该式子也称为平均场办法。</p></li>
</ul></li>
</ul></li>
</ul>
<h5 id="话题模型">话题模型</h5>
<ul>
<li><p>话题模型是一族生成式有向图模型，LDA（隐狄利克雷分配模型）是其代表。</p></li>
<li><p>话题模型中的一些基本概念:</p>
<ul>
<li>词：待处理数据的离散单元。</li>
<li>文档：由一组词组成，不计顺序。</li>
<li>话题：表示一系列相关的词。</li>
</ul></li>
<li><p>LDA认为每篇文档(<span class="math inline">\(\mathbf{W}=\{w_1,w_2,...,w_n\}\)</span>)有多个话题(用k个N维向量表示话题<span class="math inline">\(\beta_k\)</span>),<span class="math inline">\(w_i,\beta_i\)</span>的分量都表示词频,<span class="math inline">\(\Theta_t\)</span>表示文档<span class="math inline">\(t\)</span>中包含的话题比例，<span class="math inline">\(\Theta_{t,k}\)</span>表示文档<span class="math inline">\(t\)</span>中包含话题<span class="math inline">\(k\)</span>的比例，其步骤如下:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241117067.png" alt="image-20211224111739018" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241117015.png" alt="image-20211224111751973" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241122527.png" alt="image-20211224112202465" style="zoom:50%;" /></p></li>
<li><p>其对应的概率分布为:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241124078.png" alt="image-20211224112450019" style="zoom:50%;" /></p></li>
<li><p>给定训练数据<span class="math inline">\(\mathbf{W}\)</span>,LDA模型根据极大似然估计求解模型参数 <span class="math display">\[
  LL(\alpha,\eta)= \sum_{t=1}^T \ln p(w_t|\alpha,\eta)
  \]</span> 知道模型参数之后就可以根据<span class="math inline">\(\mathbf{W}\)</span>中的词频推断文档所对应的话题结构 <span class="math display">\[
  p(z,\beta,\Theta|\mathbf{W},\alpha,\eta) = \frac{p(\mathbf{W},z,\beta,\Theta|\alpha,\eta)}{p(\mathbf{W}|\alpha,\eta)} (*)
  \]</span> 其中，<span class="math inline">\(p(w_t|\alpha,\eta)\)</span>常常用变分法求解，<span class="math inline">\((*)\)</span>式子常用吉布斯采样或者变分法求解。</p></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>chap.15 规则学习</title>
    <url>/2021/12/24/%E8%A7%84%E5%88%99%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="规则学习">规则学习</h4>
<h5 id="基本概念">基本概念</h5>
<ul>
<li><p>规则通常是指语义明确、能描述数据分布隐含的客观规律或领域概念。规则学习就是从训练数据中学习出一组能够对未见实例进行判别的规则。</p></li>
<li><p>规则都形如: <span class="math display">\[
  rule\ head \leftarrow f_1 \land f_2\land ... \land f_L (rule \ body)
  \]</span></p>
<ul>
<li>并且可以细分为命题规则以及一阶规则。
<ul>
<li>命题规则：原子命题+逻辑与、或、非、蕴含构成</li>
<li>一阶规则：原子公式，有量词<span class="math inline">\(\forall,\exist\)</span>,能表达复杂的关系，因此亦称关系型规则。</li>
</ul></li>
</ul></li>
<li><p>如果一个示例被判别结果不同的多条规则覆盖了，那么我们认为发生了冲突，解决冲突的办法是冲突消解——采用投票、排序（优先级）、元规则（关于规则的规则——ex:冲突时，用长度最小的规则）。</p></li>
</ul>
<h5 id="序贯覆盖">序贯覆盖</h5>
<ul>
<li><p>规则学习的目标是产生一个能覆盖尽可能多的样例的规则集，最直接的就是“序贯覆盖”(sequential covering)——逐条归纳，也被称为分治(separate-and-conquer)策略。</p></li>
<li><p>最简单的做法是从空规则<span class="math inline">\(\oplus\leftarrow\)</span>开始，遍历训练集中的每个属性以及取值，如果其只包含正例就加入到规则体当中。</p></li>
<li><p>但是，上述穷举的做法并不能很好地完成组合爆炸的任务。一般有top-down，bottom-up两种策略进行优化:</p>
<ul>
<li><p>top-down产生的规则泛化性能更好，对于噪声的鲁棒性更好，常用于命题逻辑；而bottom-up更适合训练样本少的情况，常用于一阶规则学习。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241401834.png" alt="image-20211224140128750" style="zoom:50%;" /></p>
<p>先考虑规则准确率，准确率相同的时候考虑覆盖样例的数目，再相同的时候考虑属性优先顺序。</p></li>
<li><p>如果想要避免局部最优，可以利用集束搜索，每轮保留最优的<span class="math inline">\(b\)</span>个属性，并将它们全部加入下一轮的候选集当中</p></li>
</ul></li>
<li><p>另外，规则生成总归还是一个贪心搜索的过程，因此需要一定措施来缓解过拟合风险：</p>
<ul>
<li><p>预剪枝，规则生成过程中剪枝</p>
<ul>
<li><p>CN2算法用LRS似然率统计量作为指标：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241410428.png" alt="image-20211224141026351" style="zoom:50%;" /></p></li>
</ul></li>
<li><p>后剪枝，规则生成后剪枝:</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241411376.png" alt="image-20211224141149301" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241415427.png" alt="image-20211224141552359" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241416409.png" alt="image-20211224141657335" style="zoom:50%;" /></p></li>
</ul></li>
</ul></li>
</ul>
<h5 id="一阶规则学习">一阶规则学习</h5>
<h5 id="归纳逻辑程序设计">归纳逻辑程序设计</h5>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>Chap.11 特征选择与稀疏学习</title>
    <url>/2021/12/22/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E7%A8%80%E7%96%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="第十一章特征选择与稀疏学习">第十一章：特征选择与稀疏学习</h4>
<h5 id="特征">特征</h5>
<ul>
<li><p>相关特征:与当前学习任务相关</p></li>
<li><p>无关特征:与当前学习任务无关</p></li>
<li><p>冗杂特征:可以从其他特征中提取出来</p></li>
<li><p>从特征集合选出相关特征的过程就是特征提取。</p></li>
<li><p>特征提取的过程可以大为减轻维度灾难的问题，同时提取出重要的特征也可以降低学习的难度。</p></li>
<li><p>特征提取的一般过程：</p>
<ul>
<li>产生初始特征候选子集 —— 子集搜索</li>
<li>评价候选子集的好坏 —— 子集评价</li>
<li>基于评价结果产生下一个候选子集</li>
</ul>
<p><span id="more"></span></p></li>
<li><p>其中的关键就是子集搜索以及子集评价:</p>
<ul>
<li><p>对于子集搜索:</p>
<ul>
<li>前向搜索：逐渐增加相关特征，如果增加特征后的子集优于上一轮的最优子集，那就继续，否则结束；</li>
<li>后向搜索：从完整的特征集合开始，逐渐减少特征；</li>
<li>双向搜索：每一轮逐渐增加相关特征，同时减少无关特征。</li>
</ul></li>
<li><p>对于子集评价:</p>
<ul>
<li><p>其思想在于如果特征子集划分的数据集与样本标记划分的数据集差异越小，就认为这种特征子集划分方法越好。</p></li>
<li><p>可以用信息熵以及信息增益进行评价：</p>
<ul>
<li><p>定义第i类样本在D数据集中所占比例为<span class="math inline">\(p_i\)</span></p></li>
<li><p><span class="math display">\[
  Gain(A) = Ent(D) - \sum_{v=1}^{V} \frac{|D^v|}{|D|}Ent(D^v) \\
  Ent(D) = - \sum_{i=1}^{|\mathcal{Y}|} p_k \log_2 p_k 
  \]</span></p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>常见的特征选择方法：</p>
<ul>
<li><p>过滤式(filter)：</p>
<ul>
<li><p><strong>先对数据集进行特征选择，再训练学习器，也就是对数据集中的初始特征进行了一个过滤操作，学习器的性能表现不作为反馈。</strong></p></li>
<li><p>相关方法——Relief:其想法是设计一个相关统计量向量，向量的一个维度都对应着样本的每一个特征，那么特征子集的重要性就是向量各维度的和。选择我们需要的特征子集的时候，只需要设定一个阈值<span class="math inline">\(t\)</span>,大于<span class="math inline">\(t\)</span>的都选即可。</p></li>
<li><p>相关统计量如何设定呢？Relief的做法是对于训练集中的每个样本<span class="math inline">\(x_i\)</span>，在其同类样本中找到最近邻<span class="math inline">\(x_{i,nh}\)</span>作为猜中近邻(near-hit)，从异类样本中找到最近邻<span class="math inline">\(x_{i,nm}\)</span>作为猜错近邻(near-miss),那么相关统计量在属性j(第j维)上的表现就是： <span class="math display">\[
  \delta^j = \sum_i -diff(x_i^j, x_{i,nh}^j)^2 + diff(x_i^j, x_{i,nm}^j)^2
  \]</span></p></li>
<li><p>根据属性j是否连续，<span class="math inline">\(diff(x_a^j,x_b^j)\)</span>的计算方式也有差别。连续：<span class="math inline">\(|x_a^j-x_b^j|\)</span>,离散：<span class="math inline">\(x_a^j==x_b^j? 0:1\)</span></p></li>
<li><p>并且，上述式子表明如果属性j使得样本与其猜中近邻的距离小于样本与其猜错近邻的距离，那么，属性j对于区分样本类别是有益，我们给定的<span class="math inline">\(\delta^j\)</span>的值就是正的</p></li>
<li><p>Relirf是线性时间的，速度快</p></li>
<li><p>Relief针对二分类，多分类是Relief-F,其相关统计量的式子为: <span class="math display">\[
  \delta^j = \sum_i -diff(x_i^j, x_{i,nh}^j)^2 + \sum_{l\not=k} p_l \times diff(x_i^j, x_{i,l,nm}^j)^2
  \]</span> 可以看出只是一个简单拓展而已，也是通过衡量属性j能否使得样本与其猜中近邻的距离小于样本与其猜错近邻的距离，来判断属性j是否有益。</p></li>
</ul></li>
<li><p>包裹式(wrapper)</p>
<ul>
<li><strong>将学习器的性能作为特征子集的评价标准，因此，其目的在于给定学习器选择最有利于其性能的特征子集。</strong></li>
<li><strong>包裹式的性能常好于过滤式，但是由于需要训练多次，需要大量时间开销。</strong></li>
<li>LVW是一个典型代表：
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112211632108.png" alt="image-20211221163215946" style="zoom:50%;" /></li>
<li>其过程可以概括为，每次选出一个随机的特征子集，训练返回loss，记录最小loss的特征子集，如果连续k次最小loss都不变，那么，认为我们选出了对于训练学习器而言最有效的特征子集。</li>
<li>由于随机性的加入，LVW要么不给解，要么给出一个满足条件的解；而MC方法，一定给出解，但合适不合适不一定。</li>
</ul></li>
</ul></li>
<li><p>嵌入式(embedding)</p>
<ul>
<li><p><strong>嵌入式是将特征选择过程嵌入到学习器的训练过程当中，由学习器自动完成。</strong></p></li>
<li><p>对于一个简单的线性回归模型，以MSE作为loss，如果引入L2范数作为正则项，那么这就是岭回归问题；如果引入L1范数作为正则项，那么就是LASSO问题。他们都可以显著降低过拟合风险。</p></li>
<li><p>对于<strong>引入L1范数作为正则项，其更容易产生稀疏解，</strong>求得的权重<span class="math inline">\(w\)</span>含有的非零项更少。观察下图L2范数与L1范数等值线的形状以及可能与平方误差等值线相交的点的位置可知,L1范数等值线与平方误差等值线相交的点更容易出现在坐标轴上。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112211642656.png" alt="image-20211221164227586" style="zoom:33%;" /></p></li>
<li><p>因此，<strong>采用L1正则化进行训练，其实只用到了原始样本的一部分特征。</strong>L1正则化问题的求解可以使用近端梯度下降PGD。</p></li>
<li><p>PGD(近端梯度下降，利用了假设f(x)满足L-lipschitz条件):</p>
<ul>
<li><p>对于一个呈形如下的优化问题： <span class="math display">\[
  \min_x f(x)+\lambda ||x||_1
  \]</span> 如果<span class="math inline">\(f(x)\)</span>可导，并且<span class="math inline">\(\nabla f\)</span>满足<span class="math inline">\(L-Lipschitz\)</span>条件，即存在常数<span class="math inline">\(L&gt;0\)</span>对于<span class="math inline">\(\forall x,x^\prime\)</span>使得 <span class="math display">\[
  ||\nabla f(x^\prime) - \nabla f(x)||_2^2 \le L ||x^\prime - x||_2^2
  \]</span></p></li>
<li><p>将上式简单等价改写一下: <span class="math display">\[
  \frac{\partial^2 f(x_k)}{\partial x_k^2} =  \frac{||\nabla f(x^\prime) - \nabla f(x)||_2^2}{||x^\prime - x||_2^2} \le L
  \]</span></p></li>
<li><p>对于<span class="math inline">\(f(x)\)</span>,在<span class="math inline">\(x_k\)</span>附近展开二阶泰勒展开： <span class="math display">\[
  \hat{f}(x) = f(x_k) + &lt;\nabla f(x_k), x-x_k&gt; + \frac{1}{2}(x-x_k)^T \frac{\partial^2 f(x_k)}{\partial x_k^2} (x-x_k)\\ 
      \approx f(x_k) + &lt;\nabla f(x_k), x-x_k&gt; + \frac{L}{2} ||x-x_k||^2
  \]</span> 对上式将<span class="math inline">\(x-x_k\)</span>看成一个变量进行配方，我们就可以得到 <span class="math display">\[
  \hat{f}(x) = \frac{L}{2} [(x-x_k)^2 + \frac{2}{L}\nabla f(x_k)(x-x_k) ] + f(x_k) \\
      = \frac{L}{2} ||x - (x_k-\frac{1}{L}\nabla f(x_k))||^2 + const
  \]</span> 它的最小值在<span class="math inline">\(x_{k+1}\)</span>处取得 <span class="math display">\[
  x_{k+1} = x_k - \frac{1}{L}\nabla f(x_k)
  \]</span> 代入到原优化问题，我们可以得知原问题就是每一轮梯度下降迭代求解 <span class="math display">\[
  x_{k+1} = \arg \min_x \frac{L}{2} ||x - (x_k-\frac{1}{L}\nabla f(x_k))||^2 +\lambda ||x||_1
  \]</span></p></li>
<li><p>对于上式，我们可以先计算出<span class="math inline">\(z = x_k-\frac{1}{L}\nabla f(x_k)\)</span> ,然后我们就可以求解 <span class="math display">\[
  x_{k+1} = \arg \min_x \frac{L}{2} ||x - z||^2 +\lambda ||x||_1 (*)
  \]</span> 将<span class="math inline">\((*)\)</span>式按照分量展开,即按照<span class="math inline">\(x^i\)</span>(表示<span class="math inline">\(x\)</span>的第i个分量)展开，不存在<span class="math inline">\(\alpha_i^u \alpha_i^v(u\not=v)\)</span>这样的交叉项,也就是说<span class="math inline">\(x\)</span>的各分量之间是互不影响的。也就是说，对于每一个<span class="math inline">\(x\)</span>的一个分量而言<span class="math inline">\((*)\)</span>式就是一个二元一次方程，可以轻松求解argmin。那么，对于每个分量单独求解 <span class="math display">\[
  x_{k+1}^i = \left\{
  \begin{aligned}
    &amp; z^i - \frac{\lambda}{L}, \frac{\lambda}{L}  &lt; z^i \\
    &amp; 0, | z^i| \le \frac{\lambda}{L} \\
    &amp; z^i + \frac{\lambda}{L},z^i &lt; -\frac{\lambda}{L}
  \end{aligned}
  \right.
  \]</span></p></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h5 id="稀疏表示">稀疏表示</h5>
<ul>
<li><p>一般来说，稀疏表示指的是矩阵中有很多零元素，且并非整行整列地出现，当然整行整列也行。</p></li>
<li><p><strong>通过稀疏表示，在训练时，我们可以去除不必要的行或列，从而降低学习难度</strong>，并且稀疏表示降低了存储开销，文本数据可以线性可分。</p></li>
<li><p>那么，我们就需要<strong>探寻一种方式能够将普通稠密表达的样本变成稀疏表示</strong>。</p></li>
<li><p>而一种典型的方法就是<strong>字典学习</strong>：</p>
<ul>
<li><p>字典学习最普通的形式就是，对于一个k个词汇的字典可以用一个矩阵<span class="math inline">\(\mathbf{B} \in R^{d\times k}\)</span> 表示（这里将字典翻译的过程看成是乘以一个权重矩阵）,假设<span class="math inline">\(\alpha_i \in R^k\)</span>是样本<span class="math inline">\(x_i \in R^d\)</span> 的稀疏表示，那么问题可以转化为: <span class="math display">\[
  \min_{\mathbf{B},\alpha_i} \sum_{i=1}^m ||x_i - \mathbf{B}\alpha_i||_2^2 + \lambda \sum_{i=1}^m ||\alpha_i||_1 \ \ (*)
  \]</span> 第一项意为希望<span class="math inline">\(\alpha_i\)</span>可以重构<span class="math inline">\(x_i\)</span> ,并且重构前后误差最小化，第二项表示希望<span class="math inline">\(\alpha_i\)</span>尽量稀疏。</p></li>
<li><p>这个问题求解比LASSO更麻烦一些，需要学习<span class="math inline">\(\mathbf{B},\alpha_i\)</span>两个参数。</p></li>
<li><p>借鉴LASSO，可以采用变量交替优化的策略求解:</p>
<ul>
<li><p>第一步，固定字典<span class="math inline">\(\mathbf{B}\)</span>,将<span class="math inline">\((*)\)</span>式按照分量展开，不存在<span class="math inline">\(\alpha_i^u \alpha_i^v(u\not=v)\)</span>这样的交叉项，就可以参考LASSO的解法求解下式，为每个样本<span class="math inline">\(x_i\)</span>找到响应的<span class="math inline">\(\alpha_i\)</span> : <span class="math display">\[
  \min_{\alpha_i}  ||x_i - \mathbf{B}\alpha_i||_2^2 + \lambda  ||\alpha_i||_1
  \]</span></p></li>
<li><p>第二步，固定<span class="math inline">\(\alpha_i\)</span> 更新<span class="math inline">\(\mathbf{B}\)</span> ,此时的优化问题是 <span class="math display">\[
  \min_{\mathbf{B}} ||\mathbf{X} - \mathbf{B}\mathbf{A}||_F^2
  \]</span> F表示的是矩阵Frobenius范数。一种常用的求解上式的方式是基于逐列更新策略的<span class="math inline">\(KSVD\)</span> 。 <span class="math display">\[
  \min_{\mathbf{B}} ||\mathbf{X} - \mathbf{B}\mathbf{A}||_F^2 = \min_{\mathbf{b_i}} ||\mathbf{X} - \sum_{j=1}^k b_j \alpha^j||_F^2 \\
  =\min_{\mathbf{b_i}} ||(\mathbf{X} - \sum_{j\not=i} b_j \alpha^j) - b_i \alpha^i||_F^2 \\
  =\min_{\mathbf{b_i}} ||\mathbf{E}_i - b_i \alpha^i||_F^2
  \]</span> 在更新字典的第<span class="math inline">\(i\)</span>列的时候，其他各列都是固定的，因此<span class="math inline">\(\mathbf{E}_i = \sum_{j\not=i} b_j \alpha^j\)</span></p></li>
</ul></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统</title>
    <url>/2022/02/27/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h5 id="推荐系统">推荐系统</h5>
<h6 id="常用算法">常用算法</h6>
<ul>
<li>基于知识的推荐系统:
<ul>
<li>通过一定的工具，可能是NLP也可能是其他的，基于相似性生成推荐。</li>
</ul></li>
<li>基于内容的推荐系统:
<ul>
<li>通过用户过去的交互行为，比如最近购买的几个商品的属性相似度来进行推荐。但是有一定的范围限制。</li>
</ul></li>
<li>协同过滤:
<ul>
<li>基于整个用户群的过去交互,因此会比之前的算法都要精确得多。</li>
<li>最常见的就是基于k阶近邻的接收到测试样本:
<ul>
<li>找出当前用户最近的k个邻居，利用这k+1个构成一个聚类，然后进行排序并推荐。</li>
<li>也可以产生两种变体:基于商品或者是基于用户的推荐方案。</li>
<li>k阶近邻的协同过滤算法是懒惰学习的一种，在接收到测试样本的时候，才能进行训练。</li>
</ul></li>
<li>还有一种方案是基于规则的学习，但是它每次接收到测试样本都要进行重新训练。</li>
<li>另一种是基于分解的的学习方法。</li>
</ul></li>
</ul>
<span id="more"></span>
]]></content>
      <categories>
        <category>Learn Recommand System</category>
      </categories>
      <tags>
        <tag>ForWork</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>数字信号处理Review</title>
    <url>/2021/12/24/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86review/</url>
    <content><![CDATA[<h3 id="chap.0">Chap.0</h3>
<h4 id="信号基本概念">信号基本概念</h4>
<ul>
<li><p>信号的分类</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241504910.png" alt="image-20211224150458847" style="zoom:67%;" /></p>
<span id="more"></span></li>
<li><p>信号之间的关系</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241508522.png" alt="image-20211224150838463" style="zoom:50%;" /></p></li>
<li><p>离散信号的表示:</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241514194.png" alt="image-20211224151421137" style="zoom: 33%;" /></p></li>
<li><p>可以将离散信号看成连续信号以及周期脉冲信号的乘积。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241534080.png" alt="image-20211224153450031" style="zoom: 50%;" /></p>
<p>因此，离散信号的周期与连续信号以及周期脉冲信号的周期有关。正弦序列不一定是周期序列，因为还要有周期脉冲信号的信息才能确定。</p></li>
</ul></li>
</ul></li>
<li><p>基本概念:</p>
<ul>
<li>频率：信号每单位时间变化的次数(Hz)
<ul>
<li>传输的信号距离远的话，要用高频信号，因为信号会衰减。</li>
</ul></li>
<li>时域：以时间为自变量，也可以称为变换域（不以频率为自变量）</li>
<li>频域：以频率为自变量</li>
<li>频谱： 信号的频域表示，用来表示信号的幅度与相位。</li>
<li>滤波器：按照一定目的对信号进行变换</li>
<li>基波角频率：信号频率的最小公倍数</li>
<li>复数：
<ul>
<li><span class="math inline">\(j = i = \sqrt{-1}\)</span></li>
<li>直角坐标表示: <span class="math inline">\(z = x + j y, x = Re[z],y = Im[z]\)</span></li>
<li>复数的模<span class="math inline">\(|z| = \sqrt{x^2 + y^2}\)</span></li>
<li>复数的相位<span class="math inline">\(arc(z) = \arctan(\frac{y}{x})\)</span></li>
</ul></li>
<li>欧拉公式:
<ul>
<li><span class="math inline">\(e^{jwt} = \cos wt + j \sin wt\)</span></li>
<li><span class="math inline">\(e^{-jwt} = \cos wt - j \sin wt\)</span></li>
<li>$ wt = $</li>
<li><span class="math inline">\(\sin wt = \frac{e^{jwt} - e^{-jwt}}{2j}\)</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="chap.1">Chap.1</h3>
<h4 id="周期信号">周期信号</h4>
<ul>
<li>对于连续信号，存在正数<span class="math inline">\(T\)</span>,使得<span class="math inline">\(x(t+T) = x(t),\forall t \in \mathbb{R}\)</span></li>
<li>对于离散信号，存在正整数<span class="math inline">\(N\)</span>,使得<span class="math inline">\(x[n+N] = x[n],\forall n \in \mathbb{N}\)</span></li>
<li>满足上述条件的最小的<span class="math inline">\(T,N\)</span>就是基波周期。</li>
<li>对于两个周期信号<span class="math inline">\(x(t),y(t)\)</span>,其周期分别是<span class="math inline">\(T_1,T_2\)</span>,如果周期之比<span class="math inline">\(\frac{T_1}{T_2}\)</span>是有理数，那么其和信号<span class="math inline">\(x(t)+y(t)\)</span>仍然是周期信号，且周期为<span class="math inline">\(T_1,T_2\)</span>的最小公倍数。
<ul>
<li>任意两个离散周期序列的和仍然是周期序列。</li>
<li>离散信号按照连续信号算得周期为有理数则其为周期离散信号</li>
</ul></li>
<li>周期信号以及非周期信号都可以分解成周期信号。</li>
</ul>
<h4 id="能量信号与功率信号">能量信号与功率信号</h4>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241540355.png" alt="image-20211224154000273" style="zoom:50%;" />
<ul>
<li>信号不可能同时既是功率信号，又是能量信号</li>
</ul></li>
</ul>
<h4 id="因果信号">因果信号</h4>
<ul>
<li>定义为：
<ul>
<li>当<span class="math inline">\(t&lt;0\)</span>的时候，<span class="math inline">\(x(t)=0\)</span>;当<span class="math inline">\(t&gt;0\)</span>的时候，<span class="math inline">\(x(t)\not=0\)</span></li>
</ul></li>
</ul>
<h4 id="信号的基本变换">信号的基本变换</h4>
<ul>
<li><span class="math inline">\(x(t)\rightarrow x(at)\)</span>:
<ul>
<li>如果<span class="math inline">\(0&lt;a&lt;1\)</span>,<span class="math inline">\(x(at)\)</span>是<span class="math inline">\(x(t)\)</span>的拓展。</li>
<li>如果<span class="math inline">\(a&gt;1\)</span>,<span class="math inline">\(x(at)\)</span>是<span class="math inline">\(x(t)\)</span>的压缩。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241547490.png" alt="image-20211224154705443" style="zoom: 50%;" /></li>
</ul></li>
<li><span class="math inline">\(x(t)\rightarrow x(-t)\)</span>:
<ul>
<li>对图像按照<span class="math inline">\(x(t)\)</span>进行翻转</li>
</ul></li>
<li><span class="math inline">\(x(t)\rightarrow x(t+t_0)\)</span>:
<ul>
<li>向左移动<span class="math inline">\(t_0\)</span></li>
<li>注意<span class="math inline">\(x(t)\rightarrow x(t+t_0)\)</span>指的是将原先信号表达式中的<span class="math inline">\(t\)</span>用<span class="math inline">\(t+t_0\)</span>代替。</li>
</ul></li>
<li><span class="math inline">\(x(t)\rightarrow x(t-t_0)\)</span>:
<ul>
<li>向右移动<span class="math inline">\(t_0\)</span></li>
<li>注意<span class="math inline">\(x(t)\rightarrow x(t-t_0)\)</span>指的是将原先信号表达式中的<span class="math inline">\(t\)</span>用<span class="math inline">\(t-t_0\)</span>代替。</li>
</ul></li>
</ul>
<h4 id="典型信号">典型信号</h4>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241559701.png" alt="image-20211224155911615" style="zoom:50%;" /></p>
<ul>
<li><p>(*)抽样信号： <span class="math display">\[
  Sa(t) = \frac{\sin t}{t}
  \]</span></p>
<ul>
<li>其图像如下：</li>
</ul>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241604350.png" alt="image-20211224160412298" style="zoom:50%;" /></p>
<ul>
<li><p>零点位置位于<span class="math inline">\(t = \pm n\pi\)</span>的时候</p></li>
<li><p>性质：</p>
<ul>
<li><span class="math inline">\(\int_{-\infty}^{+\infty} Sa(t) dt = \pi\)</span></li>
<li><span class="math inline">\(\int_{0}^{+\infty} Sa(t) dt = \frac{\pi}{2}\)</span></li>
</ul></li>
</ul></li>
<li><p>单位脉冲序列：</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241610394.png" alt="image-20211224161049355" style="zoom:50%;" /></li>
<li>因此，离散信号可以使用<span class="math inline">\(\delta[n]\)</span>进行移位合成。</li>
<li>且其他信号与<span class="math inline">\(\delta[n]\)</span>相乘时会进行抽样:<span class="math inline">\(x[n]\delta[n-n_0]=x[n_0]\delta[n-n_0]\)</span></li>
</ul></li>
<li><p>单位阶跃序列/单位阶跃信号:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241616633.png" alt="image-20211224161610576" style="zoom:50%;" /></li>
<li><span class="math inline">\(u[n]\)</span>可以用<span class="math inline">\(\delta[n]\)</span>累加而得，<span class="math inline">\(\delta[n] = u[n] - u[n-1]\)</span></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241824584.png" alt="image-20211224182453506" style="zoom: 50%;" /></li>
</ul></li>
<li><p>矩形序列:</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241719697.png" alt="image-20211224171955639" style="zoom:50%;" /></p></li>
<li><p>斜变序列/斜边信号</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241720998.png" alt="image-20211224172036948" style="zoom:50%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241824523.png" alt="image-20211224182406474" style="zoom:50%;" /></li>
</ul></li>
<li><p>差分：</p>
<ul>
<li>前向差分：<span class="math inline">\(\Delta x[n] = x[n+1] - x[n]\)</span></li>
<li>后向差分：<span class="math inline">\(\nabla x[n] = x[n] - x[n-1]\)</span></li>
</ul></li>
<li><p>奇异信号：</p>
<ul>
<li>如果原信号或者信号的导数有不连续点，那么它就是奇异信号。</li>
</ul></li>
<li><p>冲激信号：</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241833279.png" alt="image-20211224183311233" style="zoom:50%;" /></p></li>
<li><p>冲激信号可用于表示其他任意信号或表示信号间断点的导数,表示间断点处的导数值的变化趋势等。</p></li>
<li><p>展缩性质：<span class="math inline">\(\delta(\alpha t) = \frac{1}{|\alpha|} \delta(t),\alpha \not=1\)</span></p></li>
<li><p>对于<span class="math inline">\(\delta(\alpha t+\beta)\)</span>要先转化成<span class="math inline">\(\delta(t + \frac{\beta}{\alpha})\)</span></p></li>
<li><p>任意的离散序列都可以转分解成单位脉冲信号以及序列的和： <span class="math display">\[
  x[n] = \sum_{-\infty}^{+\infty} x[k] \delta(n-k)
  \]</span> 该式子亦被称为序列的脉冲分解。</p></li>
</ul></li>
</ul>
<h4 id="信号的向量表示">信号的向量表示</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241850595.png" alt="image-20211224185005502" style="zoom:50%;" /></p></li>
<li><p>若<span class="math inline">\(&lt;x_1(t),x_2(t)&gt;=0\)</span>则两函数正交</p></li>
<li><p>当我们需要重构<span class="math inline">\(x_1\)</span>时，根据内积的性质：</p></li>
<li><p><span class="math inline">\(x_1(t) = \frac{&lt;x_1(t),x_2(t)&gt;}{&lt;x_2(t),x_2(t)&gt;}x_2(t)\)</span></p></li>
<li><p>正交函数集:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241853943.png" alt="image-20211224185326880" style="zoom:50%;" /></p></li>
<li><p>完备函数集：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241853299.png" alt="image-20211224185352245" style="zoom:50%;" /></p></li>
</ul>
<h5 id="信号的分解">信号的分解</h5>
<ul>
<li>一个信号可以拆分成奇分量以及偶分量：
<ul>
<li><span class="math inline">\(x(t) = x_e(t) + x_o(t)\)</span></li>
<li><span class="math inline">\(x_e(t) = \frac{x(t) + x(-t)}{2}\)</span>,显然这是偶函数</li>
<li><span class="math inline">\(x_e(t) = \frac{x(t) - x(-t)}{2}\)</span> ,显然这是奇函数</li>
</ul></li>
</ul>
<h3 id="chap.2">Chap.2</h3>
<h4 id="系统基本性质以及分类">系统基本性质以及分类</h4>
<ul>
<li><p>系统按照输入信号和输出信号的连续以及离散性质可以分成连续时间系统和离散时间系统。</p></li>
<li><p>两种系统的方框图图标:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241906132.png" alt="image-20211224190602071" style="zoom:50%;" /></li>
</ul></li>
<li><p>系统的性质</p>
<ul>
<li>记忆性：
<ul>
<li>无记忆系统：<strong>系统的输出只取决于系统该时刻的输入</strong>,y(t)只跟x(t)有关</li>
</ul></li>
<li>可逆性：
<ul>
<li>系统在不同的输入下，导致不同的输出，则系统可逆</li>
<li>如果一个系统可逆，则<strong>存在一个逆系统，系统与逆系统级联，作用等效于恒等系统</strong>，即<span class="math inline">\(y^{-1}y(x) = x\)</span></li>
</ul></li>
<li>因果性：
<ul>
<li>当且仅当输入信号激励系统时才产生系统输出响应的系统</li>
<li>如果<strong>响应𝑦(𝑡)并不依赖于将来的激励</strong>，如𝑥(𝑡+1)，那么系统就是因果的</li>
<li>y(n+1),y(-n),y(2n)都不是因果的。</li>
</ul></li>
<li>稳定性：
<ul>
<li>有界输入造成有界输出。</li>
<li>不稳定系统的例子：<span class="math inline">\(y = tx(t)\)</span>,<span class="math inline">\(x(t)\)</span>是有界的，但是<span class="math inline">\(t\)</span>是可以趋向无穷的。</li>
</ul></li>
<li>线性：
<ul>
<li>如果<span class="math inline">\(x_1(t)\rightarrow y_1(t),x_2(t)\rightarrow y_2(t)\)</span>,那么系统如果满足<span class="math inline">\(\alpha x_1(t) + \beta x_2(t) = \alpha y_1(t) + \beta y_2(t)\)</span> ,则该系统是线性的。</li>
</ul></li>
<li>时不变系统:
<ul>
<li>系统的输出响应与输入激励的关系不随输入激励作用于系统的时间起点而改变，就称为时不变系统。否则，就称为时变系统。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241917079.png" alt="image-20211224191722026" style="zoom:50%;" /></li>
<li>是不是时不变系统只需要观察，原信号<span class="math inline">\(y(t)\)</span>除了含有<span class="math inline">\(x(t)\)</span>成分外，还有没有其他只含有<span class="math inline">\(t\)</span>元素</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241921305.png" alt="image-20211224192135247" style="zoom: 50%;" /></li>
</ul></li>
<li>Linear Time Invariant (LTI)线性时不变系统。</li>
</ul></li>
</ul>
<h4 id="卷积和">卷积和</h4>
<ul>
<li><p>单位脉冲响应<span class="math inline">\(h_k[n]\)</span>是 <span class="math inline">\(\delta[n-k]\)</span> 的系统输出系统,可以借助单位脉冲响应来判断时不变性质，系统的响应表示为 <span class="math display">\[
  y[n] = \sum_{k=-\infty}^{+\infty} x[k] h[n-k]
  \]</span> 这也是卷积和的定义方式，记为<span class="math inline">\(y[n] = x[n] * h[n]\)</span></p>
<ul>
<li>卷积和主要是离散化连续信号的时候，逼近连续信号的卷积。</li>
</ul></li>
</ul>
<h4 id="卷积积分">卷积积分</h4>
<ul>
<li>信号的卷积积分<span class="math inline">\(y(t) = x(t) * h(t)\)</span>: <span class="math display">\[
  y(t) = x(t) * h(t) = \int_{-\infty}^{+\infty}x(\tau)h(t-\tau)d\tau
  \]</span></li>
</ul>
<h4 id="卷积积分的性质">卷积积分的性质</h4>
<ul>
<li><p>交换</p></li>
<li><p>分配</p></li>
<li><p>结合</p></li>
<li><p>平移特性：</p>
<ul>
<li>如果<span class="math inline">\(x_1(t) * x_2(t) = y(t)\)</span>，<span class="math inline">\(x_1(t-t_1) * x_2(t-t_2) = y(t-t_1-t_2)\)</span></li>
</ul></li>
<li><p>展缩特性：</p>
<ul>
<li>如果<span class="math inline">\(x_1(t) * x_2(t) = y(t)\)</span>，<span class="math inline">\(x_1(at) * x_2(at) = \frac{1}{|a|}y(at)\)</span></li>
</ul></li>
<li><p>微分性质:</p>
<ul>
<li><span class="math inline">\(\frac{d}{dt}[x_1(t) * x_2(t)] = \frac{d}{dt}[x_1(t)] * x_2(t) = x_1(t) * \frac{d}{dt}[x_2(t)]\)</span></li>
</ul></li>
<li><p>积分性质：</p>
<ul>
<li><p>与微分性质类似，只需要卷积的积分等于一个函数积分之后再卷积：</p>
<ul>
<li>$<em>{-}^t [x_1() * x_2()]d = </em>{-}^t x_1() d x_2(t) = x_1(t) *_{-}^t x_2() d $</li>
</ul></li>
<li><p>可以将积分与微分性质概括为:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242023409.png" alt="image-20211224202305355" style="zoom:50%;" /></p></li>
</ul></li>
</ul>
<h4 id="卷积和的性质">卷积和的性质</h4>
<ul>
<li>交换</li>
<li>结合</li>
<li>分配</li>
<li>位移特性:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242049261.png" alt="image-20211224204932201" style="zoom:50%;" /></li>
</ul></li>
<li>差分与求和特性:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242051624.png" alt="image-20211224205103553" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="奇异信号的卷积">奇异信号的卷积</h4>
<ul>
<li><span class="math inline">\(\delta(t)*\delta(t) = \delta(t)\)</span></li>
<li><span class="math inline">\(x(t)*\delta(t-T) = x(t-T)\)</span></li>
<li><span class="math inline">\(x(t) * u(t) = x^{(-1)}(t)\)</span>,也就是给<span class="math inline">\(x(t)\)</span>进行了一次积分</li>
<li><span class="math inline">\(x(t)*\delta^\prime(t) = x^\prime(t)\)</span></li>
<li><span class="math inline">\(u(t) * u(t) = r(t) = tu(t)\)</span></li>
<li>因此，我们可以通过使用<span class="math inline">\(u(t),\delta(t),\delta(t-t_0)\)</span>来分别进行积分、直通、延时操作</li>
</ul>
<h4 id="系统的冲激响应">系统的冲激响应</h4>
<ul>
<li>对于级联系统，交换两个级联系统不影响结果，对子系统先进行卷积也不影响结果,即下面的三个系统等价:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242056416.png" alt="image-20211224205637357" style="zoom:50%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242057108.png" alt="image-20211224205702053" style="zoom:50%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242057839.png" alt="image-20211224205712781" style="zoom:50%;" /></li>
</ul></li>
<li>典型的并联系统如下：
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242058459.png" alt="image-20211224205808390" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="因果系统">因果系统</h4>
<ul>
<li>因果系统是指系统𝑡0时刻的输出只和𝑡0时刻及以前的输入信号有关</li>
<li>对于一个LTI系统,它是因果系统的充要条件是单位脉冲响应为0，在负半轴的情况下：
<ul>
<li>连续：<span class="math inline">\(h(t)=0,t&lt;0\)</span></li>
<li>离散：<span class="math inline">\(h[n]=0,n&lt;0\)</span></li>
<li>单位脉冲响应： 输入信号<span class="math inline">\(x(t) = \delta(t)\)</span></li>
</ul></li>
</ul>
<h4 id="稳定系统">稳定系统</h4>
<ul>
<li>若系统对任意的有界输入其输出也有界，则称该系统是稳定系统。</li>
<li>对于一个LTI系统,它是稳定系统的充要条件是对单位脉冲响应积分或者求和的结果有界:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242117359.png" alt="image-20211224211708302" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="lti系统与单位脉冲响应">LTI系统与单位脉冲响应</h4>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242120314.png" alt="image-20211224212043241" style="zoom:50%;" /></p>
<h4 id="相关运算">相关运算</h4>
<p><span class="math display">\[
x(t) \star h(t) = \int_{-\infty}^{+\infty} x(\tau)  h(\tau+t)d\tau
\]</span></p>
<ul>
<li>不满足交换律</li>
<li><span class="math inline">\(x(t) \star h(t) = x(-t) * h(t)\)</span></li>
<li>可以通过内积衡量两个信号的相似性。</li>
</ul>
<h3 id="chap.3">Chap.3</h3>
<h4 id="微分方程及其求解">微分方程及其求解</h4>
<ul>
<li><p>如果一个线性系统，起始没有储能，那么他就构成了一个线性时不变系统。</p></li>
<li><p>微分方程的一般形式：</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242142347.png" alt="image-20211224214210273" style="zoom:50%;" /></p></li>
<li><p>微分方程的完全解由齐次解以及特解构成。</p>
<ul>
<li>齐次解:输入各项为0时的解。</li>
<li>特解：微分方程的任意一个解。</li>
<li>还需要根据初始条件求解待定系数。</li>
</ul></li>
<li><p>求齐次解：</p>
<ul>
<li><p>齐次解的形式为<span class="math inline">\(Ae^{\alpha t}\)</span></p></li>
<li><p>因此，根据 <span class="math display">\[
  y^{(N)}(t)+a_{N-1}y^{(N-1)}(t)+...+a_1y^\prime(t)+a_0y(t)=0
  \]</span> 可以得出特征方程 <span class="math display">\[
  \alpha^N +a_{N-1}\alpha^{N-1}+...+a_0=0
  \]</span> 其有<span class="math inline">\(N\)</span>个特征根，<span class="math inline">\(\alpha_1,...,\alpha_N\)</span></p>
<p>有重根的情况下，</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242209005.png" alt="image-20211224220921925" style="zoom:50%;" /></p></li>
</ul></li>
<li><p>求特解:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242221120.png" alt="image-20211224222123031" style="zoom:50%;" /></li>
<li><span class="math inline">\(y_h(t)\)</span>特解是将<span class="math inline">\(x(t)\)</span>的实际表达式代入之后，在判断特解的形式。</li>
<li>之后，再代入左边<span class="math inline">\(y(t)\)</span>的表达式中，求待定系数。</li>
</ul></li>
<li><p>求完特解就要根据初始条件(或者说叫边界条件)求待定系数。</p>
<ul>
<li>要把初始条件代入完全解当中求解。</li>
</ul></li>
</ul>
<h4 id="差分方程及其求解">差分方程及其求解</h4>
<ul>
<li><p>差分方程的一般形式：</p>
<ul>
<li><span class="math display">\[
  \sum_{i=0}^N a_i y[n-i] = \sum_{j=0}^M b_j x[n-j]
  \]</span></li>
</ul></li>
<li><p>与微分方程类似地，当差分方程的输入激励项均为0时，方程的解是齐次解：</p>
<ul>
<li><p>差分方程的齐次解的形式为<span class="math inline">\(C\alpha^n\)</span>的线性组合</p>
<ul>
<li><p>代入差分方程之后： <span class="math display">\[
  \sum_{k=0}^N a^k \alpha^{N-k} = 0
  \]</span></p></li>
<li><p><span class="math inline">\(y_h[n] = \sum_{i=1}^N C_i \alpha_i^n\)</span></p></li>
<li><p>这里需要注意的是差分方程中的 次项是<span class="math inline">\(N-k\)</span>,而微分方程中 此项是跟<span class="math inline">\(y(t)\)</span>次项一致的,以例子来说：</p>
<ul>
<li>微分方程<span class="math inline">\(y^{(i)} \rightarrow a_i \alpha^i\)</span></li>
<li>差分方程<span class="math inline">\(y[n-k] \rightarrow a_k \alpha^{N-k-1}\)</span> ,<span class="math inline">\(N\)</span>与<span class="math inline">\(y[n-i]\)</span>的求和数相等。</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>特解的形式:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251049928.png" alt="image-20211225104926821" style="zoom:50%;" /></p>
<ul>
<li><span class="math inline">\(u(t)\)</span>的特解为常数<span class="math inline">\(1\)</span></li>
</ul></li>
<li><p>把初始条件代入完全解求待定系数</p></li>
</ul>
<h4 id="初始松弛条件">初始松弛条件</h4>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251111073.png" alt="image-20211225111140001" style="zoom:50%;" /></p>
<h4 id="自由响应与强迫响应">自由响应与强迫响应</h4>
<ul>
<li>齐次解对应着自由响应</li>
<li>特解对应着强迫响应</li>
</ul>
<h4 id="零输入响应与零状态响应">零输入响应与零状态响应</h4>
<ul>
<li><p>零输入响应:</p>
<ul>
<li><p>无输入激励信号，仅由系统的起始状态单独作用而产生的响应。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251119327.png" alt="image-20211225111900275" style="zoom:50%;" /></p></li>
<li><p>零输入响应与齐次解的系数不同，且零输入响应仅由起始储能状态决定，但是齐次解既跟起始状态相关，也跟激励信号有关（齐次解的待定系数与激励信号有关）。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251134937.png" alt="image-20211225113438880" style="zoom:50%;" /></p>
<p>得到齐次解之后，可以直接将初始条件代入。</p>
<ul>
<li>说到底，零输入响应的初始条件是<span class="math inline">\(y(0_-)\)</span>,而齐次解的起始条件诸如<span class="math inline">\(y(0)\)</span></li>
</ul></li>
</ul></li>
<li><p>零状态响应：</p>
<ul>
<li>起始状态为0的条件下，外加激励信号产生的响应。
<ul>
<li>也就是说，零状态响应假定了<span class="math inline">\(y(0_+)\)</span>为0</li>
<li>并可以将此代入完全解当中，求完全解的待定系数</li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251119253.png" alt="image-20211225111913203" style="zoom:50%;" /></li>
<li>如果<span class="math inline">\(y(0_-)\rightarrow y(0_+)\)</span>有跳变，就会出现在零状态响应当中。</li>
<li>如果没有跳变，<span class="math inline">\(y(0_-)=y(0_+)\)</span></li>
<li>零状态响应也是<span class="math inline">\(x(t)*h(t)\)</span></li>
</ul></li>
<li><p>完全响应</p>
<ul>
<li>完全响应既是齐次解与特解的和，又是零输入响应与零状态响应的和</li>
</ul></li>
</ul>
<h3 id="chap.4">Chap.4</h3>
<ul>
<li>三角函数与复指函数都可以构成完备正交函数集。
<ul>
<li><span class="math inline">\(w = \frac{2\pi}{T}\)</span>是可以利用的</li>
</ul></li>
</ul>
<h4 id="信号基于函数集的分解">信号基于函数集的分解</h4>
<ul>
<li><p>三角函数族的分解：</p>
<ul>
<li><p><span class="math display">\[
  a_0 = \frac{1}{T} \int_{t_0}^{t_0+T} x(t) dt \\
  a_n = \frac{2}{T} \int_{t_0}^{t_0+T} x(t)\cos(nwt) dt = a_{-n}\\
  b_n = \frac{2}{T} \int_{t_0}^{t_0+T} x(t)\sin(nwt) dt = - b_{-n}\\
  x(t) = a_0 + \sum_{n=1}^{+\infty} a_n \cos(nwt) +\sum_{n=1}^{+\infty} b_n \sin(nwt)
  \]</span></p></li>
<li><p><span class="math inline">\(a_0\)</span>为直流分量，<span class="math inline">\(a_n\)</span>为余弦分量，<span class="math inline">\(b_n\)</span>为正弦分量</p></li>
</ul></li>
<li><p>指数函数族的分解：</p>
<ul>
<li><p><span class="math display">\[
  X_n = \frac{1}{T}\int_{t_0}^{t_0+T} x(t)\cdot e^{-jnwt} dt \\
  x(t) = \sum_{-\infty}^{+\infty} X_n e^{jnwt} \\
   = \sum_{-\infty}^{+\infty} X_n (\cos(nwt) + j\sin(nwt) )
  \]</span></p></li>
<li><p>因此，指数函数族的分解与三角函数族的分解之间有所联系: <span class="math display">\[
  X_n= \frac{1}{2} a_n - \frac{j}{2} b_n \\
  X_n^*= \frac{1}{2} a_n + \frac{j}{2} b_n %共轭
  \]</span> <span class="math inline">\(X_n^*\)</span>表示共轭</p></li>
</ul></li>
</ul>
<h4 id="傅里叶变换思路">傅里叶变换思路</h4>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251300911.png" alt="image-20211225130030832" style="zoom:50%;" /></p>
<h4 id="傅里叶级数">傅里叶级数</h4>
<ul>
<li><p>周期信号的傅里叶级数三角形式表示也正是信号基于三角函数族分解的形式。</p>
<ul>
<li><p><span class="math display">\[
  x(t) = a_0 + \sum_{n=1}^{+\infty} a_n \cos(nwt) +\sum_{n=1}^{+\infty} b_n \sin(nwt) \\
   = c_0 + \sum_{n=1}^{+\infty} c_n \cos(nwt+\phi_n) \\
   c_n = \sqrt{a_n^2 + b_n^2} \\
   b_n = -c_n \sin(\phi_n) \\
   a_n = c_n \cos(\phi_n)
  \]</span></p></li>
<li><p><span class="math inline">\(c_0\)</span>也是直流分量，<span class="math inline">\(c_n\)</span>被称为n次谐波分量。</p></li>
</ul></li>
<li><p>同样的也有周期信号的傅里叶级数的指数形式：</p>
<ul>
<li><p><span class="math display">\[
  合成公式：x(t) = \sum_{-\infty}^{+\infty} X_n e^{jnwt} \\
  分析公式：X_n = \frac{1}{T}\int_{t_0}^{t_0+T} x(t)\cdot e^{-jnwt} dt
  \]</span></p></li>
<li><p>当n为<span class="math inline">\(\pm1\)</span>时，两项和为基波分量</p></li>
<li><p>当n为<span class="math inline">\(\pm N\)</span>时，两项和为<span class="math inline">\(N\)</span>次谐波分量</p></li>
<li><p><span class="math inline">\(X_n\)</span>也被称为频谱函数</p></li>
<li><p>当相位仅为0,±𝜋时，幅度和相位可以合成为一张频谱</p></li>
</ul></li>
<li><p>傅里叶级数收敛条件：</p>
<ul>
<li><p>能量条件：</p>
<ul>
<li><p><span class="math display">\[
  \int_{-\frac{T}{2}}^{\frac{T}{2}} |x(t)|^2dt &lt; \infty
  \]</span></p>
<p><span class="math inline">\(x(t)\)</span>在一个周期内能量有限。</p></li>
</ul></li>
<li><p>波形条件：</p>
<ul>
<li>有限个不连续点</li>
<li>有限个极大极小值</li>
<li>能量有限</li>
</ul></li>
</ul></li>
</ul>
<h4 id="帕塞瓦尔定理">帕塞瓦尔定理</h4>
<ul>
<li><span class="math inline">\(P = \frac{1}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}} |x(t)|^2dt = \sum_{-\infty}^{+\infty} |X_n|^2\)</span></li>
<li><span class="math inline">\(|X_n|^2\)</span>称为功率谱。</li>
</ul>
<h4 id="傅里叶级数的性质">傅里叶级数的性质</h4>
<ul>
<li>偶信号：傅里叶级数中只含有直流项以及余弦项
<ul>
<li>偶谐信号：无直流分量，只含有正弦项以及余弦项的偶次谐波分量</li>
</ul></li>
<li>奇信号：傅里叶级数中只含有直流项以及正弦项
<ul>
<li>如果<span class="math inline">\(x(t)\)</span>是一个奇信号，并且周期可以选择一个对应周期，那么直流分量也是0</li>
<li>奇谐信号：无直流分量，只含有正弦项以及余弦项的奇次谐波分量</li>
</ul></li>
</ul>
<h4 id="吉布斯现象">吉布斯现象</h4>
<ul>
<li>用有限次谐波分量近似原信号，在不连续点会出现过冲，大约等于总跳变值的<span class="math inline">\(9\%\)</span>。</li>
</ul>
<h4 id="周期矩阵的有效频带宽度">周期矩阵的有效频带宽度</h4>
<ul>
<li><span class="math inline">\(0-\frac{2 \pi}{\tau}\)</span>是周期矩形信号的有效带宽</li>
<li>信号的频谱分量主要集中在零频到第一个过零点之间，我们一般将此宽度作为有效带宽</li>
</ul>
<h4 id="幅度衰减">幅度衰减</h4>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251353929.png" alt="image-20211225135357862" style="zoom:50%;" /></li>
</ul>
<h3 id="chap.5">Chap.5</h3>
<h4 id="傅里叶变换">傅里叶变换</h4>
<ul>
<li><p>将周期信号的周期无限延长，信号就会接近非周期信号，并且谱线间隔<span class="math inline">\(\omega \rightarrow 0\)</span>。</p></li>
<li><p>定义频谱密度函数: <span class="math display">\[
  X(j\omega) = \lim_{T\rightarrow\infty} X(nj\omega)T \\
      = \lim_{T\rightarrow\infty} X_n T\\
      = \lim_{\omega\rightarrow0} \frac{2\pi X(nj\omega)}{\omega}
  \]</span></p>
<ul>
<li><p>由频谱函数可以得到傅里叶变换：</p>
<ul>
<li><span class="math display">\[
  X(jw) = \lim_{T \rightarrow\infty} \int_{\frac{T}{2}}^{-\frac{T}{2}}x(t) e^{-jnwt}dt\\
      = \int_{\infty}^{-\infty}x(t) e^{-jnwt}dt
  \]</span></li>
</ul></li>
<li><p>其中<span class="math inline">\(\frac{ X(nj\omega)}{\omega}\)</span>就是频谱密度</p></li>
<li><p>对于信号<span class="math inline">\(x(t)\)</span>可以定义谱线间隔<span class="math inline">\(\Delta(n\omega)=\omega\)</span>,那么 <span class="math display">\[
  x(t) = \sum_{-\infty}^{+\infty} \frac{ X(nj\omega)}{\omega} e^{jn\omega t} \cdot \Delta(n\omega)
  \]</span> 就可以得到傅里叶逆变换: <span class="math display">\[
  x(t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} X(jw)e^{jwt} dw
  \]</span></p></li>
</ul></li>
<li><p>傅里叶变换:</p>
<ul>
<li><span class="math display">\[
  X(jw) = \int_{-\infty}^{+\infty} x(t)e^{-jwt} dt \\
  = \int_{-\infty}^{+\infty} x(t)\cos(wt) dt - j \int_{-\infty}^{+\infty} x(t)\sin(wt) dt
  \]</span></li>
</ul></li>
<li><p>傅里叶逆变换:</p>
<ul>
<li><span class="math display">\[
  x(t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} X(jw)e^{jwt} dw
  \]</span></li>
</ul></li>
<li><p><span class="math inline">\(X(jw)\)</span>也被称为频谱:</p>
<ul>
<li><span class="math inline">\(X(jw) = |X(jw)| e^{j\phi(w)}\)</span></li>
<li><span class="math inline">\(|X(jw)|\)</span>为幅度频谱</li>
<li><span class="math inline">\(e^{j\phi(w)}\)</span>为相位频谱
<ul>
<li><span class="math inline">\(e^{-j\pi} = e^{j\pi} = -1\)</span></li>
</ul></li>
<li>对于非周期信号，其频谱是连续谱；对于非周期信号的离散频谱可以通过对周期信号的连续频谱等间隔采样获得。</li>
<li>在时域上越宽的信号，在频域上越窄</li>
</ul></li>
</ul>
<h4 id="常见信号的频谱ft">常见信号的频谱(FT)</h4>
<ul>
<li><p>单边指数信号<span class="math inline">\(x(t) =e^{-at} u(t)\)</span> :</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251523856.png" alt="image-20211225152336749" style="zoom:50%;" /></li>
</ul></li>
<li><p>双边指数信号<span class="math inline">\(x(t) =e^{-a|t|}\)</span>:</p>
<ul>
<li><p><span class="math display">\[
  X(jw) = \int_{-\infty}^{+\infty} e^{-a|t|} e^{-jwt} dt \\
      =\int_{0}^{+\infty} e^{-at} e^{-jwt} dt + \int_{-\infty}^{0} e^{at} e^{-jwt} dt \\
      = \frac{1}{a+jw} + \frac{1}{a-jw} \\
      = \frac{2a}{a^2 + w^2}
  \]</span></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251528705.png" alt="image-20211225152824626" style="zoom: 50%;" /> 因为只有实部</p></li>
</ul></li>
<li><p>单位冲激信号<span class="math inline">\(\delta\)</span></p>
<ul>
<li>单位冲激信号的傅里叶变换为1</li>
<li>时域变化异常剧烈的冲激函数包含幅度相等的所有频率分量，这种频谱也称为“均匀谱”或“白色谱”</li>
</ul></li>
<li><p>直流信号</p>
<ul>
<li><p>其傅里叶变换为<span class="math inline">\(2\pi\delta(w)\)</span></p></li>
<li><p>直流信号的傅里叶变换计算是通过对于<span class="math inline">\(e^{-\sigma|t|}\)</span>进行傅里叶变换之后取极限算出来的：</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[e^{-\sigma|t|}] = \int_{-\infty}^{+\infty} e^{-\sigma|t|} e^{-jwt} dt \\
  = \frac{2\sigma}{\sigma^2 + w^2} \\
  \mathcal{F}[1] = \lim_{\sigma \rightarrow 0} \mathcal{F}[e^{-\sigma|t|}] = 2\pi \delta(w)
  \]</span></li>
</ul></li>
</ul></li>
<li><p>符号函数</p>
<ul>
<li><p>其傅里叶变换也借助了与直流信号一样的思路：</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[sgn(t)] = \lim_{\sigma \rightarrow 0} \mathcal{F}[sgn(t)e^{-\sigma|t|}] = \frac{2}{jw}
  \]</span></li>
</ul></li>
</ul></li>
<li><p>单位阶跃信号</p>
<ul>
<li><p><span class="math inline">\(u(t) = \frac{1}{2}+ \frac{1}{2} sgn(t)\)</span></p></li>
<li><p><span class="math display">\[
  \mathcal{F}[u(t)] = \frac{1}{jw} + \pi \delta(w)
  \]</span></p></li>
</ul></li>
<li></li>
</ul>
<h4 id="傅里叶变换的性质">傅里叶变换的性质</h4>
<ul>
<li>线性：
<ul>
<li><span class="math inline">\(x_1(t)\rightarrow_{\mathcal{F}} X_1(jw),x_2(t)\rightarrow_{\mathcal{F}} X_2(jw)\)</span>,<span class="math inline">\(ax_1(t)+bx_2(t)\rightarrow_{\mathcal{F}} aX_1(jw)+bX_2(jw)\)</span></li>
</ul></li>
<li>对称性：
<ul>
<li>$x(t)<em>{} X(jw),X(t)</em>{}2x(-jw) $</li>
</ul></li>
<li>奇偶虚实性：
<ul>
<li>将傅里叶变换中用欧拉公式展开即可</li>
</ul></li>
<li>尺度变换：
<ul>
<li>$x(t)<em>{} X(jw),x(at)</em>{} X() $</li>
<li>时域压缩，频域拉伸；时域拉伸，频域压缩</li>
<li>时域翻转，频域也翻转</li>
<li>频域零点的y轴坐标值意为时域面积，时域零点的y轴坐标值意为频域面积</li>
</ul></li>
<li>时移特性：
<ul>
<li>$x(t)<em>{} X(jw),x(t-t_0)</em>{} X(jw)e^{-jwt_0} $
<ul>
<li>符号对应</li>
</ul></li>
</ul></li>
<li>频移特性:
<ul>
<li>$x(t)<em>{} X(jw),x(t)e^{jwt_0}</em>{} X(j(w-w_0)) $
<ul>
<li>符号相反</li>
</ul></li>
<li><span class="math inline">\(x(t)\rightarrow_{\mathcal{F}} X(jw),x(t)\cos(w_0t)\rightarrow_{\mathcal{F}} \frac{1}{2}X(j(w-w_0)) + \frac{1}{2}X(j(w+w_0))\)</span></li>
<li><span class="math inline">\(x(t)\rightarrow_{\mathcal{F}} X(jw),x(t)\sin(w_0t)\rightarrow_{\mathcal{F}} -\frac{j}{2}X(j(w-w_0)) + \frac{1}{2}X(j(w+w_0))\)</span></li>
</ul></li>
<li>积分特性：
<ul>
<li>$x(t)<em>{}X(jw) <span class="math inline">\(,那么\)</span></em>{-}^t x() d_{} +X(0)(w)$<br />
</li>
</ul></li>
<li>微分特性
<ul>
<li>$x(t)<em>{}X(jw) <span class="math inline">\(,那么\)</span></em>{}(jw)^n X(jw)$<br />
</li>
<li>$x(t)<em>{}X(jw) <span class="math inline">\(,那么\)</span>t^nx(t)</em>{}$</li>
</ul></li>
<li>卷积性质：
<ul>
<li>时域卷积等于频域乘积</li>
<li>因此，对于LTI系统来说，因为<span class="math inline">\(y(t) = x(t)*h(t)\)</span>，所以<span class="math inline">\(Y(jw)=H(jw)\cdot X(jw)\)</span>。</li>
<li>频域卷积等于时域乘积再乘以<span class="math inline">\({2\pi}\)</span></li>
</ul></li>
<li>一图流:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251628895.png" alt="image-20211225162801801" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="帕塞瓦尔能量守恒">帕塞瓦尔能量守恒</h4>
<ul>
<li><span class="math inline">\(\int_{-\infty}^{+\infty} |x(t)|^2 dt = \frac{1}{2\pi} \int_{-\infty}^{+\infty} |X(jw)|^2 dw\)</span></li>
</ul>
<h4 id="周期信号的傅里叶变换">周期信号的傅里叶变换</h4>
<h5 id="典型周期信号的傅里叶变换">典型周期信号的傅里叶变换</h5>
<p>由于<span class="math inline">\(\mathcal{F}[1] = 2\pi \delta(w)\)</span>结合频移性质可得： <span class="math display">\[
\mathcal{F}[1 \cdot e^{jw_0t}] = 2\pi \delta(w - w_0) \\
\mathcal{F}[1 \cdot e^{-jw_0t}] = 2\pi \delta(w+w_0)
\]</span></p>
<ul>
<li><p>正弦</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[\cos w_0 t] = \pi (\delta(w-w_0) +  \delta(w+w_0))
  \]</span></li>
</ul></li>
<li><p>余弦</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[\sin w_0 t] = -j\pi (\delta (w-w_0) - \delta(w+w_0))
  \]</span></li>
</ul></li>
<li><p><span class="math inline">\(Sa(w_0t)\)</span>:</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[Sa(w_0t)] = \frac{\pi}{w_0}[u(w+w_0) - u(w-w_0)]
  \]</span></li>
</ul></li>
</ul>
<h4 id="一般周期信号">一般周期信号</h4>
<ul>
<li><p>一般周期信号<span class="math inline">\(x(t)\)</span>，假设周期为<span class="math inline">\(T_0\)</span>,<span class="math inline">\(x(t)\)</span>的傅里叶级数为 <span class="math display">\[
  x(t) = \sum_{-\infty}^{+\infty} X_n e^{jnw_0t}
  \]</span> 对两边同时取傅里叶变换，可知 <span class="math display">\[
  \mathcal{F}[x(t)] = \sum_{-\infty}^{+\infty} X_n \mathcal{F}[e^{jnw_0t}] \\
  = 2\pi \sum_{-\infty}^{+\infty} X_n \delta(w-nw_0)
  \]</span></p></li>
<li><p>对于周期信号来说，频谱是离散的，对于非周期信号，其频谱是连续的。</p></li>
<li><p>傅里叶级数与傅里叶变换的关系：</p>
<ul>
<li><span class="math inline">\(X_n = \frac{1}{T} X_{T}(jw) |_{w = nw_0}\)</span></li>
</ul></li>
</ul>
<h4 id="random-fourier">Random Fourier</h4>
<ul>
<li><p>核函数指的是如下形式：</p>
<ul>
<li><p><span class="math inline">\(k(x,y ) = &lt;\phi(x),\phi(y)&gt;\)</span></p></li>
<li><p>其中，<span class="math inline">\(x,y\)</span>是原始的数据点，通过<span class="math inline">\(\phi(x),\phi(y)\)</span>对<span class="math inline">\(x,y\)</span>映射到更高维的空间，并且通常我们并不在意<span class="math inline">\(\phi(x),\phi(y)\)</span>的具体形式，只在意<span class="math inline">\(k(x,y)\)</span>的结果。</p></li>
<li><p>但是当遇到数据集较大，需要实现非线性分类的时候，对每一个点都要计算<span class="math inline">\(k(x,y)\)</span>.</p></li>
<li><p>RFF的想法是把原始数据<span class="math inline">\(x,y\)</span>通过显式的映射函数<span class="math inline">\(Z\)</span>映射到一个更低维的空间<span class="math inline">\(R^D\)</span>,也就是说实现<span class="math inline">\(Z:R^d \rightarrow R^D\)</span>,并且映射之后的两点的内积就是核函数<span class="math inline">\(k(x,y)\)</span>的近似值: <span class="math display">\[
  k(x,y) = &lt;\phi(x),\phi(y)&gt; = Z(x)^T Z(y)
  \]</span> 这与一般的核函数将其映射到更高维相反。</p>
<p>并且在映射之后，我们可以使用线性的学习方法来近似非线性的学习方法。</p></li>
<li><p>具体过程如下：</p>
<ul>
<li>记<span class="math inline">\(x-y = \delta\)</span>,并假设<span class="math inline">\(\delta\)</span>的傅里叶变换是<span class="math inline">\(p(w)\)</span>,因此我们由傅里叶逆变换： <span class="math display">\[
  k(x - y) = \int_{R^d} p(w) e^{jw^T\delta} dw
  \]</span> 并且可以认为<span class="math inline">\(p(w)\)</span>是<span class="math inline">\(w\)</span>的一个分布，如果记<span class="math inline">\(\eta_w(x)=e^{jw^Tx}\)</span>,那么上面的式子就是 <span class="math display">\[
  k(x - y) = E_w[\eta_w(x)^T\eta_w(y)^*]
  \]</span> 因此<span class="math inline">\(\eta_w(x)^T\eta_w(y)^*\)</span>是<span class="math inline">\(k(x-y)\)</span>的一个无偏估计。由于核函数以及<span class="math inline">\(p(w)\)</span>都是势函数，因此复指数可以替换成cos函数 <span class="math display">\[
  Z_w(x) = \sqrt{2} \cos(w^Tx + b)= \eta_w(x)
  \]</span> 其中<span class="math inline">\(w\)</span>从<span class="math inline">\(p(w)\)</span>中采样，<span class="math inline">\(b\)</span>从均匀分布中采样，用经验估计操作代替求期望的操作。 <span class="math display">\[
  E_w[Z_w(x)^T Z_w(y)] = \frac{1}{D} \sum_{j=1}^D Z_{w_j}(x)^T Z_{w_j}(y) \\
  = \frac{2}{D} \sum_{j=1}^D  \cos(w_j^Tx + b_j)\cos(w_j^Ty + b_j)
  \]</span> 因此我们所需要的映射函数<span class="math inline">\(Z(x)\)</span> <span class="math display">\[
  Z(x) =\sqrt{\frac{2}{D}} [\cos(w_1^Tx + b_1),\cos(w_2^Tx + b_2),...,\cos(w_D^Tx + b_D)]
  \]</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="chap.6">Chap.6</h3>
<h4 id="信号的采样">信号的采样</h4>
<ul>
<li><p>一般可以通过脉冲序列进行采样,即 <span class="math display">\[
  \delta_{T_s}(t) = \sum_{n=-\infty}^{\infty} \delta(t-nT_s)
  \]</span> 那么对于任意一个信号<span class="math inline">\(x(t)\)</span>,可以借助冲激信号的抽样性质得到: <span class="math display">\[
  x(t) \cdot \delta_{T_s}(t) = \sum_{n=-\infty}^{\infty} x(nT_s) \delta(t-nT_s)
  \]</span></p></li>
<li><p>要求该采样序列的傅里叶变换，因为它是周期信号，因此要先计算傅里叶级数才行： <span class="math display">\[
  X_n = \frac{1}{T_s} \int_{-\frac{T_s}{2}}^{\frac{T_s}{2}} \delta_{T_s}(t) e^{-jnw_s t} dt \\
  = \frac{1}{T_s} \int_{-\frac{T_s}{2}}^{\frac{T_s}{2}} \delta(t) e^{-jnw_s t} dt \\
  = \frac{1}{T_s} \delta(t) e^{-jnw_s t} |_{t=0} \\
  = \frac{1}{T_s}
  \]</span> 所以它的傅里叶变换为: <span class="math display">\[
  \mathcal{F}[\delta_{T_s}(t) ] = 2\pi  \frac{1}{T_s} \sum_{n=-\infty}^{\infty} \delta(w-nw_s) \\
  = w_s \sum_{n=-\infty}^{\infty} \delta(w-nw_s)
  \]</span></p></li>
<li><p>求上述傅里叶变换的原因在于，对时域上的信号做采样，是一个乘积操作，可以转换为频域上的卷积操作： <span class="math display">\[
  \mathcal{x_s(t)} = \frac{1}{2\pi} [X(jw) * \mathcal{F}[\delta_{T_s}(t) ]] \\
  = \frac{1}{2\pi} [X(jw) * w_s \sum_{n=-\infty}^{\infty} \delta(w-nw_s)] \\
  =\frac{w_s}{2\pi} \sum_{n=-\infty}^{\infty} X(j(w-nw_s))
  \]</span> 由此可见，时域上的离散化操作导致了频域上的周期延拓。</p>
<ul>
<li>离散化与周期性相对应，连续化与非周期性相对应</li>
</ul></li>
<li><p>用冲激信号作为采样信号进行采样又称为理想采样。</p></li>
<li><p>用矩形信号作为采样信号进行采样:</p>
<ul>
<li><span class="math display">\[
  \mathcal{F}[\mathcal{x_s(t)}] = \sum_{n=-\infty}^{\infty } p_n X(j(w-nw_s))
  \]</span></li>
</ul></li>
</ul>
<h4 id="时域采样定理">时域采样定理</h4>
<ul>
<li><p>若连续信号<span class="math inline">\(x(t)\)</span>是一个频带受限的信号，即如果 <span class="math display">\[
  if|w|&gt;w_m,thenX(jw)=0,w_m= 2\pi f_m
  \]</span> 对<span class="math inline">\(x(t)\)</span>进行等间隔采样生成<span class="math inline">\(\mathcal{x_s(t)}\)</span> ,用<span class="math inline">\(\mathcal{x_s(t)}\)</span>可以恢复<span class="math inline">\(x(t)\)</span>的条件为 <span class="math display">\[
  w_s &gt; 2w_m,i.e.T_s &lt; \frac{1}{2f_m}
  \]</span> 其中<span class="math inline">\(f_s = 2f_m,i.e.,w_s = 2w_m\)</span> 是最小采样频率，称为奈奎斯特频率。</p></li>
<li><p>如果小于最小采样频率，信号就会发生混叠。</p></li>
</ul>
<h3 id="chap.7">Chap.7</h3>
<ul>
<li>波长 = 波速 / 频率</li>
<li>任何频率的波在真空中传播的速度都是光速</li>
</ul>
<h4 id="信号传输过程">信号传输过程</h4>
<ul>
<li><p>短距离用短波长的传输，远距离用长波长的进行传输</p></li>
<li><p>如果要传输低频信号，就需要将其进行调制，即将低频信号加载到一个高频振荡信号上，由接受方进行解调。</p></li>
<li><p>一般将待发送的信号称为调制信号，用于载送的信号称为载波信号。</p></li>
<li><p>调制之后会让载波信号<span class="math inline">\(c(t)\)</span>的某个信号随着<span class="math inline">\(x(t)\)</span>进行有规律的变化。 <span class="math display">\[
  c(t) = A\cos(w_c t + \phi) = A\cos(\theta(t))
  \]</span></p>
<ul>
<li>幅度调制:
<ul>
<li>让<span class="math inline">\(A\)</span>随着<span class="math inline">\(x(t)\)</span>进行变化，其余参数不变</li>
</ul></li>
<li>角度调制
<ul>
<li>让<span class="math inline">\(w_c\)</span>或者<span class="math inline">\(\phi\)</span>随着<span class="math inline">\(x(t)\)</span>进行变化，其余参数不变</li>
</ul></li>
</ul></li>
</ul>
<h4 id="正弦载波调幅">正弦载波调幅</h4>
<ul>
<li><p>令载波信号<span class="math inline">\(c(t)=\cos(w_ct)\)</span>, <span class="math display">\[
  y(t) = x(t) \cdot c(t) = x(t) \cdot \cos(w_ct)
  \]</span> 对两边进行傅里叶变换，由调制定理可知: <span class="math display">\[
  Y(jw) = \frac{1}{2} [X(j(w+w_c)) + X(j(w-w_c))]
  \]</span> <img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112252237755.png" alt="image-20211225223749628" style="zoom:50%;" /></p>
<ul>
<li>注意绝对值大的部分为上边带。</li>
<li>并且可以看出当<span class="math inline">\(w_c &lt; w_m\)</span>的时候，两个图像会发生混叠。</li>
</ul></li>
</ul>
<h4 id="复指数载波调制">复指数载波调制</h4>
<ul>
<li><p>设置载波信号<span class="math inline">\(c(t) = e^{j(w_c t + \varphi)} = \cos(w_c t + \varphi) + j \sin(w_c t + \varphi)\)</span> 进行调制。</p></li>
<li><p>同样，我们可以借助傅里叶变换计算得信号经过调制后在频域上的表现:</p></li>
</ul>
<p><span class="math display">\[
Y(jw) = \frac{1}{2\pi} [X(jw)*2\pi [\delta(w-w_c)]] \\
      = X(j(w-w_c))
\]</span></p>
<ul>
<li><p>发现，复指数载波调制只会使得原始信号向右移动，而不发生振幅的改变。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/image-20211130150546916.png" alt="image-20211130150546916" style="zoom:50%;" /></p></li>
</ul>
<h4 id="单边带调幅">单边带调幅</h4>
<ul>
<li>单边带调幅要求只发送上边带或者下边带信号，节省能量和带宽。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112252248876.png" alt="image-20211130151011303" style="zoom:50%;" /></li>
<li>求得频域表示<span class="math inline">\(Y(jw)\)</span>之后，注意频域卷积定理常常能获得一个更简单的求解输出的方式：
<ul>
<li><strong>频域卷积定理</strong>：<span class="math inline">\(\mathcal{F}[f_1(x) \cdot f_2(x)] = \frac{1}{2\pi} \mathcal{F} [f_1(x)] * \mathcal{F} [f_2(x)]\)</span></li>
<li>另外，常见函数的傅里叶变换形式:
<ul>
<li><span class="math inline">\(Sa(x) {-&gt;}^{\mathcal{F}} \pi g_2(w)\)</span></li>
<li><span class="math inline">\(\cos(w_cx) -&gt;^{\mathcal{F}} \pi[\delta(w+w_c)+\delta(w-w_c)]\)</span></li>
<li><span class="math inline">\(\sin(w_cx)-&gt;^{\mathcal{F}} j\pi [\delta(w+w_c)-\delta(w-w_c)]\)</span></li>
</ul></li>
</ul></li>
</ul>
<h4 id="同步解调">同步解调</h4>
<ul>
<li>同步解调的过程就是从调制输出<span class="math inline">\(y(t)\)</span>中恢复出<span class="math inline">\(x(t)\)</span>,即从<span class="math inline">\(Y(jw)\)</span>中恢复出<span class="math inline">\(X(jw)\)</span></li>
<li>为了做到这一点，我们常将<span class="math inline">\(y(t)\cdot \cos(w_ct)\)</span> :
<ul>
<li><span class="math inline">\(r(t) = y(t)\cdot \cos(w_ct) = x(t) \frac{1+\cos(2w_c t)}{2}\)</span><br />
</li>
<li><span class="math inline">\(R(jw) = \frac{1}{2} X(jw) + \frac{1}{4}[X(j(w+2w_c)) + X(j(w-2w_c))]\)</span></li>
</ul></li>
<li>可以发现解调之后，信号信息只差了一个<span class="math inline">\(\frac{1}{2}\)</span>的系数</li>
<li>并且我们也可以发现，在恢复的过程中，只有当<span class="math inline">\(2w_c \ge w_m\)</span>的时候,才能不发生混叠。用滤波器取出原信号的时候，滤波器带宽需要满足<span class="math inline">\(w_m\)</span>&lt;𝐵&lt;<span class="math inline">\(2w_c-w_m\)</span> 。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112252252133.png" alt="image-20211130204749424" style="zoom:50%;" /></li>
</ul>
<h4 id="单边带调幅-1">单边带调幅</h4>
<ul>
<li>单边带调幅属于同步解调的一种特殊情况:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/image-20211130205155497.png" alt="image-20211130205155497" style="zoom:50%;" /></li>
<li>单边带调幅描述的就是只有上边带信息或者下边带信息的情况。</li>
<li>如上图，只有下边带信息的时候，我们可以利用同步解调的适当组合求解:
<ul>
<li><p>其实还是<span class="math inline">\(\cdot \cos(w_c t)\)</span></p></li>
<li><p><span class="math inline">\(X(jw) = \frac{1}{2} [Y(j(w+w_c)) + Y(j(w-w_c))]\)</span></p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/image-20211130205353070.png" alt="image-20211130205353070" /><figcaption aria-hidden="true">image-20211130205353070</figcaption>
</figure></li>
<li><p>之后，再利用滤波器就可以进行解调。</p></li>
</ul></li>
</ul></li>
<li>并且当调制端与解调端的载波信号相位不等，解调之后的信号就会失真，当相位差到了<span class="math inline">\(\frac{\pi}{2}\)</span>的时候，就无法恢复原信号了。</li>
<li>频分复用：
<ul>
<li>对于不同的信号，用不同的余弦信号用不同的相位进行载波，在解调的时候用不同的带通滤波器就可以一次性解调出不同的输入信号。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261045341.png" alt="image-20211226104514182" style="zoom:50%;" /></li>
</ul></li>
<li>时分复用</li>
<li>码分复用CDM：发送的时候信号乘以正交随机码，解调的时候再乘正交随机码进行恢复。</li>
</ul>
<h4 id="频域分析的应用">频域分析的应用</h4>
<ul>
<li>图卷积/图卷积网络</li>
<li>简化图卷积网络</li>
<li>F-principle:
<ul>
<li>DNNs训练网络的时候，通常都是从低频开始学习再学到高频信息或者说DNNs先学了一个整体再补充学习细节部分。</li>
</ul></li>
<li>傅里叶变换纠偏:
<ul>
<li>利用频谱分析图像的旋转角度，从而还原。</li>
</ul></li>
</ul>
<h3 id="chap.8">Chap.8</h3>
<h4 id="离散时间傅里叶变换dtft">离散时间傅里叶变换(DTFT)</h4>
<ul>
<li>DTFT:</li>
</ul>
<p><span class="math display">\[
DTFT(x[n]) = X(e^{jw}) = \sum_{n=-\infty}^{\infty}x[n]e^{-jnw}
\]</span></p>
<ul>
<li><p>DTFT逆变换： <span class="math display">\[
  IDTFT(X(e^{jw})) = x[n] = \frac{1}{2\pi} \int_{-\pi}^{\pi}X(e^{jw})e^{jwn} dw
  \]</span></p></li>
<li><p>与傅里叶变换的形式还是比较对应的。</p></li>
<li><p>其中<span class="math inline">\(X(e^{jw})\)</span> 是以<span class="math inline">\(2\pi\)</span>为周期的周期函数。</p></li>
<li><p>DTFT针对的是离散非周期信号</p></li>
<li><p>也有一些类似的性质：</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261117849.png" alt="image-20211226111717696" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="离散傅里叶级数-dfs">离散傅里叶级数 (DFS)</h4>
<ul>
<li><p><span class="math display">\[
  X[k] = DFS(x[n]) = \sum_{n=0}^{N-1} x[n] \cdot e^{-j\frac{2\pi}{N}kn} \\
  x[n] = IDFS(X[k]) = \frac{1}{N} \sum_{k=0}^{N-1} X[k] e^{j\frac{2\pi}{N}kn} \\
  W_N = e^{-j\frac{2\pi}{N}}
  \]</span></p></li>
<li><p>作用对象主要是离散周期信号，其也是一个离散谱</p></li>
</ul>
<h4 id="几类变换之间的关系">几类变换之间的关系</h4>
<ul>
<li>FS以及离散FS（DFS）都是针对周期信号的，<span class="math inline">\(FT\)</span>以及<span class="math inline">\(DFT\)</span>都是针对非周期信号的，上述四个变换都是进行频域分析，而后两章节介绍的LT、ZT都是复频域上的分析，ZT是LT的离散版本。</li>
<li>由DFS，可以实现由DFT以及FFT。</li>
</ul>
<h4 id="离散傅里叶变换">离散傅里叶变换</h4>
<ul>
<li><p>DFT: <span class="math display">\[
  W_N = e^{-j\frac{2\pi}{N}} \\
  W_N^{nk} = e^{-j\frac{2\pi}{N}nk} \\
  X[k] = \sum_{n=0}^{N-1} x[n]\cdot W_N^{nk}\\
  \]</span></p></li>
<li><p>IDFT: <span class="math display">\[
  x[n] = \frac{1}{N} \sum_{n=0}^{N-1} X[k] W_N^{-nk}
  \]</span></p></li>
<li><p>DFT的作用对象是长度为N的非周期序列,可以看成是截取了DFS的主值序列构成的变换对，通俗地说，就是只取了DFS的前N个。</p></li>
<li><p>关于DFT以及DTFT的关系：</p>
<ul>
<li>x[n]的DFT是其DTFT再一个周期<span class="math inline">\([0,2\pi)\)</span>的等间隔抽样,换句话说，取了DTFT的一个周期并采样出了N个点。</li>
</ul></li>
<li><p>DFT也含有周期性,位移时需要注意其循环移位的特性。</p>
<ul>
<li><p>并且其卷积操作变成了循环卷积操作：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261217520.png" alt="image-20211226121726382" style="zoom:50%;" /></p></li>
<li><p>在4点卷积的情况下结果不同，但是如果将点数放大到5、6、7之后，可能可以出现相同的卷积序列。</p></li>
</ul></li>
</ul>
<h4 id="快速傅里叶变换fft">快速傅里叶变换(FFT)</h4>
<ul>
<li>DFT与IDFT的时间复杂度相同，且都只包含加法以及乘法。
<ul>
<li>复数加法的时间复杂度为<span class="math inline">\(N(N-1)\)</span></li>
<li>复数乘法的时间复杂度为<span class="math inline">\(N^2\)</span></li>
</ul></li>
<li>想要降低它们的时间复杂度，可以通过将长序列拆分为短序列的方式进行：
<ul>
<li>常用 的拆分方式有基2时间抽取以及基2频率抽取。</li>
<li>基2时间抽取：
<ul>
<li>按照奇数偶数的下标进行分解。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261224600.png" alt="image-20211226122450460" style="zoom:50%;" />
<ul>
<li>对于旋转因子<span class="math inline">\(W_N^M\)</span>,N/2相当于M*2</li>
</ul></li>
<li>将N长度的长序列的DFT拆分为了对两个<span class="math inline">\(N/2\)</span>长度的序列进行DFT，因此这样对分下去，最终的时间复杂度为<span class="math inline">\(\frac{N}{2}\log_2 N\)</span></li>
</ul></li>
</ul></li>
<li>对于IFFT:
<ul>
<li><span class="math inline">\(FFT^*(DFT(X^*[m])) / N\)</span></li>
</ul></li>
<li>对于常规的复数乘法也可以用分治算法进行优化：
<ul>
<li>将n长度的分成两块，每块n/2长度</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261239388.png" alt="image-20211226123942254" style="zoom:50%;" /></li>
</ul></li>
<li>多项式乘法的优化;
<ul>
<li>两个d次多项式，我们需要求解2d+1个参数才可以，在已知两个d次多项式参数的情况下，就可以以<span class="math inline">\(O(n^2)\)</span>的时间复杂度求解。</li>
<li>为了确定d次的多项式，可以采用分治+插值的方法：
<ul>
<li>将d次多项式拆分为奇次项与偶次项，奇次项再提取一个x就可以计算一次利用两次，通过把x设置为<span class="math inline">\(z^n = 1\)</span>的n个根，n个根在进行<span class="math inline">\(\pm\)</span>项抵消一次运算之后可以继续产生正负对，从而使分治进行到底。</li>
</ul></li>
</ul></li>
</ul>
<h3 id="chap.9">Chap.9</h3>
<h4 id="laplace-transform">Laplace Transform</h4>
<ul>
<li>LT:</li>
</ul>
<p><span class="math display">\[
X(s) = \mathcal{L}[x(t)] = \int_{-\infty}^{+\infty}x(t)e^{-st}dt\\
其中，s = \sigma + j\omega
\]</span></p>
<ul>
<li><p>ILT: <span class="math display">\[
  x(s) = \mathcal{L}^{-1}[X(s)] = \frac{1}{2\pi j}  \int_{\sigma-j\infty}^{\sigma+j\infty}X(s)e^{st}ds\\
  其中，s = \sigma + j\omega
  \]</span></p></li>
<li><p>是在复频域上分析，但是频谱分析还得用FT，复数域无法构建</p></li>
<li><p>单边LT： <span class="math display">\[
  X(s) = \int_{0_{-}}^{+\infty}x(t)e^{-st}dt\\
  \]</span></p></li>
<li><p>单边ILT： <span class="math display">\[
  x(t) =\frac{1}{2\pi j}  \int_{\sigma-j\infty}^{\sigma+j\infty}X(s)e^{st}ds
  \]</span></p></li>
<li><p>单边LT存在的条件：</p>
<ul>
<li><p><span class="math display">\[
  X(s) = \int_{0_{-}}^{+\infty}|x(t)|e^{-\sigma t}dt = C &lt; \infty\\
  \]</span></p></li>
<li><p>而对于任意的信号<span class="math inline">\(x(t)\)</span>,要满足上式，<span class="math inline">\(x(t)\)</span>应该满足 <span class="math display">\[
  \lim_{t\rightarrow \infty} x(t) e^{-\sigma t} = 0 (\sigma &gt; \sigma_0)
  \]</span></p></li>
<li><p>意为当<span class="math inline">\(\sigma &gt; \sigma_0\)</span>之后的平面区域上，对于这个<span class="math inline">\(x(t)\)</span>,<span class="math inline">\(\lim_{t\rightarrow \infty} x(t) e^{-\sigma t} = 0\)</span> ，用图片表示如下:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112091156156.png" alt="image-20211209115629079" style="zoom:50%;" /></p>
<p>如果<span class="math inline">\(x(t)\)</span>是有始有终、能量有限的信号，那么收敛区域为整个s平面。</p>
<ul>
<li>例如，<span class="math inline">\(u(t) - u(t-a)\)</span>形式的矩形区域，冲激信号等</li>
</ul>
<p>如果<span class="math inline">\(x(t) = t^n\)</span> 的多项式形式,那么<span class="math inline">\(\sigma &gt;0\)</span>时，可以有<span class="math inline">\(\lim_{t\rightarrow \infty} x(t) e^{-\sigma t} = 0\)</span> 。</p>
<ul>
<li>例如，<span class="math inline">\(u(t),t^nu(t)\)</span> ,可以将<span class="math inline">\(u(t)\)</span>看成是多项式中的单位1</li>
</ul>
<p>如果<span class="math inline">\(x(t) = e^{at}\)</span> ,那么当<span class="math inline">\(\sigma &gt; a\)</span>时，极限就会收敛。</p>
<p>同理，当<span class="math inline">\(x(t)\)</span>的增长速率超过了<span class="math inline">\(e^{-\sigma t}\)</span>的下降速率，那么<span class="math inline">\(x(t)\)</span>就没有办法收敛。</p>
<ul>
<li>例如当<span class="math inline">\(x(t) = t^t,e^{t^2}\)</span></li>
</ul></li>
</ul></li>
</ul>
<h4 id="常用信号的拉普拉斯变换">常用信号的拉普拉斯变换</h4>
<p><span class="math display">\[
\mathcal{L}[e^{\lambda t }u(t)] = \frac{1}{s-\lambda}\\
收敛条件为\sigma &gt; \lambda
\]</span></p>
<p><span class="math display">\[
\mathcal{L}[\delta(t-t_0)] = e^{-st_0}\\
收敛条件为\sigma &gt; -\infty
\]</span></p>
<p><span class="math display">\[
\mathcal{L}[u(t)] = \frac{1}{s}\\
收敛条件为\sigma &gt; 0
\]</span></p>
<p><span class="math display">\[
\mathcal{L}[u(t-t_0)] = \frac{1}{s}(1-e^{-st_0}) ??\\
收敛条件为\sigma &gt; 0 
\]</span></p>
<p><span class="math display">\[
\cos (\omega_0 t) u(t) = \frac{e^{j\omega_0 t} + e^{-j\omega_0 t}}{2} u(t) \rightarrow^{\mathcal{L}} \frac{1}{2}(\frac{1}{s-j\omega} + \frac{1}{s+j\omega}) = \frac{s}{s^2 + \omega^2}
\]</span></p>
<p><span class="math display">\[
\sin (\omega_0 t) u(t) = \frac{e^{j\omega_0 t} - e^{-j\omega_0 t}}{2j} u(t) \rightarrow^{\mathcal{L}} \frac{1}{2j}(\frac{1}{s-j\omega} - \frac{1}{s+j\omega}) = \frac{\omega_0}{s^2 + \omega^2}
\]</span></p>
<p><span class="math display">\[
\mathcal{L}[\delta_t^\prime] = s
\]</span></p>
<p><span class="math display">\[
\mathcal{L}[\delta_t] = 1
\]</span></p>
<h4 id="单边拉普拉斯变换的性质">单边拉普拉斯变换的性质</h4>
<ul>
<li><p>线性性质:</p>
<ul>
<li><span class="math inline">\(a_1x_1(t) + a_2x_2(t) \rightarrow^{\mathcal{L}} a_1X_1(s) + a_2X_2(s)\)</span></li>
<li>收敛条件为<span class="math inline">\(\sigma &gt; \max(\sigma_1,\sigma_2)\)</span>，其中<span class="math inline">\(\sigma_1\)</span>为<span class="math inline">\(x_1(t)\)</span>的收敛条件,<span class="math inline">\(\sigma_2\)</span>为<span class="math inline">\(x_2(t)\)</span>的收敛条件,<span class="math inline">\(x_1(t) \rightarrow^{\mathcal{L}} X_1(s)\)</span> ,<span class="math inline">\(x_2(t) \rightarrow^{\mathcal{L}} X_2(s)\)</span></li>
<li>利用线性性质可以计算得正弦信号与余弦信号的LT:
<ul>
<li><span class="math inline">\(\cos (\omega_0 t) u(t) = \frac{e^{j\omega_0 t} + e^{-j\omega_0 t}}{2} u(t) \rightarrow^{\mathcal{L}} \frac{1}{2}(\frac{1}{s-j\omega} + \frac{1}{s+j\omega}) = \frac{s}{s^2 + \omega^2}\)</span><br />
</li>
<li><span class="math inline">\(\sin (\omega_0 t) u(t) = \frac{e^{j\omega_0 t} - e^{-j\omega_0 t}}{2j} u(t) \rightarrow^{\mathcal{L}} \frac{1}{2j}(\frac{1}{s-j\omega} - \frac{1}{s+j\omega}) = \frac{\omega_0}{s^2 + \omega^2}\)</span><br />
</li>
</ul></li>
<li>有没有<span class="math inline">\(u(t)\)</span>不影响结果</li>
</ul></li>
<li><p>展缩性质：</p>
<ul>
<li><span class="math inline">\(x(at) \rightarrow^{\mathcal{L}} \frac{1}{a} X(\frac{s}{a})\)</span>,收敛条件为<span class="math inline">\(\sigma &gt; a\sigma_0, a&gt;0\)</span></li>
<li><span class="math inline">\(x(t) \rightarrow^{\mathcal{L}} X(s)\)</span></li>
<li>展缩性质（尺度变换）是针对整体的，但是下面介绍的时移性质是针对t本身的。
<ul>
<li>例子： 对于<span class="math inline">\(x(at-b)u(at-b),x(t)u(t)\)</span>
<ul>
<li>先进行展缩:<span class="math inline">\(x(at)u(at)\)</span></li>
<li>后进行时移:<span class="math inline">\(x(at-b)u(at-b) = x(a(t-\frac{b}{a}))u(a(t-\frac{b}{a}))\)</span></li>
<li>但是，如果我们先进行时移:<span class="math inline">\(x(t-b)u(t-b)\)</span></li>
<li>再进行展缩，得到的结果是<span class="math inline">\(x(at-b)u(at-b)\)</span>,没有影响到b</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>时移性质:</p>
<ul>
<li><p><span class="math inline">\(x(t-t_0)u(t-t_0) \rightarrow^{\mathcal{L}} e^{-st_0}X(s)\)</span> 收敛条件为<span class="math inline">\(\sigma &gt; \sigma_0, t_0&gt;0\)</span></p></li>
<li><p><span class="math inline">\(x(t) \rightarrow^{\mathcal{L}} X(s)\)</span></p></li>
<li><p>利用时移性质以及线性性质可以通过将周期信号转换为第一个周期信号的线性组合进行单边LT求解:</p>
<ul>
<li><p><span class="math display">\[
  x(t) = \sum_{k=0}^{\infty} x_1(t-kT)
  \]</span></p></li>
<li><p><span class="math display">\[
  \mathcal{L}[x(t)] = \sum_{k=0}^{\infty} e^{-skT} X_1(s) = \frac{X_1(s)}{1-e^{-sT}}
  \]</span></p></li>
</ul></li>
</ul></li>
<li><p>卷积性质:</p>
<ul>
<li><span class="math inline">\(x_1(t) * x_2(t) \rightarrow^{\mathcal{L}} X_1(s)X_2(s)\)</span> ,<span class="math inline">\(\sigma &gt; \max(\sigma_1,\sigma_2)\)</span></li>
<li><span class="math inline">\(x_1(t) \rightarrow^{\mathcal{L}} X_1(s)\)</span> ,<span class="math inline">\(x_2(t) \rightarrow^{\mathcal{L}} X_2(s)\)</span></li>
</ul></li>
<li><p>乘积性质:</p>
<ul>
<li><span class="math inline">\(x_1(t)x_2(t) \rightarrow^{\mathcal{L}} \frac{1}{2\pi j} X_1(s) * X_2(s)\)</span> <span class="math inline">\(\sigma &gt; \sigma_1 + \sigma_2\)</span></li>
<li><span class="math inline">\(x_1(t) \rightarrow^{\mathcal{L}} X_1(s)\)</span> ,<span class="math inline">\(x_2(t) \rightarrow^{\mathcal{L}} X_2(s)\)</span><br />
</li>
<li>特殊形式:
<ul>
<li>指数加权:<span class="math inline">\(e^{-\lambda t}x(t) \rightarrow^{\mathcal{L}} X(s+\lambda)\)</span> ,<span class="math inline">\(\sigma &gt; \sigma_0 - \lambda\)</span></li>
<li>(Key)线性加权:<span class="math inline">\(-tx(t) \rightarrow^{\mathcal{L}} \frac{dX(s)}{ds}\)</span>,<span class="math inline">\(\sigma &gt; \sigma_0\)</span>
<ul>
<li><span class="math inline">\(tx(t) \rightarrow^{\mathcal{L}} -\frac{dX(s)}{ds}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>微分性质:</p>
<ul>
<li><span class="math inline">\(\frac{dX(t)}{dt} \rightarrow^{\mathcal{L}} sX(s) - x(0_{-})\)</span> ,<span class="math inline">\(\sigma &gt; \sigma_0\)</span></li>
<li>高阶微分:
<ul>
<li><span class="math inline">\(\frac{d^n X(t)}{d^n t} \rightarrow^{\mathcal{L}} s^n X(s) - \sum_{r=0}^{n-1} s^{n-r-1} x^{(r)}(0_{-})\)</span> ,<span class="math inline">\(\sigma &gt; \sigma_0\)</span></li>
</ul></li>
</ul></li>
<li><p>积分性质:</p>
<ul>
<li><p><span class="math inline">\(\int_{-\infty}^{t} x(\tau) d\tau \rightarrow^{\mathcal{L}} \frac{X(s)}{s} + \frac{x^{-1}(0_{-})}{s}\)</span> ,<span class="math inline">\(\sigma &gt; \max(\sigma_0,0)\)</span></p></li>
<li><p><span class="math inline">\(x^{-1}(0_{-}) = \int_{-\infty}^{0_{-}} x(\tau) d\tau\)</span></p></li>
</ul></li>
<li><p>初值定理与终值定理:</p>
<ul>
<li>对于因果序列，如果<span class="math inline">\(x(t) \rightarrow^{\mathcal{L}} X(s),\sigma &gt; \sigma_0\)</span>,并且导数可以进行求导，那么
<ul>
<li>如果<span class="math inline">\(x(t)\)</span>在<span class="math inline">\(t=0\)</span>的时候不包含冲激函数及其各阶导数，且对于有理真分式，有<span class="math inline">\(\lim_{t \rightarrow 0} x(t) = x(0_{+}) = \lim_{s \rightarrow \infty}sX(s)\)</span></li>
<li>如果<span class="math inline">\(sX(s)\)</span>的收敛域包含<span class="math inline">\(j\omega\)</span>轴
<ul>
<li><span class="math inline">\(\lim_{t \rightarrow \infty} x(t) = x(\infty) = \lim_{s \rightarrow 0}sX(s)\)</span><br />
</li>
<li>且LT与FT都存在，呈<span class="math inline">\(X(j\omega) = X(s)|_{s=j\omega}\)</span></li>
</ul></li>
<li>如果<span class="math inline">\(sX(s)\)</span>的收敛域不包含<span class="math inline">\(j\omega\)</span>轴
<ul>
<li>LT存在但是FT不存在</li>
</ul></li>
<li>如果<span class="math inline">\(sX(s)\)</span>的收敛域在<span class="math inline">\(j\omega\)</span>轴上
<ul>
<li>LT与FT都存在</li>
<li>且<span class="math inline">\(X(j\omega) = X(s)|_{s=j\omega} + \pi \sum_{n} K_n \delta(\omega - \omega_n)\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h4 id="单边拉普拉斯变换的反变换">单边拉普拉斯变换的反变换</h4>
<ul>
<li><p>通常使用部分分式法进行求解</p>
<ul>
<li><p>LT的结果可以表示为</p>
<ul>
<li><p><span class="math display">\[
  X(s) = \frac{N(s)}{D(s)} = \frac{b_m (s-z_1)(s-z_2)...(s-z_m)}{(s-p_1)(s-p_2)...(s-p_n)}
  \]</span></p></li>
<li><p>其中<span class="math inline">\(z_m\)</span>为零点，<span class="math inline">\(p_n\)</span>为极点</p></li>
</ul></li>
<li><p>求解的时候通常将其化成有理真分式</p>
<ul>
<li><p>对于不满足有理真分式条件的，我们需要先进行提取分子，转换为有理真分式</p></li>
<li><p><span class="math display">\[
  X(s) = \frac{N(s)}{D(s)} = \frac{k_1}{s-p_1} + \frac{k_2}{s-p_2} + ... +\frac{k_n}{s-p_n}
  \]</span></p></li>
<li><p>如果没有重根，那么依次在两边乘以<span class="math inline">\(s-p_i\)</span> ,并且令<span class="math inline">\(s = p_i\)</span>代入求解</p></li>
<li><p>如果有重根，那么对于除最高次项之外的次项需要借助于求导激励性求解</p></li>
<li><p>对于分母集体出现<span class="math inline">\(s^2\)</span>的时候，可以将其看成一个整体进行看待</p></li>
<li><p>在最后得到的结果中，需要借助常用函数的LT进行对应处理:</p>
<ul>
<li><span class="math inline">\(\delta^\prime(t) \rightarrow^{\mathcal{L}} s\)</span></li>
<li><span class="math inline">\(\delta(t) \rightarrow^{\mathcal{L}} 1\)</span></li>
<li><span class="math inline">\(u(t) \rightarrow^{\mathcal{L}} \frac{1}{s}\)</span></li>
<li><span class="math inline">\(e^{-t} u(t) \rightarrow^{\mathcal{L}} \frac{1}{s+1}\)</span></li>
<li><span class="math inline">\(t(u(t)) \rightarrow^{\mathcal{L}} \frac{1}{s^2}\)</span></li>
<li><span class="math inline">\(\cos (\omega_0 t) u(t) \rightarrow^{\mathcal{L}} \frac{s}{s^2 + \omega^2}\)</span></li>
<li><span class="math inline">\(\sin (\omega_0 t) u(t) \rightarrow^{\mathcal{L}} \frac{\omega_0}{s^2 + \omega^2}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h4 id="微分方程与系统的复频域分析">微分方程与系统的复频域分析</h4>
<ul>
<li>借助频域我们可以更快地进行微分方程的求解
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101052128.png" alt="image-20211210105248859" style="zoom:50%;" /></li>
<li>通过微分特性对微分方程转换为s域上的代数方程
<ul>
<li>然后将代数方程转换为与<span class="math inline">\(X(s)\)</span>有关的项作为零状态响应以及与<span class="math inline">\(X(s)\)</span>无关的项作为零输入响应:
<ul>
<li><span class="math inline">\(Y(s) = Y_{zi}(s) + Y_{zs}(s)\)</span> , <span class="math inline">\(y(t) = \mathcal{L}^{-1} [Y(s)]\)</span></li>
</ul></li>
</ul></li>
<li>一个例子:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101104153.png" alt="image-20211210110439014" style="zoom:50%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101105349.png" alt="image-20211210110505211" style="zoom:50%;" /></li>
</ul></li>
</ul></li>
</ul>
<h4 id="系统函数">系统函数</h4>
<ul>
<li><p>定义为:在零状态响应(起始条件为0，即<span class="math inline">\(y^{(i)}(o_{-})=0\)</span>)的情况下，输出的LT与输入的LT的比值,即是系统函数<span class="math inline">\(H(s)\)</span></p>
<ul>
<li><p><span class="math display">\[
  H(s) = \frac{\mathcal{L}[y_{zs}(t)]}{\mathcal{L}[x(t)]} 
  \]</span></p></li>
<li><p>而<span class="math inline">\(y_{zs}(t)\)</span>反映的是<span class="math inline">\(x(t) * h(t)\)</span></p></li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261651231.png" alt="image-20211226165139076" style="zoom:50%;" /></p></li>
</ul>
<h4 id="零极点与时域特性">零极点与时域特性</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101108845.png" alt="image-20211210110841701" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101109207.png" alt="image-20211210110912088" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112101109016.png" alt="image-20211210110933888" style="zoom:50%;" /></p></li>
<li><p>因果系统在𝑠域有界输入有界输出(BIBO)的充要条件是系统函数𝐻(𝑠)的全部极点位于左半𝒔平面</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261346012.png" alt="image-20211226134647881" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261347836.png" alt="image-20211226134713670" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261347902.png" alt="image-20211226134740773" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261348755.png" alt="image-20211226134832630" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261348282.png" alt="image-20211226134847153" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261349377.png" alt="image-20211226134906224" style="zoom:50%;" /></p></li>
</ul>
<h3 id="chap.10">Chap.10</h3>
<h4 id="z变换">z变换</h4>
<ul>
<li>连续信号通过采样获得离散信号:
<ul>
<li><span class="math inline">\(x_s(t) = \sum_{n=0}^{\infty} x(nTs) \delta(t-nT_s)\)</span></li>
<li>对两边取拉普拉斯变换: $X_s(s) = _{n=0}^{} x(nTs) e^{-snT_s} $</li>
<li>令<span class="math inline">\(z = e^{sT_s},s = \frac{1}{T_s} \ln z\)</span> ,$X(z) = _{n=0}^{} x(nTs) z^{-n} $</li>
<li>如果<span class="math inline">\(T_s=1\)</span> ,那么<span class="math inline">\(X(z) = \sum_{n=0}^{\infty} x[n] z^{-n}\)</span> ,<span class="math inline">\(z = e^s\)</span></li>
</ul></li>
</ul>
<h4 id="单边z变换">单边z变换</h4>
<ul>
<li>对于一个序列<span class="math inline">\(x[n]\)</span>,单边z变换为:
<ul>
<li><span class="math inline">\(X(z) = \mathcal{Z}[x[n]] = \sum_{n=0}^{\infty} x[n] z^{-n}\)</span> ,此时<span class="math inline">\(X(z)\)</span>就是<span class="math inline">\(x[n]\)</span>的生成函数</li>
<li>收敛域:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111206919.png" alt="image-20211211120652814" style="zoom:50%;" /></li>
<li>有限长序列的收敛域为<span class="math inline">\(|z|&gt;0\)</span></li>
</ul></li>
</ul></li>
</ul>
<h4 id="常用单边序列的z变换">常用单边序列的z变换</h4>
<ul>
<li><p>常用技巧就是对<span class="math inline">\(a^n\)</span>进行求导，就可以得到<span class="math inline">\(na^n\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{Z} \{\delta[n]\} = 1, z\ge 0\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{Z} \{u[n]\} = \frac{1}{1-z^{-1}}, |z|\ge 1\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{Z} \{n u[n]\} = \frac{z^{-1}}{(1-z^{-1})^{2}}, |z|\ge 1\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{Z} \{a^n u[n]\} = \frac{z}{z -e^b} = \frac{1}{1-e^bz^{-1}}, |z|\ge |e^b|\)</span>,<span class="math inline">\(a = e^b\)</span></p>
<ul>
<li><span class="math inline">\(\mathcal{Z} \{a^n u[n]\} = \frac{1}{1-az^{-1}}\)</span> ,<span class="math inline">\(|z|\ge |a|\)</span></li>
<li><span class="math inline">\(\mathcal{Z} \{n a^n u[n]\} = \frac{az}{(z-a)^2}\)</span></li>
<li><span class="math inline">\(\mathcal{Z} \{e^{j\omega_0 n} u[n]\} = \frac{1}{1-e^{j\omega_0}z^{-1}}\)</span></li>
<li><span class="math inline">\(\mathcal{Z} \{\cos(\omega_n n)u[n]\} \leftrightarrow \frac{1-\cos\omega_0 z^{-1}}{1 - 2z^{-1}\cos\omega_0 + z^{-2}}\)</span>
<ul>
<li>当<span class="math inline">\(\omega_n = \frac{\pi}{2}\)</span>,<span class="math inline">\(\mathcal{Z} \{\cos(\omega_n n)u[n]\} \leftrightarrow \frac{1}{1 + z^{-2}}\)</span></li>
</ul></li>
<li><span class="math inline">\(\mathcal{Z} \{\sin(\omega_n n)u[n]\} \leftrightarrow \frac{\sin\omega_0 z^{-1}}{1 - 2z^{-1}\cos\omega_0 + z^{-2}}\)</span>
<ul>
<li>当<span class="math inline">\(\omega_n = \frac{\pi}{2}\)</span>,<span class="math inline">\(\mathcal{Z} \{\sin(\omega_n n)u[n]\} \leftrightarrow \frac{1}{z(1 + z^{-2})}\)</span><br />
</li>
</ul></li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111308431.png" alt="image-20211211130824325" style="zoom:50%;" /></p></li>
<li><p><span class="math inline">\(a^n\cos(\frac{\pi}{2}n) u[n] = \frac{1}{1+a^2z^{-2}} = \frac{z^2}{z^2+a^2}\)</span></p></li>
<li><p>$a^n(n) u[n] =  $</p></li>
</ul>
<h4 id="双边z变换">双边z变换</h4>
<ul>
<li><span class="math inline">\(X(z) = \sum_{n=-\infty}^{\infty} x[n] z^{-n}\)</span></li>
</ul>
<h4 id="双边z反变换">双边z反变换</h4>
<ul>
<li><span class="math inline">\(x[n] = \mathcal{Z}^{-1}\{X(z)\} = \frac{1}{2\pi j} \oint_c X(z) z^{n-1} dz\)</span></li>
</ul>
<h4 id="单边z变换的性质">单边z变换的性质</h4>
<ul>
<li>线性:
<ul>
<li><span class="math inline">\(ax_1[n]+bx_2[n] \overset{z}\leftrightarrow aX_1(z)+bX_2(z)\)</span> ,<span class="math inline">\(|z| &gt; \max (R_{x_1}, R_{x_2})\)</span></li>
</ul></li>
<li>位移:
<ul>
<li>因果性:系统 n时刻的输出序列只取决于n时刻及以前的输入序列，而与n时刻以后的输入序列无关。</li>
<li>因果序列：<span class="math inline">\(x[n-k]u[n-k] \overset{z}\leftrightarrow z^{-k}X(z)\)</span>,<span class="math inline">\(|z| &gt; R_x\)</span></li>
<li>非因果序列：
<ul>
<li><span class="math inline">\(x[n+k]u[n] \overset{z}\leftrightarrow z^{k}[X(z)-\sum_{n=0}^{k-1} x[n]z^{-n}]\)</span> ,<span class="math inline">\(|z| &gt; R_x\)</span></li>
<li><span class="math inline">\(x[n-k]u[n] \overset{z}\leftrightarrow z^{-k}[X(z)+\sum_{n=-k}^{-1} x[n]z^{-n}]\)</span>,<span class="math inline">\(|z| &gt; R_x\)</span></li>
</ul></li>
</ul></li>
<li>指数加权：
<ul>
<li><span class="math inline">\(a^n x[n] \overset{z}\leftrightarrow X(\frac{z}{a})\)</span> ,<span class="math inline">\(ROC = |a|R_x\)</span></li>
</ul></li>
<li>z域微分:
<ul>
<li><span class="math inline">\(n x[n] \overset{z}\leftrightarrow -z \frac{dX(z)}{dz}\)</span>,<span class="math inline">\(ROC = R_x\)</span></li>
</ul></li>
<li>序列卷积：
<ul>
<li><span class="math inline">\(x_1[k]*x_2[k] \overset{z}\leftrightarrow X_1(z)X_2(z)\)</span> ,<span class="math inline">\(|z| \in R_{x_1} \cap R_{x_2}\)</span></li>
</ul></li>
<li>初值与终值定理:
<ul>
<li><span class="math inline">\(x[0] = \lim_{Z\rightarrow \infty} X(z)\)</span></li>
<li>如果<span class="math inline">\((z-1)X(z)\)</span>的收敛域包含单位圆，那么<span class="math inline">\(x[\infty] = \lim_{Z\rightarrow 1} (z-1)X(z)\)</span></li>
<li>初值与终值定理例子:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111253647.png" alt="image-20211211125323528" style="zoom:50%;" /></li>
</ul></li>
</ul></li>
</ul>
<h4 id="单边z反变换">单边z反变换</h4>
<ul>
<li>仍然是用部分分式法进行求解</li>
</ul>
<h4 id="使用z变换求解差分方程">使用Z变换求解差分方程</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111317662.png" alt="image-20211211131731580" style="zoom:50%;" /></p></li>
<li><p>例子：</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111325531.png" alt="image-20211211132552421" style="zoom:50%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111329106.png" alt="image-20211211132948021" style="zoom:50%;" /></li>
</ul></li>
</ul>
<h4 id="系统函数-1">系统函数</h4>
<ul>
<li>系统在零状态条件下，输出的Z变换与输入的Z变换之比
<ul>
<li><span class="math inline">\(H(z) = \frac{\mathcal{Z}[y_{zs}[n]]}{\mathcal{Z} [x[n]]}\)</span></li>
</ul></li>
</ul>
<h4 id="零极点分布">零极点分布</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111337420.png" alt="image-20211211133720323" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111338126.png" alt="image-20211211133815017" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112111338029.png" alt="image-20211211133831918" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261949628.png" alt="image-20211226194905459" style="zoom:50%;" /></p></li>
</ul>
<h4 id="离散系统的稳定性">离散系统的稳定性</h4>
<ul>
<li><p>离散LTI系统稳定的充要条件为<span class="math inline">\(\sum_{n=-\infty}^{\infty} |h[n]| &lt; \infty\)</span></p></li>
<li><p><span class="math inline">\(H(z)\)</span>的收敛域包含单位圆，那么系统就稳定</p></li>
<li><p><strong>因果系统</strong>的<strong>极点都在单位圆内</strong>，那么系统就稳定</p></li>
</ul>
<h3 id="ppt习题">PPT习题</h3>
<h4 id="chap.2-ex">Chap.2 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241949837.png" alt="image-20211224194920774" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241951949.png" alt="image-20211224195108885" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241954058.png" alt="image-20211224195453982" style="zoom:50%;" /></p>
<ul>
<li><p>对角斜线上的值(数组行列的乘积)就是我们所求的<span class="math inline">\(y[n]\)</span>的每一个求和项。</p></li>
<li><p>按照离散信号的表格记法，箭头指的位置就是<span class="math inline">\(x[0]/h[0]\)</span>的位置。</p></li>
<li><p>另外还有一个矩阵法:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112241957843.png" alt="image-20211224195707789" style="zoom:50%;" /></p></li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242010787.png" alt="image-20211224201052718" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242024799.png" alt="image-20211224202422727" style="zoom:50%;" /></p></li>
<li><p>这里的可利用信息就是<span class="math inline">\(u(t) * u(t) = r(t) = tu(t)\)</span> ,将<span class="math inline">\(x(t),h(t)\)</span>写成<span class="math inline">\(u(t)\)</span>的组合。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242039737.png" alt="image-20211224203947665" style="zoom:50%;" /></p>
<ul>
<li>这里第一步的原因为 <span class="math display">\[
  x(t) = u(t) - u(t-1) \\
  u(t)^\prime恰好是\delta(t)
  \]</span></li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242051610.png" alt="image-20211224205142545" style="zoom:50%;" /></p></li>
<li><p>可利用信息：离散序列可以转变为冲激序列然后利用卷积性质运算。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242100761.png" alt="image-20211224210049697" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242108203.png" alt="image-20211224210808129" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242118353.png" alt="image-20211224211808278" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242118918.png" alt="image-20211224211854843" style="zoom:50%;" /></p></li>
</ul>
<h4 id="chap.3-ex">Chap.3 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242210329.png" alt="image-20211224221012245" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242224060.png" alt="image-20211224222438995" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242240796.png" alt="image-20211224224042722" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112242252402.png" alt="image-20211224225219309" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251050301.png" alt="image-20211225105050229" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251051762.png" alt="image-20211225105104686" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251140678.png" alt="image-20211225114026603" style="zoom: 50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251217222.png" alt="image-20211225121711137" style="zoom:50%;" /></p>
<ul>
<li>这里因为我们求的是冲激响应<span class="math inline">\(h[n]\)</span>,因此，可以将<span class="math inline">\(\delta[n]\)</span>作为输入激励<span class="math inline">\(x[n]\)</span>传入,得到的输出<span class="math inline">\(y[n]\)</span>就是<span class="math inline">\(h[n]\)</span>。可以借助这一点求出初始条件，用来代入齐次解求得零输入响应。</li>
<li>因为是因果系统，因此0之前的单位脉冲响应都为0</li>
</ul></li>
</ul>
<h4 id="chap.4-ex">Chap.4 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251338909.png" alt="image-20211225133857814" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251349224.png" alt="image-20211225134909152" style="zoom:50%;" /></p>
<ul>
<li>其实，可以利用<span class="math inline">\(X_n = \frac{a_n}{2} - \frac{j b_n}{2}\)</span>直接求指数分量</li>
</ul></li>
</ul>
<h4 id="chap.5-ex">Chap.5 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251426821.png" alt="image-20211225142654728" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112251621993.png" alt="image-20211225162159902" style="zoom:50%;" /></p></li>
</ul>
<h4 id="chap.6-ex">Chap.6 ex</h4>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112252128310.png" alt="image-20211225212801185" style="zoom:50%;" />
<ul>
<li>求采样后的信号的频谱，就是求采样信号的频谱与原信号的频谱的卷积。</li>
<li>由于是周期信号，因此，傅里叶变换需要借助傅里叶级数的展开。</li>
<li>傅里叶级数与傅里叶变换的转换公式可以带来冲激信号，有利于卷积预算。</li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112252152481.png" alt="image-20211225215208362" style="zoom:50%;" /></li>
</ul>
<h4 id="chap.7-ex">Chap.7 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261058528.png" alt="image-20211226105841391" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261059784.png" alt="image-20211226105910682" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261059087.png" alt="image-20211226105937985" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261100042.png" alt="image-20211226110011927" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261101557.png" alt="image-20211226110109444" style="zoom:50%;" /></p></li>
</ul>
<h4 id="chap.8-ex">Chap.8 ex</h4>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261114413.png" alt="image-20211226111415276" style="zoom:50%;" />
<ul>
<li>不要求计算</li>
</ul></li>
</ul>
<h4 id="chap.9-ex">Chap.9 ex</h4>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261306453.png" alt="image-20211226130655342" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261325936.png" alt="image-20211226132545806" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261326747.png" alt="image-20211226132648612" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261330500.png" alt="image-20211226133036355" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261332571.png" alt="image-20211226133252445" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261333730.png" alt="image-20211226133324610" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261334126.png" alt="image-20211226133431988" style="zoom:50%;" /></p>
<ul>
<li>对二次求导之后的结果进行拉普拉斯变换，左右对应相等。</li>
</ul>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261335361.png" alt="image-20211226133522224" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261335789.png" alt="image-20211226133539651" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261339596.png" alt="image-20211226133943465" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261340996.png" alt="image-20211226134021831" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261341255.png" alt="image-20211226134101115" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261341128.png" alt="image-20211226134128999" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261342066.png" alt="image-20211226134201944" style="zoom:50%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261342243.png" alt="image-20211226134225114" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261342949.png" alt="image-20211226134249812" style="zoom:50%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261343424.png" alt="image-20211226134311285" style="zoom:50%;" /></p></li>
</ul>
<h4 id="chap.10-ex">Chap.10 ex</h4>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112261714867.png" alt="image-20211226171411706" style="zoom:50%;" /></li>
</ul>
]]></content>
      <categories>
        <category>DSP Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>DSP</tag>
      </tags>
  </entry>
  <entry>
    <title>Chap.12 计算学习理论</title>
    <url>/2021/12/22/%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<h4 id="计算学习理论">计算学习理论</h4>
<h5 id="基础知识">基础知识</h5>
<ul>
<li><p>对于一个数据集<span class="math inline">\(D = (\mathcal{X},\mathcal{Y})\)</span>,假设<span class="math inline">\(\mathcal{X}\)</span>中的所有样本都是从分布<span class="math inline">\(\mathcal{D}\)</span>当中采样出来的且服从独立同分布采样。</p></li>
<li><p><span class="math inline">\(h:\mathcal{X}-&gt;\mathcal{Y}\)</span>,定义泛化误差：</p>
<ul>
<li><p><span class="math display">\[
  E(h;\mathcal{D}) = P_{x&lt;-\mathcal{D}}(h(x)\not = y)
  \]</span></p>
<p>预测结果与label不一致。</p></li>
</ul></li>
<li><p>定义<span class="math inline">\(h\)</span>在<span class="math inline">\(D\)</span>上的经验误差：</p>
<ul>
<li><span class="math display">\[
  \hat{E}(h;D) = \frac{1}{m}\sum_{i=1}^m \mathbb{I}(h(x_i) \not= y_i)
  \]</span></li>
</ul></li>
<li><p>由于<span class="math inline">\(D\)</span>是分布<span class="math inline">\(\mathcal{D}\)</span>的独立同分布采样，因此，<span class="math inline">\(\mathbb{E}[\hat{E}(h;D)] = E(h;\mathcal{D})\)</span>,对于<span class="math inline">\(E(h;\mathcal{D})\)</span>有一个上限<span class="math inline">\(\epsilon\)</span> ,称其为误差参数。</p></li>
<li><p>如果经验误差为0，那么就认为<span class="math inline">\(h\)</span>与<span class="math inline">\(D\)</span>一致，否则不一致</p></li>
</ul>
<span id="more"></span>
<ul>
<li><p>常用不等式：</p>
<ul>
<li><p>Jensen不等式：</p>
<ul>
<li>对任意的凸函数<span class="math inline">\(f(x)\)</span>,有 <span class="math display">\[
  f(\mathbb{E(x)}) \le \mathbb{E}(f(x))
  \]</span></li>
</ul></li>
<li><p>Hoeffding不等式：</p>
<ul>
<li>若<span class="math inline">\(x_1,x_2,...,x_m\)</span>为m个独立随机变量，并且满足<span class="math inline">\(x_i \sub [0,1]\)</span>,则对任意的<span class="math inline">\(\epsilon &gt; 0\)</span>,有 <span class="math display">\[
  P(\frac{1}{m} \sum_{i=1}^m x_i - \frac{1}{m} \sum_{i=1}^m\mathbb{E}(x_i) \ge \epsilon) \le\exp(-2m\epsilon^2) \\
  P(|\frac{1}{m} \sum_{i=1}^m x_i - \frac{1}{m} \sum_{i=1}^m\mathbb{E}(x_i)| \ge \epsilon) \le 2 \exp(-2m\epsilon^2)
  \]</span></li>
</ul></li>
<li><p>McDiarmid不等式：</p>
<ul>
<li>若<span class="math inline">\(x_1,x_2,...,x_m\)</span>为m个独立随机变量，且对任意的<span class="math inline">\(i\sub[1,m]\)</span>,函数f满足 <span class="math display">\[
  \sup_{x_1,..,x_m,x_i^\prime} |f(x_1,..,x_m) - f(x_1,..,x_{i-1},x_i^\prime,x_{i+1},...,x_m)| \le c_i
  \]</span> 那么对于任意的<span class="math inline">\(\epsilon &gt; 0\)</span>,有 <span class="math display">\[
  P(f(x_1,..,x_m)-\mathbb{E}(f(x_1,..,x_m)) \ge \epsilon) \le \exp(\frac{-2\epsilon^2}{\sum_i c_i^2}) \\
  P(|f(x_1,..,x_m)-\mathbb{E}(f(x_1,..,x_m))| \ge \epsilon) \le 2\exp(\frac{-2\epsilon^2}{\sum_i c_i^2}) 
  \]</span></li>
</ul></li>
</ul></li>
</ul>
<h5 id="pac可学习">PAC可学习</h5>
<ul>
<li><p>概率近似正确学习理论（PAC）是计算学习理论中最基本的。</p></li>
<li><p>令<span class="math inline">\(c\)</span>表示一个概念，如果对于任意的<span class="math inline">\((x,y)\)</span>都有<span class="math inline">\(c(x) = y\)</span>成立，那么<span class="math inline">\(c\)</span>就是目标概念，所有目标概念所构成的集合就是概念类<span class="math inline">\(\mathcal{C}\)</span>。</p></li>
<li><p>给定任意一个学习算法<span class="math inline">\(\mathcal{L}\)</span>,它所考虑的所有可能概念的集合为假设空间<span class="math inline">\(\mathcal{H}\)</span>。如果目标概念<span class="math inline">\(c \in \mathcal{H}\)</span>,那么在当前假设空间中存在能把所有示例按照与真实label一致的方式分开，那么，我们称该问题对于学习算法<span class="math inline">\(\mathcal{L}\)</span>是可分的/一致的，反之，如果<span class="math inline">\(c\not\in \mathcal{H}\)</span>,那就不可分/不一致了。</p></li>
<li><p>而一般学习任务的目标就是近似这个目标概念<span class="math inline">\(c\)</span>,由于机器学习过程诸多因素的制约，我们无法希望<span class="math inline">\(h\)</span>可以精确地学到目标概念<span class="math inline">\(c\)</span>。</p></li>
<li><p>如果对于<span class="math inline">\(\epsilon &gt; 0, \delta &lt; 1\)</span>,存在一个学习算法<span class="math inline">\(\mathcal{L}\)</span>,其输出假设<span class="math inline">\(h\in\mathcal{H}\)</span>满足 <span class="math display">\[
  P(E(h)\le \epsilon) \ge 1 - \delta
  \]</span> 那么称该学习算法能够在假设空间中PAC辨识概念类<span class="math inline">\(\mathcal{C}\)</span>,他以<span class="math inline">\(1 - \delta\)</span>的概率学到了目标概念的一个近似（差一个<span class="math inline">\(\epsilon\)</span>）。</p></li>
<li><p>如果从分布<span class="math inline">\(\mathcal{D}\)</span>中采样得到m个样例，<span class="math inline">\(\epsilon &gt; 0, \delta &lt; 1\)</span>,对所有的分布<span class="math inline">\(\mathcal{D}\)</span>,如果存在学习算法<span class="math inline">\(\mathcal{L}\)</span>和多项式表示<span class="math inline">\(poly\)</span>,能够使得任意的<span class="math inline">\(m \ge poly(1/\epsilon, 1/\delta,size(x),size(c))\)</span>,学习算法能够在假设空间中PAC辨识概念类<span class="math inline">\(\mathcal{C}\)</span>,那么称概念类<span class="math inline">\(\mathcal{C}\)</span>对于假设空间<span class="math inline">\(\mathcal{H}\)</span>是PAC可学习的。</p>
<ul>
<li>如果满足上述条件的学习算法是多项式时间的，那么称概念类<span class="math inline">\(\mathcal{C}\)</span>是高效PAC可学习的，并且称学习算法<span class="math inline">\(\mathcal{L}\)</span>为概念类<span class="math inline">\(\mathcal{C}\)</span>的PAC学习算法。</li>
<li>满足上述条件的最小的<span class="math inline">\(m\)</span>称为学习算法<span class="math inline">\(\mathcal{L}\)</span>的样本复杂度。</li>
<li>PAC学习将复杂算法的时间复杂度的分析转换为了对于样本复杂度的分析，并且对于机器学习给出了一个抽象的理论框架。</li>
</ul></li>
<li><p>按照<span class="math inline">\(|\mathcal{H}|\)</span>是否有限，也可以将假设空间分为有限假设空间以及无限假设空间。</p>
<ul>
<li><p>有限假设空间都是PAC可学习的，输出<span class="math inline">\(h\)</span>的泛化误差随着样例数目的增多而逐渐收敛到0，证明如下：</p>
<ul>
<li><p><span class="math display">\[
  P(h(x)=y) = 1 - P(h(x)\not=y)\\
            = 1 - E(h) \\
            &lt; 1 - \epsilon
  \]</span></p></li>
<li><p>假设D中包含了从<span class="math inline">\(\mathcal{D}\)</span>分布中采样得到的<span class="math inline">\(m\)</span>个样例，因此，<span class="math inline">\(h\)</span>与D表现一致的概率为： <span class="math display">\[
  P(h(x_i)=y_i,\forall i\in [m]) &lt;(1-\epsilon)^m
  \]</span></p></li>
<li><p><span class="math inline">\(P(h\in \mathcal{H}:E(h)&gt;\epsilon\ and\ \hat{E}(h) =0) &lt; |\mathcal{H}|(1-\epsilon)^m &lt; |\mathcal{H}| e^{-m\epsilon}\)</span> <span class="math inline">\(|\mathcal{H}| e^{-m\epsilon}\le \delta\)</span></p>
<p><span class="math inline">\(m\ge \frac{1}{\epsilon}(\ln|\mathcal{H}| +\ln\frac{1}{\delta})\)</span></p></li>
</ul></li>
</ul></li>
<li><p>经验风险最小化（ERM）原则：</p>
<ul>
<li>对于学习算法的一个输出<span class="math inline">\(h\)</span>,如果满足： <span class="math display">\[
  \hat{E}(h) = \min_{h^\prime\in\mathcal{H}}\hat{E}(h^\prime)
  \]</span> 学习算法<span class="math inline">\(\mathcal{L}\)</span>为满足经验风险最小化（ERM）原则的算法。</li>
</ul></li>
<li><p>如果从分布<span class="math inline">\(\mathcal{D}\)</span>中采样得到m个样例，<span class="math inline">\(\epsilon &gt; 0, \delta &lt; 1\)</span>,对所有的分布<span class="math inline">\(\mathcal{D}\)</span>,如果存在学习算法<span class="math inline">\(\mathcal{L}\)</span>和多项式表示<span class="math inline">\(poly\)</span>,能够使得任意的<span class="math inline">\(m \ge poly(1/\epsilon, 1/\delta,size(x),size(c))\)</span>,且<span class="math inline">\(\mathcal{L}\)</span>的输出满足： <span class="math display">\[
  P(E(h)-\min_{h^\prime\in\mathcal{H}}E(h^\prime) \le \epsilon) \ge 1-\delta
  \]</span> 则称假设空间<span class="math inline">\(\mathcal{H}\)</span>是不可知PAC可学习的。</p></li>
</ul>
<h5 id="vc维">VC维</h5>
<ul>
<li><p>增长函数<span class="math inline">\(\Pi_{\mathcal{H}}(m)\)</span>是假设空间中对m个样例所能赋予label的最大可能结果数。</p></li>
<li><p>对于假设空间中对<span class="math inline">\(D\)</span>中<span class="math inline">\(m\)</span>个样例赋予的每种可能结果，我们都将其称为是对数据集<span class="math inline">\(D\)</span>的一个对分。</p></li>
<li><p>如果假设空间<span class="math inline">\(\mathcal{H}\)</span>能够实现<span class="math inline">\(D\)</span>中的所有对分,即<span class="math inline">\(\Pi_{\mathcal{H}}(m) = 2^m\)</span>,那么就称D能被假设空间<span class="math inline">\(\mathcal{H}\)</span>打散。</p></li>
<li><p>将能够将假设空间<span class="math inline">\(\mathcal{H}\)</span>打散的最大示例集的大小称为<span class="math inline">\(VC\)</span>维</p>
<ul>
<li><p>计算方式，存在大小为d的示例集能够被假设空间<span class="math inline">\(\mathcal{H}\)</span>打散,但是任意的大小为d+1的示例集都不能够被假设空间<span class="math inline">\(\mathcal{H}\)</span>打散,则<span class="math inline">\(VC\)</span>维为d。</p></li>
<li><p><span class="math inline">\(VC\)</span>维为d那么对任意的<span class="math inline">\(m\in\mathbb{N}\)</span>: <span class="math display">\[
  \Pi_{\mathcal{H}}(m) \le \sum_{i=1}^d C_m^i
  \]</span></p></li>
</ul></li>
<li></li>
<li><p>任何<span class="math inline">\(VC\)</span>维有限的假设空间<span class="math inline">\(\mathcal{H}\)</span>都是PAC可学习的。</p></li>
</ul>
<h5 id="rademacher复杂度">Rademacher复杂度</h5>
<h5 id="稳定性">稳定性</h5>
<ul>
<li><p>Rademacher复杂度与VC维都与具体的学习算法无关，对所有的学习算法都是适用的，则可以让我们脱离具体学习算法的本身来学习问题本身。而如果想要分析算法，稳定性是值得关注的。</p></li>
<li><p>稳定性指的是算法在输入发生变化的情况下，输出是否随之发生较大的变化。</p></li>
<li><p>两种示例集变化：</p>
<ul>
<li><span class="math inline">\(D^{i}\)</span></li>
</ul></li>
<li><p>泛化误差与经验误差：</p>
<ul>
<li>泛化误差:<span class="math inline">\(l(\mathcal{L},\mathcal{D})\)</span></li>
<li>经验误差：<span class="math inline">\(\hat{l}(\mathcal{L},\mathcal{D})\)</span></li>
</ul></li>
<li><p>均匀稳定性：</p>
<ul>
<li><p><span class="math display">\[
  |l(\mathcal{L}_D,z) - l(\mathcal{L}_D,z)| \le \beta
  \]</span></p>
<p>则称<span class="math inline">\(\mathcal{L}\)</span>关于损失函数<span class="math inline">\(l\)</span>满足<span class="math inline">\(\beta\)</span>-均匀稳定性。</p></li>
</ul></li>
<li><p>如果算法是ERM并且稳定的，那么假设空间可学习。</p></li>
</ul>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>编译原理笔记</title>
    <url>/2022/01/04/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="chap.1">Chap.1</h3>
<h4 id="编译器">编译器</h4>
<ul>
<li><p>编译器是一段程序，以<strong>某种源语言</strong>为输入，输出<strong>该语言翻译为目标语言</strong>的结果,一般会生成<strong>可执行的目标程序</strong>。</p>
<ul>
<li>可以是程序语言-&gt;机器代码的过程，也可以是c++-&gt;python的过程</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031330468.png" alt="image-20220103133017426" style="zoom:80%;" /></li>
</ul></li>
<li><p>与编译器相比，解释器不生成中间程序，<strong>直接解释程序输入</strong>，<strong>边解释边执行</strong>。</p></li>
<li><p>编译器的结构可以分为两个部分：分析源程序信息<strong>加入符号表</strong> <strong>与机器无关</strong>的<strong>前端</strong>以及根据符号表以及中间表示<strong>构造目标程序</strong>的<strong>与机器有关</strong>的<strong>后端</strong>。</p>
<ul>
<li>更具体来说，到<strong>中间代码生成为止</strong>，可以划分为<strong>前端</strong>。</li>
<li>从<strong>代码生成</strong>开始划分为<strong>后端</strong>。</li>
<li><strong>前端后端分开</strong>的好处：<strong>不同的源语言、不同的机器</strong>可以得到<strong>不同的编译器组合</strong> ,可以进行<strong>相同的中间代码优化</strong>。</li>
</ul>
<p><span id="more"></span></p></li>
<li><p>编译器执行的确定步骤为:</p>
<ul>
<li>由输入的源程序的<strong>字符流</strong>通过<strong>词法分析</strong>生成<strong>符号流</strong>，再通过<strong>语法分析、语义分析</strong>生成一棵<strong>语法树</strong>，通过<strong>中间代码生成器</strong>产生<strong>中间代码表示</strong>，用<strong>机器无关代码优化器</strong>进行优化，最终通过<strong>代码生成器</strong>产生<strong>目标机器语言</strong>，并利用<strong>机器相关代码优化器</strong>生成<strong>目标机器语言</strong>。</li>
<li>其中的信息用<strong>符号表</strong>进行保存，收集<strong>各种属性信息</strong>，可以<strong>由上述所有过程</strong>使用。</li>
<li>编译器划分多个阶段的原因在于，通过<strong>任务分解</strong> <strong>简化编译器的设计</strong>，<strong>提高编译器的效率</strong>，增强编译器的<strong>可移植性</strong>。</li>
</ul></li>
<li><p>词法分析</p>
<ul>
<li>分析输入的字符流，生成<strong>词素</strong>(lexeme),基于词素，生成<strong>词法单元</strong>,形式为<span class="math inline">\(&lt;token-name,attribute-name&gt;\)</span>,token-name可以给<strong>语法分析</strong>步骤使用，attribute-name指向<strong>相应的符号表条目</strong>，由<strong>语义分析/代码生成</strong>步骤使用。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031315017.png" alt="image-20220103131554949" style="zoom:80%;" /></li>
</ul></li>
<li><p>语法分析</p>
<ul>
<li>语法分析<strong>接受</strong>词法分析输出的<strong>词法单元</strong>，根据token-name<strong>生成语法树</strong>，表明词法单元的<strong>语法结构</strong>。</li>
</ul></li>
<li><p>语义分析</p>
<ul>
<li>根据<strong>符号表以及语法树</strong>的信息，检查源程序<strong>是否满足语言定义的语义约束</strong>，同时，搜集<strong>类型信息</strong>，进行<strong>类型检查</strong>，<strong>类型转换</strong>,<strong>中间代码</strong> 的翻译。</li>
</ul></li>
<li><p>中间代码生成</p>
<ul>
<li>根据<strong>语义分析</strong>的输出，<strong>生成</strong>类机器语言的中间表示(通常是<strong>三地址代码</strong>,还有<strong>抽象语法树</strong>的形式）。</li>
<li>三地址代码：每个指令<strong>最多包含三个运算分量</strong></li>
</ul></li>
<li><p>机器无关代码优化器</p>
<ul>
<li><p>通过对中间代码的分析，<strong>改进中间代码</strong>，得到更好的目标代码</p>
<p>使之运行的<strong>更快</strong>、占用<strong>更少</strong>的内存：<strong>少占资源</strong></p></li>
</ul></li>
<li><p>代码生成器</p>
<ul>
<li>把<strong>中间代码表示</strong>形式<strong>映射到目标语言</strong>,<strong>分配寄存器、分配内存、选择指令</strong></li>
</ul></li>
<li><p>编译器的趟(Pass):</p>
<ul>
<li><strong>以文件为输入输出单位</strong>的编译过程的个数</li>
</ul></li>
<li><p>程序设计语言和编译器之间的关系：</p>
<ul>
<li>程序设计语言的发展<strong>向编译器提出新的要求</strong>，设计<strong>相应的算法和表示方法</strong>来<strong>翻译和支持新的语言特征</strong>，编译器的发展可以<strong>降低高级语言的执行开销</strong>。</li>
</ul></li>
</ul>
<h3 id="chap.3">Chap.3</h3>
<h4 id="词法分析器作用">词法分析器作用</h4>
<ul>
<li>读入源程序<strong>输入的字符流</strong>，生成<strong>词素</strong>(lexeme),基于<strong>词素</strong>，生成并输出<strong>词法单元</strong>，可以被<strong>供语法分析</strong>阶段使用。</li>
<li>一个常见的用法是
<ul>
<li>让语法分析器<strong>在需要时</strong>，调用，<strong>生成、传递词法单元</strong>，以<strong>避免额外的输入输出</strong>。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201051521889.png" alt="image-20220105152116800" style="zoom:80%;" /></li>
</ul></li>
<li>常见的构造方式：
<ul>
<li>手工编写代码扫描输入中的每个词素</li>
<li>使用词法分析器生成工具（如lex flex）。</li>
</ul></li>
</ul>
<h5 id="词法单元及相关概念">词法单元及相关概念</h5>
<ul>
<li>词法单元（Token）:
<ul>
<li>形式为<span class="math inline">\(&lt;token-name,attribute-value&gt;\)</span>,token-name是某种<strong>词法单位抽象符号</strong>，attribute-value为<strong>属性值</strong>。</li>
<li><strong>属性值</strong>被用于<strong>语义分析、代码生成</strong>等阶段。不同的目的需要不同的属性。因此，属性值通常是一个<strong>结构化</strong>数据。例如，记录类型、位置等。</li>
</ul></li>
<li>词素（Lexeme）:
<ul>
<li>源程序中的<strong>字符序列</strong>,<strong>与模式匹配</strong>，被词法分析器识别为该词法单元的<strong>实例</strong>。</li>
</ul></li>
<li>模式（Pattern）：
<ul>
<li>描述<strong>词素的形式</strong>，一般为<strong>正则表达式</strong>。</li>
</ul></li>
<li>字母表：
<ul>
<li>表示一个<strong>有限的符号集合</strong>。</li>
</ul></li>
<li>串
<ul>
<li>用<strong>字母表</strong>中的符号组成的<strong>有穷</strong>集合。</li>
<li>有连接运算以及幂次运算，幂次：相同的连接。</li>
</ul></li>
<li>前缀、后缀，子串：
<ul>
<li>按照常见定义的串中<strong>连续</strong>的一段集合。</li>
<li>真前缀、真后缀，真子串表示与原串不同。</li>
<li>规范定义是：去掉<strong>串头部或者尾部</strong>的几个字母。</li>
</ul></li>
<li>子序列：
<ul>
<li>串中的一段集合，可以是<strong>非连续</strong>的。</li>
</ul></li>
<li>语言：
<ul>
<li>给定<strong>字母表上一个任意的可数的串</strong>的集合</li>
<li>有并运算、连接运算、Kleene闭包（包含空集的<span class="math inline">\(L^i\)</span>构成的集合）、正闭包（不包含空集的<span class="math inline">\(L^i\)</span>构成的集合）</li>
</ul></li>
</ul>
<h4 id="正则表达式re">正则表达式(RE)</h4>
<ul>
<li><p>每个正则表达式r可以描述一个语言L(r)，也即其定义的正则集合。</p></li>
<li><p>正则表达式的运算:</p>
<ul>
<li><p>对于某个符号或者空符号<span class="math inline">\(f\)</span>: <span class="math display">\[
  L(f) = \{f\}
  \]</span></p></li>
<li><p>选择 <span class="math display">\[
  L(r|s) = L(r) \cup L(s)
  \]</span></p></li>
<li><p>连接 <span class="math display">\[
  L(rs) = L(r)L(s)
  \]</span></p></li>
<li><p>闭包 <span class="math display">\[
  L(r^*) = L(r) ^*
  \]</span></p>
<ul>
<li>闭包含有幂等性<span class="math inline">\(** = *\)</span></li>
</ul></li>
<li><p>括号 <span class="math display">\[
  L((r)) = L(r)
  \]</span></p></li>
<li><p>优先级方面: <span class="math inline">\(*\)</span>&gt;连接&gt;选择</p></li>
<li><p>等价性 <span class="math display">\[
  L(r) = L(s),L=s
  \]</span></p></li>
<li><p>一个或多个<span class="math inline">\(+\)</span>: <span class="math display">\[
  L(r^+) = L(r)L(r^*)
  \]</span></p></li>
<li><p>零个或多个<span class="math inline">\(?\)</span>: <span class="math display">\[
  L(r?) = L(\epsilon|r) = L(r) \cup L(\epsilon)
  \]</span></p></li>
<li><p><span class="math inline">\([]\)</span>: <span class="math display">\[
  L([abc]) = L([a-c]) = L(a|b|c)
  \]</span></p></li>
</ul></li>
<li><p>利用正则表达式可以对字母表中的符号进行<strong>正则定义</strong>。 <span class="math display">\[
  symbol \rightarrow RE
  \]</span></p></li>
</ul>
<h4 id="词法单元的识别">词法单元的识别</h4>
<ul>
<li>首先<strong>通过正则定义</strong>来<strong>描述各种词法单元</strong>的模式</li>
<li>词法分析器可以<strong>将正则表达式转换成状态转换图</strong>:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031442739.png" alt="image-20220103144223700" style="zoom:80%;" /> 表示开始状态</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031442850.png" alt="image-20220103144247803" style="zoom:80%;" /> 表示每一个可能状态，<strong>接收状态为两个圈</strong>，如果两个圈加*表示识别的内容不在词素中。</li>
</ul></li>
<li>词法分析中<strong>对于保留字以及标识符</strong>会进行<strong>优先识别</strong>，<strong>事先建立单独的状态转换图</strong>。</li>
<li>通过switch以及state变量就可以通过转换图构造词法分析器。
<ul>
<li><strong>每个状态对应于一段代码</strong></li>
<li>如果<strong>找不到相应的边</strong>，则调用fail()</li>
<li>进入某个接受状态时，返回<strong>相应的词法单元</strong></li>
<li>有*标记时，需要回退forward指针</li>
</ul></li>
</ul>
<h4 id="有穷自动机-fa">有穷自动机 FA</h4>
<ul>
<li><p><strong>本质上与状态转换图等价</strong></p></li>
<li><p>区别在于自动机是<strong>识别器</strong>，对<strong>每个输入串回答yes or no</strong></p>
<ul>
<li><p>分为NFA,DFA,都可以识别RE，每个NFA存在等价转换为DFA的方式</p></li>
<li><p>NFA与DFA的区别在于（<strong>确定性以及不确定性</strong>）:</p>
<ul>
<li><p>一个符号<strong>标记</strong>离开同一状态的<strong>多条边</strong> vs</p>
<p>对于<strong>每个状态</strong>和字母表中的<strong>每个字符</strong>，<strong>有且仅有 一条离开该状态、以该符号为标号的边</strong>:</p>
<ul>
<li>意为对于每个状态，<strong>一个标记</strong>对应<strong>一个目标状态</strong></li>
</ul></li>
<li><p><strong>可以</strong>有边的标号是ε vs</p>
<p><strong>没有</strong>标记为ε的边</p></li>
</ul></li>
</ul></li>
<li><p>NFA可以表示为一个转换表:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031507862.png" alt="image-20220103150706793" style="zoom:80%;" />
<ul>
<li>表中元素表示可以前往的状态。</li>
</ul></li>
<li>NFA的模拟,需要用到子集构造法:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201051444568.png" alt="image-20220105144430509" style="zoom:80%;" />
<ul>
<li>与DFA的区别就在于，<strong>NFA</strong>需要<strong>闭包</strong>运算，<strong>DFA不用</strong>。</li>
</ul></li>
</ul></li>
<li>一个NFA<strong>接受</strong>输入字符串x<strong>输出yes</strong>，<strong>当且仅当</strong>对应的转换图中<strong>存在一条</strong>从开始状态到某个接受状态的路径，使得该路径中<strong>各条边上的标号组成符号串x</strong> 。 （路径中可能包含ε 边）
<ul>
<li>从开始状态到某个接受状态的所有路径上的符号串集合，称为接受的语言集合<em>L(A)</em></li>
</ul></li>
</ul></li>
<li><p>DFA:</p>
<ul>
<li>可以高效判断一个串能否被一个DFA接受.
<ul>
<li>一个输入可以<strong>走向确定的状态</strong></li>
</ul></li>
<li>DFA的模拟：
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201051436498.png" alt="image-20220105143610415" style="zoom:80%;" /></li>
<li>F是<strong>状态集合S</strong>的子集，s在F中表示<strong>接受状态</strong></li>
</ul></li>
<li><strong>正则表达式</strong>可以表示<strong>词法单元的模式</strong>，但<strong>模式匹配</strong>的过程需要DFA的帮助。因此，需要把<strong>正则表达式转为DFA</strong>。一般会先把<strong>正则表达式转为NFA,再将NFA转为DFA</strong>。</li>
<li><strong>将NFA转为DFA</strong>——子集构造法:<span class="math inline">\(\color{red}{Key}\)</span>
<ul>
<li><span class="math inline">\(\epsilon-closure(x)\)</span>:从x出发<strong>只通过<span class="math inline">\(\epsilon\)</span></strong>可以达到的状态集合,<span class="math inline">\(\color{red}{包含x本身}\)</span> 。</li>
</ul></li>
<li><span class="math inline">\(move(x,y)\)</span>:从x状态出发，通过y边可以抵达的状态集合。
<ul>
<li>以<span class="math inline">\(\epsilon-closure(0)\)</span>为初始状态</li>
<li>之后<strong>尝试所有非空输入边x</strong>，<span class="math inline">\(\epsilon-closure(move(T,x))\)</span>生成一个新状态<span class="math inline">\(T_1\)</span> <span class="math inline">\(\color{red}{注意这里有两步，求转移状态+求闭包}\)</span></li>
<li>然后对新状态尝试所有非空输入边x，<strong>直到不再生成新状态</strong></li>
</ul></li>
</ul></li>
<li><p>DFA状态数最小化:对DFA进行化简<span class="math inline">\(\color{red}{Key}\)</span></p>
<ul>
<li>如果分别从状态s和状态t出发，沿着标号为x的路径到达的<strong>两个状态只有一个是接受状态</strong>，称为<strong>x区分状态s和t</strong>。</li>
<li>最小化的过程：
<ul>
<li>按照接受与否，将状态划分为<strong>接受状态集</strong>以及<strong>其他状态集</strong></li>
<li>对于<strong>其他状态集</strong>,寻找可以区分其他状态集的边,并按照区分进行分割<span class="math inline">\(Set_1,Set_2\)</span>,也就是通过<strong>一个串</strong>拆分为<strong>可以抵达接受态</strong>和<strong>不可抵达接受态</strong>。</li>
<li>对于<span class="math inline">\(Set_1,Set_2\)</span>重复上步，直至<strong>无状态可分</strong>。 (<strong>划分</strong>)</li>
<li>从每个集合中<strong>选取一个代表</strong>，组成<strong>化简后的DFA</strong>。 (<strong>构造</strong>)</li>
</ul></li>
</ul></li>
<li><p>正则表达式到NFA:</p>
<ul>
<li><p>按照一定模式，进行转换。<span class="math inline">\(\color{red}{记一记就好}\)</span></p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031552830.png" alt="image-20220103155207777" /><figcaption aria-hidden="true">image-20220103155207777</figcaption>
</figure></li>
<li><figure>
<img src="C:\Users\cyq\AppData\Roaming\Typora\typora-user-images\image-20220103155220779.png" alt="image-20220103155220779" /><figcaption aria-hidden="true">image-20220103155220779</figcaption>
</figure></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031552784.png" alt="image-20220103155237711" style="zoom:67%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031553033.png" alt="image-20220103155339977" style="zoom:67%;" /></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031553430.png" alt="image-20220103155353369" style="zoom:67%;" /></p></li>
</ul></li>
</ul>
<h3 id="chap.4">Chap.4</h3>
<h4 id="语法分析器">语法分析器</h4>
<ul>
<li>词法分析器输出的<strong>词法单元序列作为输入</strong>，输出<strong>语法树表示</strong>,<strong>用于验证输入源程序的合法性并输出良构程序的语法结构；对于病构的程序，能够报告语法错误</strong>，<strong>并进行错误回复</strong>
<ul>
<li>通用型 CKY</li>
<li><strong>top-down</strong> : 处理LL文法</li>
<li>bottom-up : 处理LR文法</li>
</ul></li>
</ul>
<h5 id="文法">文法</h5>
<ul>
<li><p>这里一般指<strong>上下文无关文法</strong> （Context Free Grammar, CFG）。</p>
<ul>
<li><p>由于程序设计语言中往往<strong>存在嵌套结构</strong>，因此，上下文无关文法是一种描述的好方式。</p></li>
<li><p>上下文无关文法由以下部分组成</p>
<ul>
<li><p>终结符号 : 小写字母或者类似id的形式</p></li>
<li><p>非终结符号 ： 大写字母</p></li>
<li><p>产生式 “→”,又称为<strong>重写规则</strong>，进行了一个<strong>推导</strong></p>
<ul>
<li><strong>产生式到终结符号</strong>的过程，表明了该<strong>终结符号是产生式的一个实例</strong>。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031652200.png" alt="image-20220103165244153" style="zoom:50%;" /> 表示<strong>零步或多步</strong>推导过程。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031653479.png" alt="image-20220103165343440" style="zoom:67%;" /> 表示<strong>一步或多步</strong>推导过程。</li>
</ul></li>
<li><p>开始符号 : <em>S</em></p>
<ul>
<li><p>如果从文法的开始符号S开始,经过<strong>零步或多步</strong>推导，得到<span class="math inline">\(\alpha\)</span>，那么就称<span class="math inline">\(\alpha\)</span>是文法G的一个<strong>句型</strong>。</p></li>
<li><p><strong>不包括非终结符号</strong>的句型就是句子。</p></li>
<li><p>语言，则是<strong>句子的集合</strong>,由文法<em>G</em>生成的语言(<strong>句子的集合</strong>)被称为<strong>上下文无关语言<em>L(G)</em></strong> 。换言之，语言是<strong>由文法的开始符号</strong>出发，能够推导得到的<strong>所有句子的集合</strong>。</p></li>
<li><p>两个文法<strong>生成相同语言</strong>，则两文法等价</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>从文法推导的角度理解:</p>
<ul>
<li>语法分析的任务是：<strong>接受一个终结符号串</strong>作为输入，找出<strong>从文法的开始符号推导出这个串</strong>的方法。
<ul>
<li>这样的推导方式也就是top-down的分析方式。</li>
</ul></li>
<li>推导中可能遇到的<strong>两个问题</strong>为:
<ul>
<li><strong>非终结符号的替换顺序</strong>是什么</li>
<li>若以这个非终结符号为头的<strong>产生式有多个</strong>，<strong>该用哪个产生式</strong>的右部替换</li>
</ul></li>
<li>一般的解决方式是<strong>最左推导</strong>或者<strong>最右推导</strong>。
<ul>
<li><strong>最左推导</strong>：总是选择每个句型的<strong>最左非终结</strong>符号，记为<span class="math inline">\(\rightarrow_{lm}\)</span></li>
<li><strong>最右推导</strong>：总是选择<strong>最右</strong>边的<strong>非终结</strong>符号，记为<span class="math inline">\(\rightarrow_{rm}\)</span></li>
</ul></li>
<li>通过<strong>最左推导</strong>生成的句型为<strong>最左句型</strong>。</li>
<li>可以将推导的过程表示成<strong>语法分析树</strong>的形式。</li>
</ul></li>
</ul>
<h5 id="与词法分析相比">与词法分析相比</h5>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031710192.png" alt="image-20220103171051108" style="zoom:67%;" /></li>
<li>正则表达式适合描述<strong>词法结构</strong>，文法适合描述<strong>嵌套结构</strong></li>
<li><strong>文法比正则表达式</strong>描述能力更<strong>强</strong>
<ul>
<li><strong>每个正则表达式</strong>都可以用一个<strong>上下文无关文法来描述</strong>，反之不成立</li>
</ul></li>
<li><strong>正则表达式</strong>描述词法单元比较<strong>简洁</strong>,基于正则表达式构造的词法分析器<strong>效率更高</strong></li>
</ul>
<h5 id="在语法分析之前">在语法分析之前</h5>
<ul>
<li><p>在进行高效的语法分析之前，需要对文法做以下处理:</p>
<ul>
<li><p><strong>消除二义性</strong>:</p>
<ul>
<li><p>二义性是一个文法可以生成多个语法分析树</p></li>
<li><p>消除二义性的方法有<strong>基于优先级</strong>消除二义性以及<strong>基于语义解释消除</strong>二义性。</p></li>
<li><p>注意的一点是<span class="math inline">\(\color{red}{后计算的产生式运算优先级更高}\)</span></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032126123.png" alt="image-20220103212645081" style="zoom:80%;" /></p></li>
<li><p>对于if-else，要明确地指出哪些句子是matched，哪些是open的，不然一定存在二义性。</p></li>
</ul></li>
<li><p><strong>消除左递归</strong>：</p>
<ul>
<li>原因在于<strong>自顶向下的语法分析技术</strong> <strong>不能处理</strong>左递归的文法:
<ul>
<li><strong>自顶向下的语法分析技术</strong>:从一个<strong>开始符号开始</strong>推导到<strong>最后的终结符号串</strong>。</li>
</ul></li>
<li>立即左递归： <span class="math inline">\(A\rightarrow A\alpha\)</span></li>
<li>左递归则是<span class="math inline">\(A\)</span>通过一步或者多步推导生成了<span class="math inline">\(A\alpha\)</span>。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031828634.png" alt="image-20220103182846560" style="zoom: 50%;" /></li>
<li>对于非立即左递归的左递归消除算法：
<ul>
<li>对所有的非终结符号<strong>按照产生顺序</strong>进行排序<span class="math inline">\(A_1,A_2,...,A_n\)</span></li>
</ul></li>
<li>对于<span class="math inline">\(A_i-&gt;A_j\)</span>,<span class="math inline">\(j&gt;i\)</span>,那么不会出现左递归的情况
<ul>
<li>反之，如果<span class="math inline">\(A_i-&gt;A_k\)</span>,<span class="math inline">\(k&lt;i\)</span>,就将<span class="math inline">\(A_k\)</span>按照产生式不断展开，那么就可以化成<span class="math inline">\(A_i-&gt;A_j\)</span>,<span class="math inline">\(j&gt;i\)</span>的情况。</li>
</ul></li>
<li>之后，按照消除立即左递归的思路处理一遍就可以。</li>
</ul></li>
</ul></li>
<li><p>提取左公因子</p>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031852496.png" alt="image-20220103185218444" style="zoom:80%;" /></p>
<ul>
<li><p>对于每个非终结符号<em>A</em>，找出它的两个或多个可选项之间的最长公共前缀<em>α</em>，且<em>α<strong>≠</strong>ε</em> ,之后进行下述展开</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031854120.png" alt="image-20220103185420057" style="zoom:67%;" /></p></li>
</ul></li>
</ul></li>
</ul>
<h4 id="自顶向下分析">自顶向下分析</h4>
<ul>
<li><p><strong>自顶向下分析</strong>可以被看作是<strong>为输入串构造语法分析树</strong>的问题,也可以看作一个<strong>寻找输入串的最左推导</strong>的过程,从一个<strong>开始符号开始</strong>推导到<strong>最后的终结符号串</strong>。</p></li>
<li><p>自顶向下分析的伪代码描述（或者说是<strong>递归下降</strong>）：</p>
<ul>
<li><p><strong>通用的递归下降分析</strong>框架:</p>
<ul>
<li>由<strong>一组过程</strong>组成，每个非终结符号对应一个过程。选择一个产生式体，<strong>扫描相应的句子</strong>。若遇到<strong>非终结符号</strong>，<strong>调用该符号对应的过程</strong>。</li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031900580.png" alt="image-20220103190040522" style="zoom:80%;" /></p></li>
<li><p>简单来说就是<strong>不断展开非终结符号</strong>,<strong>读入下一个输入符号</strong>，直到遇到输入符号<span class="math inline">\(a\)</span> 。</p>
<ul>
<li>读入输入符号a,a是<strong>不会重复读入</strong>的。</li>
</ul></li>
<li><p>但是对于<strong>有多个产生式的非终结符号</strong>，上述的伪代码<strong>无法有效处理</strong>选择问题。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031903975.png" alt="image-20220103190327898" style="zoom:80%;" /></p></li>
<li><p>为了处理这个问题，就需要<strong>预测分析技术</strong>:</p>
<ul>
<li>通过在输入中<strong>向前看固定多个符号</strong>来选择正确的产生式,通常情况下，我们<strong>只需要向前看一个符号</strong>:</li>
<li>与文法相关的两个函数:
<ul>
<li>FIRST<span class="math inline">\((\alpha)\)</span> : 可从<strong>α推导得到的串的首符号</strong>的集合,<strong>可以包含<span class="math inline">\(\epsilon\)</span></strong> ,主要作用于<strong>分支选取</strong>。
<ul>
<li>如果X是<strong>终结符号</strong>，那么FIRST(X)={X}</li>
<li>如果X是<strong>非终结符号</strong>，且有规则X <em>→</em> a…,那么将a添加到FIRST(X)中。</li>
<li>如果X <em>→</em> ε，那么ε也在FIRST(X)中。</li>
<li>对于产生式X<em>→</em> Y1Y2…Yn,把FIRST(Y1)中的非ε符号添加到FIRST(X)中。如果<strong>ε在FIRST(Y1)中</strong>，把<strong>FIRST(Y2)中的非ε符号</strong>添加到<strong>FIRST(X)</strong>中;如果ε在FIRST(Y1),FIRST(Y2)中,把FIRST(Y3)中的非ε符号添加到FIRST(X)中，<strong>以此类推</strong>，如果ε在FIRST(Y1),FIRST(Y2),...,FIRST(Yn)中，把ε添加到FIRST(X)中。
<ul>
<li><strong>ε在FIRST(Y1)中,说明X <em>→</em> ε</strong></li>
</ul></li>
<li>特别的，例如，对于两个非终结符号串<span class="math inline">\(E-&gt;TAFA\)</span>,<span class="math inline">\(FIRST(E) = FIRST(TAFA) = FIRST(T)\)</span><br />
</li>
</ul></li>
<li>FOLLOW(A):
<ul>
<li>对于非终结符号<em>A</em>，FOLLOW(<em>A</em>)定义为可能在某些句型中<strong>紧跟在<em>A</em>右边的终结符号</strong>的集合。</li>
<li>如果A是某些句型的最右符号，那么<span class="math inline">\(\$ ∈Follow(A)\)</span> $是特殊的输入串“结束标记”</li>
<li>计算规则:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031922613.png" alt="image-20220103192253522" style="zoom:80%;" /></li>
<li>对于E-&gt;TG, <strong>FOLLOW(T) = FIRST(G) <span class="math inline">\(\cup\)</span> FOLLOW(G)</strong>
<ul>
<li>一般计算FOLLOW(A)需要<strong>找A所在的产生式的体</strong>。</li>
<li>如果<strong>FIRST(A)含有</strong><span class="math inline">\(\epsilon\)</span>,就找产生式的头E的FOLLOW(E)</li>
<li>对于<strong>处于产生式的体中间</strong>的非终结符号，需要按FIRST(G) <span class="math inline">\(\cup\)</span> FOLLOW(G)的公式计算。</li>
<li>一般不计入<span class="math inline">\(\epsilon\)</span></li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201031930449.png" alt="image-20220103193036384" style="zoom:80%;" /></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h4 id="ll1文法">LL(1)文法</h4>
<ul>
<li><p>如果对于文法G的任意两个不同的产生式<span class="math inline">\(A\rightarrow \alpha|\beta\)</span> :</p>
<ul>
<li><span class="math inline">\(FIRST(\alpha)\cap FIRST(\beta) = \emptyset\)</span>
<ul>
<li>向前看一个输入符号选择产生式的需要。</li>
</ul></li>
<li><span class="math inline">\(\alpha \rightarrow^* \epsilon,\beta\rightarrow^* \epsilon\)</span>不能同时成立</li>
<li>如果<span class="math inline">\(\beta\rightarrow^* \epsilon\)</span>,那么<span class="math inline">\(FIRST(\alpha)\cap FOLLOW(A) = \emptyset\)</span></li>
</ul>
<p>就称该文法为LL(1)文法。</p>
<p><strong>第一个L</strong>表示<strong>自左向右扫描</strong>，<strong>第二个L</strong>指<strong>产生最左推导</strong>，而1则表示<strong>向前看一个输入符号</strong>。<span class="math inline">\(\color{red}{Key}\)</span></p></li>
<li><p><strong>LL(1)文法+无左递归可以使用</strong>上述预测分析技术,并将first和follow集合中的信息放入一个预测分析表M[A,a]，该预测表告诉我们<strong>当非终结符号为A，当前输入符号为a时，要选择哪条产生式。</strong></p>
<ul>
<li><strong>无左递归、无二义性</strong>才能用<strong>自顶向下的语法分析</strong></li>
</ul></li>
<li><p><strong>构造预测分析表</strong>:</p>
<ul>
<li>对于文法<em>G</em>的每个产生式<em>A</em> <em>→</em> <em>α</em> ：
<ul>
<li>对于First(<em>α</em>)中的<strong>每个终结符号</strong>a，将<em>A</em> <em>→</em> <em>α</em>加入到<em>M[<strong>A,a</strong>]</em></li>
<li>如果ε在First<em>(<strong>α</strong>)</em>中，那么对于Follow(A)中的<strong>每个终结符号</strong>b，将<em>A</em> <em>→</em> <em>α</em>加入到<em>M[<strong>A,b</strong>]</em>中</li>
<li>如果ε在First<em>(<strong>α</strong>)</em>中，且$在Follow(A)中，将<em>A</em> <em>→</em> <em>α</em>加入到<em>M[A,$]</em>中</li>
<li><span class="math inline">\(\color{red}{换言之}\)</span>,将<em>A</em> <em>→</em> <em>α</em>加入到M[A,First(α)]中；对于可以推导出<span class="math inline">\(\epsilon\)</span>的产生式<em>A</em> <em>→</em> <em>α</em>，将<em>A</em> <em>→</em> <em>α</em>加入到M[A,Follow(A)]中。<span class="math inline">\(\color{red}{Key}\)</span> <span class="math inline">\(\color{red}{一般后一种情况的产生式为A\rightarrow\epsilon}\)</span>
<ul>
<li><strong>对于产生式A -&gt; a，如果FIRST(a)不含ε，则在所有的(A,FIRST(a))处写上这条产生式；如果含ε，还要在(A,FOLLOW(A))处补上这条产生式。</strong></li>
</ul></li>
</ul></li>
<li>若<em>M[<strong>A,a</strong>]</em>中没有产生式，填为error</li>
</ul></li>
<li><p>尽管<strong>所有文法都可以构造</strong>预测分析表，但是无法保证像<strong>LL(1)文法</strong>一样表达式选择是<strong>唯一</strong>的</p></li>
<li><p>LL(1)与递归下降：</p>
<ul>
<li>对于<strong>LL(1)文法</strong>，如何改造递归下降程序，使之能够避免回溯?</li>
<li>一般的递归下降算法为
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032123696.png" alt="image-20220103212344641" style="zoom:80%;" /></li>
<li>这里的关键点在于<span class="math inline">\(\color{red}{读入一个输入符号之后，即使发生错误，也不会回退，因此，作业题中不能识别aaaaaa}\)</span></li>
</ul></li>
</ul></li>
<li><p>预测分析的示例:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032002078.png" alt="image-20220103200214969" style="zoom:80%;" /></p>
<p>步骤大概就是:</p>
<ul>
<li>消除左递归、二义性、提取左公因子</li>
<li>生成FIRST，FOLLOW</li>
<li>生成预测分析表</li>
<li>画出类似上图的栈结构</li>
</ul></li>
</ul>
<h4 id="自底向上分析">自底向上分析</h4>
<ul>
<li>自底向上语法分析过程对应于<strong>为一个输入串构造语法分析树</strong>的过程,也是将一个串<em>w</em><strong>归约</strong>为<strong>文法符号S</strong>的过程,也是<strong>反向最右推导</strong>过程，也是<strong>句柄</strong>剪枝过程。从叶子节点（底部）开始逐渐向上到达根节点（顶部）。<strong>归约</strong>可以看成<strong>推导的逆过程</strong>。问题在于:
<ul>
<li>什么时候规约</li>
<li>选择哪一个产生式</li>
</ul></li>
<li>句柄：<strong>和某个产生式体相匹配</strong>的<strong>子串</strong>，<strong>对它的归约</strong>代表了<strong>相应的最右推导</strong>的一个<strong>反向</strong>步骤。要<strong>从最右句型的<span class="math inline">\(\color{red}{最左边}\)</span></strong>开始找。<span class="math inline">\(\color{red}{Key}\)</span>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032009531.png" alt="image-20220103200937478" style="zoom:80%;" /></li>
</ul></li>
<li>问题就被转变为如何去寻找句柄。</li>
</ul>
<h5 id="移进归约语法分析框架">移进归约语法分析框架</h5>
<ul>
<li><p>有四种动作：</p>
<ul>
<li>移进：将输入的一个符号移入栈
<ul>
<li>初始栈只含$</li>
</ul></li>
<li>规约：对栈中符号按照产生式规约
<ul>
<li>这样，移进规约的过程就与寻找句柄的过程<strong>相通</strong>了。</li>
</ul></li>
<li>接受: 最终栈为$S ,S 为开始符号</li>
<li>报错</li>
</ul></li>
<li><p><span class="math inline">\(\color{red}{说明相应的自底向上语法分析过程，只需要给出移进规约的表即可}\)</span></p></li>
<li><p>无法处理部分文法，比如二义性文法,会产生冲突。</p></li>
<li><p>为了解决这种冲突，我们需要使用<strong>LR语法分析技术（SLR分析）</strong>。</p>
<ul>
<li><p>如果能够用某个方法<strong>为一个文法构造出移进-归约语法分析表</strong>，那么就称为LR文法</p>
<ul>
<li>LR(k)分析:
<ul>
<li>L : 从左往右扫描输入</li>
<li>R: <strong>反向构造</strong>一个最右推导序列</li>
<li>k: 向前看k个符号</li>
</ul></li>
</ul></li>
<li><p>定义LR(0)项(item)：一个文法G的一个LR(0)项是G的<strong>一个产生式</strong>再<strong>加上一个位于它的体中某处的点</strong>。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032022932.png" alt="image-20220103202230887" style="zoom:80%;" /></p></li>
<li><p>项的集合（项集）<strong>对应于一个状态</strong></p></li>
<li><p>定义增广文法:</p>
<ul>
<li>在文法<em>G</em>上增加一个产生式<em>S’</em> →<em>S</em></li>
<li>目的是告诉语法分析器<strong>何时宣布接受输入符号串</strong>。<strong>即用<em>S’</em> →<em>S</em>进行归约时，表明分析结束</strong> <span class="math inline">\(\color{red}{Key}\)</span></li>
</ul></li>
<li><p>定义项集闭包:</p>
<ul>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032026165.png" alt="image-20220103202629055" /><figcaption aria-hidden="true">image-20220103202629055</figcaption>
</figure></li>
<li><p>简单来说就是，对于I中的每一个项，如果<strong><span class="math inline">\(\cdot\)</span>点后面的第一个非终结符号</strong>，<strong>有对应的产生式</strong>在文法G中，且<strong>开头加点<span class="math inline">\(\cdot\)</span>的形式未收纳在I中</strong>，就<strong>加入</strong>；然后，<strong>重复</strong>此过程。<span class="math inline">\(\color{red}{Key}\)</span></p>
<p><span class="math inline">\(\color{blue}{例子}\)</span>： 一个SLR/LR(0)自动机</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032128051.png" alt="image-20220103212857974" style="zoom:80%;" /></p></li>
</ul></li>
<li><p>定义GOTO函数：</p>
<ul>
<li><p>GOTO(<em>I,X</em>)定义: <em>I</em>中所有形如[<em>A →</em> <em>α·<strong>X</strong>β</em>]的项所对应的项[<em>A →</em> <em>α<strong>X</strong>·β</em>]的集合的闭包。</p>
<ul>
<li><p>简单来说就是，把点在X位置推进一个位置，重复闭包运算之后<strong>将得到的状态返回</strong>。<span class="math inline">\(\color{red}{Key}\)</span></p>
<p><span class="math inline">\(\color{blue}{继承上方例子}\)</span>:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032131430.png" alt="image-20220103213100365" style="zoom:80%;" /></p></li>
</ul></li>
</ul></li>
<li><p>LR(0)项集规范族的构造：</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032033980.png" alt="image-20220103203317909" style="zoom:80%;" /></li>
<li>规范LR(0)项集族中的<strong>一个项集</strong>对应于<strong>LR(0)自动机中的一个状态</strong>。
<ul>
<li>也就是例子中的<span class="math inline">\(I_i\)</span></li>
</ul></li>
</ul></li>
<li><p>GOTO函数则<strong>定义了LR(0)自动机中的状态转换</strong>。GOTO(<em>I,X</em>)描述了当输入为<em>X</em>时离开状态<em>I</em>的转换。</p></li>
</ul></li>
<li><p>假设文法符号串γ使LR(0)自动机从开始状态0运行到某个状态<em>j</em>，LR(0)自动机按照如下方式决定移入或归约：</p>
<pre><code>  + 如果下一个输入符号为*a*，且*j*上有*a*的转换，就移入*a*
  + 否则就**对状态*j*中的项中点在最后的**产生进行归约(也就是说，状态*j*中的项会告诉我们使用那个产生式进行归约),规约会**退出原状态**,**回到上一个状态**。
  + &lt;img src=&quot;https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032039537.png&quot; alt=&quot;image-20220103203921446&quot; style=&quot;zoom:80%;&quot; /&gt; </code></pre>
<ul>
<li>以上图来说，移入id,转移到状态<span class="math inline">\(I_5\)</span>,<span class="math inline">\(I_5\)</span><strong>没有下一个输入<span class="math inline">\(*\)</span>的转移函数</strong>,而<span class="math inline">\(I_5\)</span>中<strong>有产生式</strong><span class="math inline">\(F\rightarrow id\cdot\)</span>,启示我们要<strong>按照该产生式规约</strong>，规约之后，相当于在<span class="math inline">\(I_0\)</span>状态移入<span class="math inline">\(F\)</span>,因此到达<span class="math inline">\(I_3\)</span>状态。之后，同理。</li>
</ul></li>
<li><p>LR语法分析表/SLR的语法分析表:</p>
<ul>
<li><p>包括<strong>ACTION和GOTO</strong>两个部分</p>
<ul>
<li><p>分为FOLLOW(S)的终结符号以及非终结符号两部分。</p></li>
<li><p>将LR(0)自动机的状态以及状态转移画成表的形式,画出上图例子的图之后即可。</p></li>
<li><p>因此，构造LR语法分析表/SLR的语法分析表与构造LR(0)自动机<strong>等价</strong>。</p></li>
<li><p>具体的构造算法:</p>
<ul>
<li><p>构造文法G的LR(0)项集规范族<em>C</em></p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032100805.png" alt="image-20220103210052710" /><figcaption aria-hidden="true">image-20220103210052710</figcaption>
</figure></li>
<li><p><strong>简单来说</strong>，对于状态i中的<strong>位于<span class="math inline">\(\cdot\)</span>后的所有终结符号</strong>，将移入终结符号后<strong>抵达的状态</strong>移入表;对于<span class="math inline">\(\cdot\)</span>位于产生式A-&gt;..<strong>最后</strong>的情况，需要对<strong>FOLLOW(A)中的所有终结符号</strong>用<strong>该产生式</strong>进行规约;对于非终结符号，将GOTO(i,A)后的状态j填入。</p></li>
<li><p>规约的式子用<span class="math inline">\(r_i\)</span>表示。终结符号转移之后的状态用<span class="math inline">\(s_i\)</span>表示。</p>
<p><span class="math inline">\(\color{blue}{继承上方例子}\)</span>:</p>
<pre><code>  &lt;img src=&quot;https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032132601.png&quot; alt=&quot;image-20220103213250531&quot; style=&quot;zoom:80%;&quot; /&gt; </code></pre></li>
</ul></li>
<li><p>在分析过程中的<strong>中间分析状态</strong>，称为<strong>格局</strong>。</p></li>
<li><p>若<strong>SLR的语法分析表中</strong>各位置<strong>没有多个条目</strong>，则称为<strong>文法<em>G</em>的SLR(1)分析表</strong>。使用该分析表的分析器，称为<strong>G的SLR(1)语法分析器</strong>。G称为<strong>SLR(1)文法</strong> 。</p>
<ul>
<li>换句话说，没有二义性。</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h4 id="二义性文法的分析">二义性文法的分析</h4>
<ul>
<li>二义性文法都不是LR的,可以在LR分析器中实现消除二义性规则
<ul>
<li>基于优先级，**+时规约，*移入**</li>
<li>基于语义解释，i E t S,遇到else,<strong>要选择移入</strong>。</li>
</ul></li>
<li>二义性文法却有其存在的必要
<ul>
<li>二义性文法<strong>容易修改</strong>算符的<strong>优先级和结合性</strong>,<strong>简洁,高效</strong></li>
</ul></li>
</ul>
<h4 id="解题框架">解题框架</h4>
<ul>
<li>增广文法</li>
<li>LR(0)项集族</li>
<li>GOTO</li>
<li>FOLLOW</li>
<li>语法分析表</li>
<li>移进规约分析</li>
</ul>
<h3 id="chap.5">Chap.5</h3>
<h4 id="语义分析">语义分析</h4>
<ul>
<li>上下文无关文法无法解决语义分析的原因在于<span class="math inline">\(\color{red}{标示符在程序中先声明后使用}\)</span>等现象与上下文有关。</li>
</ul>
<h5 id="语法制导sdd">语法制导(SDD)</h5>
<ul>
<li><p>语法制导是在产生式的基础上<strong>附加语义规则</strong>，可以<strong>用于类型检查</strong>和<strong>中间代码</strong> 的翻译</p>
<ul>
<li>语音规则描述文法符号的<strong>属性值</strong>。</li>
<li><strong>上下文无关文法</strong>和<strong>属性及规则</strong>的结合</li>
<li><strong>属性和文法符号</strong>相关联</li>
<li><strong>语义规则和产生式</strong>相关联</li>
</ul></li>
<li><p>语法制导是<strong>上下文无关文法</strong>和<strong>属性及规则</strong>的结合。</p></li>
<li><p>属性包含了<strong>综合属性</strong>以及<strong>继承属性</strong>。</p>
<ul>
<li>区分，对于语法分析树
<ul>
<li><strong>综合属性</strong>是由<strong>结点本身</strong>以及<strong>子节点</strong>定义的。也就是<strong>从产生式的体传到头</strong>的属性。</li>
<li><strong>继承属性</strong>是由<strong>结点本身</strong>、<strong>父节点、左兄弟节点</strong>定义的。也就是<strong>从产生式的头传到体</strong>的属性。</li>
</ul></li>
</ul></li>
<li><p>给出翻译的<strong>抽象</strong>描述</p>
<p><strong>隐藏</strong>了语义动作的<strong>实现细节</strong></p>
<p>附在产生式上的语义规则<strong>没有明确告诉我们何时</strong>执行其中的语义动作</p></li>
</ul>
<h6 id="s属性的sdd">S属性的SDD</h6>
<ul>
<li><strong>只包含综合属性</strong>的SDD称为S属性的SDD 。</li>
</ul>
<h5 id="l属性的sdd">L属性的SDD</h5>
<ul>
<li>一个SDD称为L属性定义，对于一个产生式<em>A→X<strong>1</strong>X<strong>2</strong>…<strong>X</strong>n</em>所关联的语义规则<em>，</em>其中的每个属性：
<ul>
<li>要么是综合属性
<ul>
<li>因此<strong>S属性的SDD一定是L属性的SDD</strong></li>
</ul></li>
<li>要么<span class="math inline">\(X_i.a\)</span>这一个继承属性依赖于<span class="math inline">\(X_i\)</span>左边的非终结符号
<ul>
<li>(也就是<strong>左兄弟结点</strong>)</li>
</ul></li>
<li>依赖图没有环</li>
</ul></li>
<li>S属性的SDD 以及 L属性的SDD都<strong>一定有已知的属性求值顺序</strong>。</li>
<li>对于<strong>S属性</strong>的SDD,计算属性的过程只需要<strong>bottom-up、后根遍历</strong>(left,right,root)就可以了。</li>
<li>对于<strong>L属性</strong>的SDD,计算属性的过程只需要<strong>top-down、前根遍历</strong>(root,left,right)就可以了。在<strong>遍历一层</strong>的<strong>所有结点</strong>，计算<strong>继承属性</strong>，之后，计算<strong>当前结点的综合属性</strong>。
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041046430.png" alt="image-20220104104620264" style="zoom:80%;" /></li>
</ul></li>
</ul>
<h5 id="sdd中的副作用函数">SDD中的副作用（函数）</h5>
<ul>
<li>一个<strong>没有副作用</strong>（<strong>函数</strong>）的SDD有时候也称为<strong>属性文法</strong></li>
<li>翻译过程有时候需要副作用
<ul>
<li>打印结果(print)</li>
<li>符号表中加入标识符类型(addType)</li>
</ul></li>
</ul>
<h5 id="注释语法分析树">注释语法分析树</h5>
<ul>
<li><p>基于语法分析树，可以<strong>通过语义规则</strong>对语法分析树上的各个结点的<strong>所有属性进行求值</strong>。</p>
<p><strong>显示了它的各个属性的值</strong>的语法分析树称为<strong>注释语法分析树</strong> 。</p></li>
<li><p>对<strong>存在继承属性</strong>的语法分析树进行注释(属性求值)的时候，需要根据<strong>依赖图</strong>求解。</p>
<ul>
<li>并且继承属性与综合属性可能因为<strong>循环定义</strong>无法求解属性值。</li>
</ul></li>
</ul>
<h6 id="依赖图">依赖图</h6>
<ul>
<li><p>依赖图的<strong>结点</strong>为语法分析树每个节点的<strong>每个属性</strong></p></li>
<li><p>依赖图的<strong>边</strong>表示求值的依赖关系,具体的说就是<strong>值传递的关系</strong>，例如<span class="math inline">\(a=b\)</span>,那么b到a有一条<strong>有向边</strong>（指向a）,表示<strong>值从b传到a</strong>。</p>
<ul>
<li><p><span class="math inline">\(\color{green}{Example}\)</span>:</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201032215977.png" alt="image-20220103221543906" style="zoom:80%;" /></p></li>
</ul></li>
<li><p>之后借助<strong>拓扑排序</strong>就可以解出属性求值顺序。</p>
<ul>
<li>拓扑排序的意思是对于有向边<span class="math inline">\(b-&gt;a\)</span>,那么排序的时候<strong>b排在a前面</strong>,因为<strong>b的值要传给a</strong>。</li>
<li><strong>存在环</strong>，则<strong>不存在拓扑排序</strong>,也就可以判断时候<strong>有循环定义</strong>。</li>
</ul></li>
</ul>
<h5 id="语法制导的翻译">语法制导的翻译</h5>
<ul>
<li><p>语法制导的翻译应用——抽象语法树：</p>
<ul>
<li><strong>抽象语法树</strong>是一种<strong>中间表示形式</strong>,树中每个结点代表一个程序构造，这个结点的子结点代表这个构造的有意义的组成部分。</li>
<li>借助抽象语法树可以较容易地完成到中间代码的翻译</li>
<li>各个结点用字段的记录对象来实现:
<ul>
<li>内部结点:构造函数<strong>Node(op, c1,c2,…ck)</strong>,op一般表示一种运算
<ul>
<li>创建新的结点或者属性</li>
</ul></li>
<li>叶子结点（<strong>最外层的结点</strong>）:构造函数<strong>Leaf(id, id.entry)</strong>
<ul>
<li>创建新的结点，并给这个结点一个属性id.entry</li>
</ul></li>
</ul></li>
<li>在<strong>自底向上分析过程</strong>中和<strong>归约动作一起进行求值</strong>。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041101645.png" alt="image-20220104110108570" style="zoom:80%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052030526.png" alt="image-20220105203028434" style="zoom:80%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041102112.png" alt="image-20220104110223040" style="zoom:80%;" /></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052033953.png" alt="image-20220105203327879" style="zoom:80%;" /></li>
</ul></li>
<li><p>描述类型的结构，例如数组:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052040370.png" alt="image-20220105204048294" style="zoom:80%;" />
<ul>
<li>C为数组类型，B为基本类型。<strong>C.b表示数组的每个元素的type,C.t表示数组的type</strong></li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041103047.png" alt="image-20220104110351968" style="zoom:80%;" /></li>
</ul></li>
</ul>
<h5 id="语法制导的翻译方案sdt">语法制导的翻译方案（SDT）</h5>
<ul>
<li><p>语法制导的翻译方案是指在产生式中<strong>附加动作</strong></p></li>
<li><p>产生式体中<strong>嵌入</strong>程序片段的<strong>上下文无关文法</strong></p></li>
<li><p>程序片段是<strong>语义动作</strong>，可以出现在体中的<strong>任何位置</strong></p></li>
<li><p>告诉我们<strong>何时</strong>执行相应的语义动作,翻译方案给出了更多的<strong>实现细节信息</strong></p></li>
<li><p>对<strong>S属性的SDD</strong>，可以构造一个SDT:</p>
<ul>
<li>每个动作都放在产生式的<strong>最后</strong></li>
<li>在利用这个产生式进行<strong>规约时执行这个动作</strong></li>
</ul>
<p>这样的SDT称为<strong>后缀翻译方案</strong></p></li>
<li><p>为了利用<strong>自顶向下技术</strong>进行<strong>语法分析</strong>，需要从SDT中<strong>消除左递归</strong></p>
<ul>
<li>对于执行print等副作用的动作，可以<strong>直接把动作当作终结符号</strong>处理。</li>
<li>当出现下图的类似综合属性的情况，就需要<strong>额外</strong>对非终结符号的<strong>属性进行改写</strong>。
<ul>
<li>框架不变，只不过加上了动作。</li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041206911.png" alt="image-20220104120626803" style="zoom:67%;" /></li>
</ul></li>
</ul>
<h3 id="chap.6">Chap.6</h3>
<h4 id="中间代码生成">中间代码生成</h4>
<ul>
<li>中间代码的表示形式有<strong>抽象语法树</strong>、<strong>三地址代码</strong>。
<ul>
<li><p>中间代码表示有利于进行<strong>高层次的优化</strong>（与<strong>源语言、目标机器</strong>无关）</p></li>
<li><p>并且为<strong>新的机器建编译器</strong>，<strong>只需要</strong>做从中间代码到新的目标代码的<strong>翻译器</strong>（<strong>前端独立</strong>）</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052118843.png" alt="image-20220105211800748" style="zoom:80%;" /></p></li>
<li><p><strong>静态类型检查</strong>和<strong>中间代码生成</strong>的过程都可以用<strong>语法制导的翻译(放在语义规则中完成)</strong>来描述和实现</p></li>
</ul></li>
</ul>
<h5 id="表达式的dag">表达式的DAG</h5>
<ul>
<li>在函数<strong>Leaf和Node</strong>每次被调用时，<strong>构造新节点前先检查</strong>是否已存在同样的节点，如果已经存在，则<strong>返回这个已有的节点</strong>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041238783.png" alt="image-20220104123815715" style="zoom:67%;" /></li>
</ul></li>
</ul>
<h5 id="三地址代码">三地址代码</h5>
<ul>
<li><p>三地址代码是抽象语法树或DAG的线性表示形式</p></li>
<li><p>一条指令右侧<strong>最多有一个运算符</strong></p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041239083.png" alt="image-20220104123939019" style="zoom:67%;" /></p></li>
<li><p>三地址代码有以下指令形式，包括了<strong>各种条件转移指令、调用、返回</strong>等。每次<strong>只能用一个指令</strong>。</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041244243.png" alt="image-20220104124403164" style="zoom:67%;" /></p></li>
<li><p>数组取项的时候，需要乘以8.</p>
<p>x[i]=y. i = 8*index</p></li>
</ul>
<h5 id="类型">类型</h5>
<ul>
<li><p>类型检查。比如检查&amp;&amp;左右都是boolean类型。</p></li>
<li><p>声明的文法：</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041403079.png" title="fig:" alt="image-20220104140313021" /></li>
</ul></li>
<li><p>即声明一个<strong>基本类型、数组类型</strong>或者<strong>记录</strong></p></li>
<li><p>对于特别的数组类型，array(num,type)也是一个类型表达式。</p></li>
<li><p>用类型表达式进行类型声明，除了<strong>类型声明</strong>之外，还要进行<strong>类型的存储布局</strong>。</p>
<ul>
<li>约定<strong>字节</strong>是可寻址的<strong>最小内存单位</strong></li>
<li>一个字节通常是一个<strong>8个二进制位</strong></li>
<li><strong>类型的宽度</strong>表示<strong>一个对象所需的存储单元的数量</strong>
<ul>
<li>一个整型数的宽度是4个字节。一个浮点数的宽度是8个字节。</li>
<li>注意通常内存都会进行<strong>对齐</strong>。</li>
<li>计算类型以及宽度的SDT:
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041404200.png" alt="image-20220104140433130" style="zoom:67%;" />
<ul>
<li>当推导没有进行到C-&gt;<span class="math inline">\(\epsilon\)</span>的时候，<strong>默认T的宽度类型按照C</strong>来。</li>
<li>因此，需要额外记录<strong>基本类型B的宽度以及类型</strong>。</li>
</ul></li>
<li>例子为下方对int[2][3]的翻译过程
<ul>
<li>要注意的就是<span class="math inline">\(\color{red}{T-&gt;B C,C-&gt;\epsilon}\)</span>的额外动作</li>
</ul></li>
</ul></li>
</ul></li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052119444.png" alt="image-20220105211922374" style="zoom:80%;" /></li>
</ul></li>
</ul>
<h5 id="表达式翻译为三地址代码">表达式翻译为三地址代码</h5>
<ul>
<li><p><strong>表达式翻译为三地址代码</strong>的SDD:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041421909.png" alt="image-20220104142135827" style="zoom:80%;" /></li>
<li>addr属性表示值的地址，code表示三地址代码
<ul>
<li>addr需要在注释语法分析树中画出。</li>
</ul></li>
</ul></li>
<li><p>数组类型的语法制导翻译:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041318730.png" alt="image-20220104131845623" style="zoom:80%;" /></li>
</ul></li>
<li><p>数组元素的寻址:</p>
<ul>
<li>数组a[i1][i2]...[ik]的第一个元素的<strong>相对位置</strong>记为base,之后按照<em>base+i<strong>1</strong></em>w<strong>1</strong>+i<strong>2</strong><em>w<strong>2</strong>+…+<strong>i</strong>k</em><strong>w</strong>k计算地址。上述地址的计算是<strong>按行存放</strong>的。
<ul>
<li>无论是按列存放还是按照行存放，表示都不会变，a[i][j]仍然是a[i][j]
<ul>
<li><strong>列存放的次序</strong>: a[i][j]-&gt;a[i+1][j], 无论是几维，都<strong>从高开始堆</strong></li>
<li><strong>行存放的次序</strong>: a[i][j]-&gt;a[i][j+1], 无论是几维，都<strong>从低开始堆</strong></li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>数组引用</strong>生成代码的<strong>翻译方案</strong>：</p>
<ul>
<li><p>非终结符号L的三个综合属性</p>
<p>L.addr指示一个临时变量。计算<strong>数组引用的偏移量</strong></p>
<p>L.array是一个<strong>指向数组名字对应的符号表条目的指针</strong>。L.array.base为该数组的基地址。</p>
<p>L.type是<strong>L生成的子数组的类型</strong>。对于任何数组类型t，其宽度由t.width给出。t.elem给出其数组元素的类型。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201052135266.png" alt="image-20220105213525186" style="zoom:80%;" /></p></li>
</ul></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041335914.png" alt="image-20220104133535820" style="zoom:80%;" /></p></li>
</ul>
<h5 id="记录与字段">记录与字段</h5>
<ul>
<li>一个记录中各字段名称需要不同，但是不同记录可以相同。</li>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041418346.png" alt="image-20220104141847287" style="zoom:80%;" /></li>
<li>记录本身处于原始符号表。Env.push(top)</li>
<li>每个记录都会使用一个新的符号表 。 top = new Env()</li>
<li>在新环境中，每个字段声明重新从0开始算。</li>
</ul>
<h5 id="控制流语句的翻译">控制流语句的翻译</h5>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041343123.png" alt="image-20220104134300976" style="zoom:80%;" /></p></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041345828.png" alt="image-20220104134506763" /><figcaption aria-hidden="true">image-20220104134506763</figcaption>
</figure></li>
<li><figure>
<img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041345148.png" alt="image-20220104134552075" /><figcaption aria-hidden="true">image-20220104134552075</figcaption>
</figure>
<ul>
<li>一开始，我们<strong>只有S.code以及S.next两个属性值</strong>，因此跳转<strong>除非是跳到S.next</strong>,<strong>不然都要生成label</strong>。</li>
</ul></li>
</ul>
<h5 id="避免冗杂的goto语句">避免冗杂的goto语句</h5>
<ul>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041346087.png" alt="image-20220104134658011" style="zoom:80%;" /></p>
<p>goto L3是冗杂的。</p>
<p>可以通过用ifFalse等价替换if，来避免不必要的goto语句</p></li>
<li><p>同时在SDD中引入一个<strong>特殊标号“fall”</strong>(穿越，fall through)，表示<strong>不要生成任何跳转指令</strong>,<strong>直接顺序执行下一条语句</strong>。</p></li>
<li><p>注意<strong>部分fall的时候还要生成一个newlabel</strong>，指向跳转的位置才行。</p></li>
</ul>
<h5 id="回填colorblue上课略过">回填(<span class="math inline">\(\color{blue}{上课略过}\)</span>)</h5>
<ul>
<li>除了使用S.next这一个<strong>继承属性描述跳转位置</strong>之外，利用<strong>回填</strong>的技术只进行<strong>一趟</strong>处理。
<ul>
<li>生成跳转指令时<strong>暂时不指定该跳转指令的目标</strong>。等到<strong>能够确定正确的目标标号</strong>时<strong>再去填充</strong>这些指令的目标位置。</li>
<li>需要回填的指令将被<strong>放在一个列表</strong>中</li>
</ul></li>
</ul>
<h3 id="chap.7">Chap.7</h3>
<h4 id="运行时刻的环境">运行时刻的环境</h4>
<ul>
<li>产生目标代码后，将于操作系统协作，在<strong>目标机器上执行代码</strong>,由<strong>编译器创建</strong>并管理<strong>运行时刻环境</strong></li>
<li>编译系统给程序里的对象<strong>分配空间</strong>，包括代码，静态和动态数据，全局和局部数据等</li>
</ul>
<h5 id="存储管理">存储管理</h5>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041436672.png" alt="image-20220104143643611" style="zoom:67%;" />
<ul>
<li>代码区主要用于<strong>放置可执行目标代码</strong>，在<strong>编译时刻</strong>就可以<strong>确定大小</strong>，通常<strong>在存储的低地址端</strong>。</li>
<li>静态区存放<strong>全局常量</strong>和<strong>编译器产生</strong>的某些数据</li>
<li>剩余的动态区域由<strong>堆区、栈区</strong>分配，位于<strong>在剩余地址空间的两端</strong>。
<ul>
<li><strong>堆区、栈区</strong>的生长方向相反。</li>
<li><strong>动态区</strong>的数据大小<strong>在运行时刻才能决定</strong>。</li>
<li>栈区主要跟与函数调用相关：
<ul>
<li>当一个<strong>函数被调用</strong>的时候，用于<strong>存放该函数的局部变量</strong>的空间被<strong>压入栈</strong>。</li>
<li>当这个函数<strong>结束</strong>时，该空间<strong>从栈中弹出</strong></li>
<li>栈区空间<strong>可以</strong>被多个<strong>活动阶段不重叠的函数共享</strong></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h5 id="函数调用">函数调用</h5>
<ul>
<li><p>函数体的一次<strong>执行</strong>称为该函数的一个<strong>活动</strong>（Activation）</p></li>
<li><p>从函数体执行的第一步到最后一步的步序列为该函数的<strong>活动生存期</strong>。</p></li>
<li><p>函数活动的<strong>嵌套特性</strong>：即一个函数p的一个活动调用了函数q，那么q的该次活动必定在p的活动结束之前结束。</p></li>
<li><p>可以用<strong>活动树</strong>来说明在整个程序运行期间的所有函数的活动。</p>
<ul>
<li><strong>根节点是main函数</strong>的活动。在<strong>表示函数p</strong>的某个活动的节点上，其<strong>子节点</strong>对应于<strong>被p的这次活动调用的各个函数</strong>的活动。我们<strong>按照这些活动被调用的顺序</strong>，<strong>自左向右地</strong>表示它们。</li>
<li>一个<strong>子节点</strong>必须<strong>在其右兄弟节点的活动开始之前结束</strong></li>
<li>因此，<strong>函数调用</strong>序列和<strong>活动树的先序遍历</strong>相对应</li>
<li><strong>函数返回</strong>序列和<strong>活动树的后序遍历</strong>相对应</li>
<li><strong>先进后出</strong>适合栈存储</li>
</ul></li>
<li><p>每个活动都有一个<strong>活动记录</strong>：</p>
<ul>
<li><p>活动树的<strong>根位于栈底</strong>，<strong>栈中全部活动记录的序列</strong>对应于在活动树中<strong>从根节点到达当前活跃的活动节点的路径</strong>。<strong>当前程序控制所在活动的活动</strong>记录位于<strong>栈顶</strong></p></li>
<li><p>存储<strong>所有</strong>的<strong>尚未返回</strong>的函数调用信息</p></li>
<li><p><strong>活动记录</strong>记录了下图中的数据：</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041540688.png" alt="image-20220104154040579" style="zoom:67%;" /></p>
<ul>
<li>访问链描述的是 <strong>函数在哪个父函数体中定义</strong>，那么父函数就会给一个访问链给子函数。(作业涉及)</li>
</ul></li>
</ul></li>
</ul>
<h5 id="调用代码序列返回代码序列">调用代码序列、返回代码序列</h5>
<ul>
<li><strong>实现函数调用</strong>的代码称为<strong>调用代码序列</strong>
<ul>
<li>为一个活动记录<strong>在栈中分配空间</strong>，并在此记录的<strong>字段中填写信息</strong></li>
<li>调用代码序列分为<strong>调用者</strong>和<strong>被调用者</strong>的代码</li>
<li>调用者和被调用者之间传递的值（包括<strong>参数和返回值</strong>），一般被放在<strong>被调用者活动记录</strong>的<strong>开始位置</strong></li>
<li><strong>固定长度的</strong>项（包括控制链、访问链和机器状态字段）放在记录的<strong>中间</strong>位置</li>
<li>开<strong>始不知道大小的</strong>项（例如动态数组）被放置在活动记录的<strong>尾部</strong>
<ul>
<li>放在尾部才能<strong>随时增长</strong>空间。</li>
</ul></li>
</ul></li>
<li><strong>返回代码序列</strong>是<strong>恢复机器状态</strong>，使得调用函数能够在调用结束后继续执行的代码。
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041545284.png" alt="image-20220104154529204" style="zoom:80%;" /></li>
<li>调用者<strong>计算实参</strong>的值</li>
<li>调用者将<strong>返回地址和top_sp</strong>的值放在被调用者的活动记录中，然后<strong>增加top_sp</strong>的值</li>
<li>被调用者<strong>保存寄存器值和其它状态信息</strong>,将<strong>返回值</strong>放在与参数相邻的位置,<strong>恢复top_sp和其它寄存器</strong>，然后跳转到由调用者放在机器状态字段中的<strong>返回地址</strong></li>
</ul></li>
</ul>
<h5 id="堆区管理">堆区管理</h5>
<ul>
<li><p>堆用来存储那些<strong>生命周期不确定</strong>，由<strong>程序显式删除来结束生存期</strong>的数据对象。它们的<strong>生存期与函数无关</strong>。</p></li>
<li><p>用<strong>存储管理器</strong>来<strong>分配和回收堆区空间</strong></p>
<ul>
<li><p>最好<strong>尽量减少存储碎片</strong>、<strong>充分利用存储子系统</strong>、<strong>减少分配和回收的时间</strong>。</p></li>
<li><p>计算机的存储结构一般分为<strong>寄存器，一级缓存，二级缓存，物理内存，虚拟内存</strong>。速度依次<strong>降低</strong>。</p></li>
<li><p>为了<strong>充分利用存储空间、不浪费时间</strong>，需要考虑程序的<strong>时间局部性</strong>以及<strong>空间局部性</strong>。</p></li>
<li><p>为了尽量减少存储碎片，如果进行<strong>人工垃圾回收</strong>，可能会发生：</p>
<ul>
<li><strong>内存泄漏</strong>：<strong>一直未能删除</strong>不会被引用的数据</li>
<li><strong>悬空指针引用</strong>：<strong>引用已经被删除</strong>的数据</li>
</ul>
<p>最好就是进行<strong>垃圾回收算法的研究</strong>。基本思想：<strong>可达性分析</strong>。分析一个存储<strong>是否可以被引用或到达</strong>。</p>
<ul>
<li>定义根集为<strong>不需要任何指针操作</strong>就可以<strong>被程序直接访问</strong>的数据。</li>
<li>用<strong>引用计数法</strong>表示可达性：
<ul>
<li>对象分配:<strong>新对象</strong>的引用计数被设置为<strong>1</strong></li>
<li>参数传递:<strong>被传递</strong>给一个函数的<strong>每个对象的引用计数加1</strong></li>
<li>引用赋值:若u和v都是引用，对于语句u=v, <strong>v指向的对象</strong>的引用计数<strong>加1</strong>，u<strong>原来指向的原对象</strong>引用计数<strong>减1</strong></li>
<li>函数返回:该函数<strong>活动记录的局部变量</strong>中所指向的对象的<strong>引用减1</strong>.</li>
<li>可达性传递丢失:当一个对象的<strong>引用计数变成0</strong>时，我们必须将<strong>该对象中的各个引用所指向的每个对象</strong>的引用计数<strong>减1</strong> ,然后准备删除它。</li>
</ul></li>
<li>对于环结构，该方法没法进行<strong>垃圾回收</strong>。
<ul>
<li>引用计数<strong>永远大于0</strong>。</li>
</ul></li>
<li>基于跟踪的垃圾回收:
<ul>
<li><strong>基本的标记清扫式回收器</strong>:
<ul>
<li>找出所有可达对象,<strong>将其他对象删除</strong>
<ul>
<li>只作清扫。</li>
</ul></li>
</ul></li>
<li><strong>标记压缩回收器</strong>
<ul>
<li>找出所有可达对象,在堆区内移动可达对象以<strong>消除存储碎片</strong>
<ul>
<li>也就是“<strong>压缩</strong>”的含义。</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="chap.8">Chap.8</h3>
<h4 id="代码生成">代码生成</h4>
<ul>
<li><p>根据<strong>中间表示</strong>生成<strong>目标机器代码</strong>,代码生成器之前<strong>可能有一个优化组件</strong></p></li>
<li><p>代码生成器的任务是<strong>指令选择</strong>、<strong>寄存器分配和指派</strong>、<strong>指令排序</strong>（安排指令的顺序）。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041629046.png" alt="image-20220104162903970" style="zoom:67%;" /></p>
<ul>
<li>LD<strong>只能加载到寄存器</strong>，ST<strong>装载到指定内存位置</strong>。
<ul>
<li>*p=9等修改指定内存位置数据的，需要使用ST指令。LD只会修改寄存器的值</li>
<li>return 之后的代码不执行噢</li>
</ul></li>
</ul>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202201041641943.png" alt="image-20220104164148872" style="zoom:80%;" /></p>
<ul>
<li>call的过程就是把<strong>返回地址#..用 ST 指令放到指定位置处</strong>,<strong>可以</strong>存放在代码段的<strong>后段</strong>，用*<strong>label</strong>取出即可。
<ul>
<li>用BR指令跳转到被调用函数处执行。</li>
</ul></li>
</ul></li>
<li><p>指令的寻址方式:</p>
<ul>
<li>a(r)寻址:a的左值<strong>加</strong>上存放在<strong>寄存器r</strong>中的值,
<ul>
<li>这里注意括号里<strong>必须是寄存器</strong>噢</li>
</ul></li>
<li><strong>contents(x)</strong>表示x所代表的<strong>寄存器或内存中存放的值</strong>
<ul>
<li>a(r)翻译为contents(a+contents(r))</li>
</ul></li>
<li><strong>constant(r)</strong>，寄存器r中的值<strong>加上前面的常数</strong></li>
<li>*<strong>r</strong>表示r的内容所表示的位置上存放的位置中的值,即<strong>contents(r)</strong></li>
<li>在<strong>常数</strong>前面加上#</li>
</ul></li>
<li><p>过程调用相关的栈式分配:</p>
<ul>
<li>在<strong>寄存器SP</strong>中存放一个<strong>指向栈顶</strong>的活动记录的开始处的<strong>指针</strong>。</li>
<li>发生<strong>过程调用</strong>时，调用过程<strong>增加SP值</strong>，并把<strong>控制转移</strong>至被调用过程。返回时，<strong>减少SP的值</strong>，从而<strong>释放被调用过程的活动记录</strong>。</li>
</ul></li>
</ul>
<h5 id="基本块与流图">基本块与流图</h5>
<ul>
<li><p>把中间代码划为基本块。</p>
<ul>
<li><p>控制流<strong>只能从基本块中的第一个指令进入该块</strong>。没有跳转到基本块中间的转移指令。</p>
<p>除了基本块的最后一个指令，控制流<strong>在离开基本块之前不会停止或者跳转</strong>。</p></li>
<li><p>确定基本块：</p>
<ul>
<li>确定基本块的<strong>首指令</strong>：
<ul>
<li>中间代码的<strong>第一个三地址指令</strong>是一个首指令</li>
<li>任意一个条件或无条件转移指令的<strong>目标指令</strong>是一个首指令</li>
<li>紧跟在一个<strong>条件或无条件转移指令之后的指令</strong>是一个首指令</li>
</ul></li>
<li>每个首指令对应的基本块包括了<strong>从它自己开始，直到下一个首指令</strong>（不含）或者<strong>结尾指令之间的所有指令</strong>。</li>
</ul></li>
</ul></li>
<li><p>流图的结点是基本块：</p>
<ul>
<li>从基本块B到基本块C之间有一条边当且仅当基本块C的第一个指令可能紧跟在B的最后一条指令之后执行。
<ul>
<li><strong>有一个从B的结尾跳转到C的开头</strong>的条件或无条件<strong>跳转语句</strong></li>
<li>按照原来的三地址语句序列中的顺序，C紧跟在B之后，且B的结尾不存在跳转语句。</li>
<li>增加一个入口和出口。入口到流图的第一个基本块有一条边。从任何可能是程序的最后执行指令的基本块到出口有一条边。</li>
</ul></li>
<li>流图可以识别循环：
<ul>
<li>若满足以下条件，则流图中的一个结点集合L是一个循环：
<ul>
<li>从<strong>整个流图的入口结点</strong>开始到<strong>L中的任何结点的路径</strong>都<strong>必然经过循环入口</strong>结点。</li>
<li>L的<strong>每个结点</strong>都有一个<strong>到达L的入口结点的非空路径</strong>，并且该路径都在L中。</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>基本块的优化</strong>又称为局部优化</p>
<ul>
<li>基本块可以用DAG来表示
<ul>
<li><strong>消除局部公共子表达式</strong></li>
<li><strong>消除死代码</strong>
<ul>
<li><strong>删除没有附加活跃变量</strong>且<strong>没有父节点</strong>的结点</li>
</ul></li>
<li><strong>语句重排</strong>序</li>
<li>对运算分量进行符合代数规则重排序
<ul>
<li>用代数恒等式简化运算，减小计算开销,除法-&gt;乘法，乘法-&gt;加法</li>
</ul></li>
</ul></li>
<li>数组引用的DAG表示：
<ul>
<li>x=a[i]，用运算符为=[]的结点表示。这个结点的<strong>左右子节点</strong>是数组初始值a0和下标i。变量x是这个结点的<strong>标号</strong>之一。</li>
<li>a[j]=y, 这个结点的<strong>三个子节点</strong>分别表示a0、j和y。<strong>没有其它变量用这个结点标号</strong>。此结点创建后，当前已经建立的、<strong>其值依赖于的a0所有结点被杀死</strong>。</li>
</ul></li>
</ul></li>
<li><p>寄存器的使用约定:</p>
<ul>
<li><strong>各个运算分量必须存放在寄存器</strong>中</li>
<li>寄存器适合存放<strong>临时变量</strong></li>
<li>寄存器用来存放在一个基本块中计算而在<strong>另一个基本块中使用</strong>的值。</li>
<li>寄存器用来<strong>帮助</strong>进行运行时刻<strong>存储管理</strong>。如运行时刻栈的指针。</li>
</ul></li>
<li><p><strong>寄存器描述符</strong>：<strong>记录寄存器当前存放</strong>了哪个变量的值。</p></li>
<li><p><strong>地址描述符</strong>：<strong>记录每个名字的当前值的存放处所</strong>，可以是寄存器，也可以是内存地址，或者它们的集合</p></li>
<li><p><strong>LD，ST指令、赋值</strong>等会修改这些描述符。</p></li>
<li><p><strong>代码生成算法</strong>:</p>
<ul>
<li>调用<strong>getreg(i)选择寄存器</strong>
<ul>
<li>i值已经存放到某寄存器x，就选x</li>
<li>未存放，有空寄存器y,就选y</li>
<li>没有空寄存器y,复用代价最小的寄存器</li>
</ul></li>
<li>根据寄存器<strong>有无加载</strong>，<strong>生成LD指令</strong></li>
<li><strong>修改寄存器描述符</strong>，修正存放对象的描述</li>
</ul></li>
</ul>
<h3 id="chap.9">Chap.9</h3>
<h4 id="机器无关的优化"><strong>机器无关的优化</strong></h4>
<ul>
<li>代码优化
<ul>
<li>在目标代码中<strong>消除不必要的指令</strong></li>
<li>把一个指令序列替换为一个<strong>完成相同功能的更快的</strong>指令序列</li>
</ul></li>
<li>可做的优化
<ul>
<li>可以消去<strong>流图</strong>中的<strong>全局公共子表达式</strong></li>
<li>复制传播:
<ul>
<li>复制传播转换的基本思想是在<strong>复制语句u=v之后</strong>尽可能的<strong>用v来替代u</strong>。</li>
</ul></li>
<li>死代码的消除:
<ul>
<li>一个变量在一个程序点上的值在以后不再被使用，则变成不活跃了，变成死代码了。</li>
</ul></li>
<li>代码移动:
<ul>
<li>在进入循环前，<strong>对循环不变表达式(循环中值不变的表达式)进行求值</strong>。</li>
<li>尽可能减少内部循环的指令可能</li>
</ul></li>
<li>归纳变量：
<ul>
<li>对于一个变量x，如果<strong>存在一个正的或负的常数c</strong>使得每次x被赋值时<strong>它的值总是增加c</strong>，那么<strong>x被称为归纳变量</strong></li>
<li>如果<strong>有一组归纳变量的值的变化保持步调一致</strong>，常常可以<strong>将这组变量删除只剩一个</strong>。</li>
<li>基本可以认为<strong>循环的迭代变量</strong>就是归纳变量。
<ul>
<li>把随着i、j变化的变量尽可能去掉i、j</li>
</ul></li>
</ul></li>
<li>强度削减：</li>
<li>把一个<strong>高代价的运算</strong>（比如乘法）替换为一个<strong>代价较低的运算</strong>（比如加法）的转换称为强度削减。</li>
</ul></li>
<li>代码生成的过程:
<ul>
<li>生成三地址代码</li>
<li>找出基本块</li>
<li>流图</li>
<li>删除全局公共子表达式</li>
<li>复制传播、死代码的消除、强度削减、删除归纳变量</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>CS Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>CS</tag>
      </tags>
  </entry>
  <entry>
    <title>chap.10 降维与度量学习</title>
    <url>/2021/12/21/%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="第十章.降维与度量学习">第十章.降维与度量学习</h4>
<h5 id="k近邻学习k-nearest-neighbor">k近邻学习(k-Nearest Neighbor)</h5>
<ul>
<li><p>是一种监督学习方法。</p></li>
<li><p>idea ： 给定样本，基于一种距离度量方案找出与其最接近的k个训练样本，然后基于这k个样本的信息进行预测。</p>
<ul>
<li><p>在分类问题中，对这k个样本采取投票法决定类别。</p></li>
<li><p>对于回归问题，用平均法作为预测结果。</p></li>
<li><p>一个示例图:</p>
<ul>
<li><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112202057821.png" alt="image-20211220205713716" style="zoom:50%;" /></li>
</ul></li>
</ul></li>
<li><p>是一种懒惰学习算法。懒惰学习是指在训练阶段只把样本进行保存，训练时间的开销几乎为0，在获得测试样本时，再对训练样本进行处理；而与之对应的，如果在训练阶段就对样本进行处理的算法就是“急切学习”。</p>
<p><span id="more"></span></p></li>
<li><p>数学推导：</p>
<ul>
<li><p>给定测试样本<span class="math inline">\(x\)</span>,如果其最近邻样本为<span class="math inline">\(z\)</span>,那么分类错的概率就是<span class="math inline">\(x\)</span>,<span class="math inline">\(z\)</span>分了不同的类 <span class="math display">\[
  P(err) = 1 - \sum_{c\in\mathcal{Y}} P(c|x)P(c|z)\\
  \mathcal{Y}\ is\ the \ class\ set
  \]</span></p></li>
<li><p>对上述式子做一个强假设：样本独立同分布，且<span class="math inline">\(z\)</span>可以在<span class="math inline">\(x\)</span>的任意近的范围内找到。那么，如果令<span class="math inline">\(c^\star = \arg\max_{c\in\mathcal{Y}} P(c|x)\)</span> 即贝叶斯最优分类器的结果，可以推导出： <span class="math display">\[
  P(err) \approx 1 - \sum_{c\in\mathcal{Y}} P(c|x)^2 \\
      \le 1 - P^2(c^\star|x) \\
       = (1 - P(c^\star|x)) (1 + P(c^\star|x)) \\
       \le 2 \times [1 - P(c^\star|x)]
  \]</span> 因此，KNN分类器分错样本的概率比贝叶斯最优分类器的误差的两倍小。</p></li>
</ul></li>
<li><p>Review(贝叶斯最优分类器):</p>
<ul>
<li><p>将loss定义为将<span class="math inline">\(c_i\)</span>样本错分为<span class="math inline">\(c_j\)</span>样本的损失： <span class="math display">\[
  Loss(c_j|x) = \sum_{i=1}^N \lambda_{ji} P(c_i|x)
  \]</span></p></li>
<li><p>为了最小化总体loss，只需要选择能够让条件风险最小的类别<span class="math inline">\(c^\star\)</span>即可，就可以得到一个最优分类器： <span class="math display">\[
  c^\star = \arg\min_{c\in\mathcal{Y}} Loss(c|x) \\
          = \arg\max_{c\in\mathcal{Y}} P(c|x) 
  \]</span> 通俗的解释来说，想要让其他类错分为<span class="math inline">\(c^\star\)</span> 的造成的损失最小，那么就选择在所有类别中样本被划分的后验概率最大的那一个class <span class="math inline">\(c\)</span> 。</p></li>
</ul></li>
<li><p>但是，KNN分类器分错样本的概率比贝叶斯最优分类器的误差的两倍小这个结论能够推导出来的条件是<span class="math inline">\(z\)</span>可以在<span class="math inline">\(x\)</span>的任意近的范围内找到,也就是说在任意样本<span class="math inline">\(x\)</span>的任意<span class="math inline">\(\delta\)</span>范围都有另一个训练样本<span class="math inline">\(z\)</span>,则要求我们的采样密度足够大，这也就是“密采样”。</p></li>
<li><p>如果<span class="math inline">\(delta=0.001\)</span>,对于单个属性，就要求1000个样本分布在归一化属性范围内。如果属性维度为<span class="math inline">\(n\)</span>,那么采样数量就是<span class="math inline">\((1000)^n\)</span> 。在这种高纬度的数据情况下，会出现数据样本稀疏、距离计算困难等诸多障碍，也就是所谓的“维数灾难”。</p></li>
<li><p>要缓解维数灾难的重要方法就是降维——将原始高维子空间降为低维子空间,而要求就是这个低维子空间正是我们的学习任务密切相关的部分。在实际问题中，与问题密切相关的很多时候，恰恰就是一个低维子空间。</p></li>
</ul>
<h5 id="降维方法多维缩放mds">降维方法——多维缩放MDS</h5>
<ul>
<li><p>MDS要求原始空间中样本之间的距离在低维空间中得以保持。</p></li>
<li><p>将该问题建模。假设m个样本在原始空间的距离矩阵为<span class="math inline">\(\mathbf{D} = \{dist_{ij}\} \in R^{m\times m}\)</span>, <span class="math inline">\(dist_{ij}\)</span>为样本<span class="math inline">\(x_i\)</span>到样本<span class="math inline">\(x_j\)</span>的距离。我们的目标是找到低维空间的距离矩阵<span class="math inline">\(\mathbf{Z}\in R^{d^\prime \times m}\)</span> ,并且<span class="math inline">\(||z_j - z_i||_2^2 = dist_{ij} (1)\)</span> 。</p></li>
<li><p>令$ = ^T  = {b_{ij}} = z_i^T z_j $ ,是降维后样本的内积矩阵，由(1)式，我们可以推导得知， <span class="math display">\[
  dist_{ij}^2 = ||z_i||^2 + ||z_j||^2 - 2z_i^T z_j (2) \\
   = b_{ii} + b_{jj} - 2b_{ij}
  \]</span></p></li>
<li><p>为了方便，我们可以假设降维之后的样本<span class="math inline">\(\mathbf{Z}\)</span>被中心化，即<span class="math inline">\(\sum_{i=1}^m z_i = 0\)</span> 。</p></li>
<li><p>那么，<span class="math inline">\(\sum_{i=1}^m b_{ij} = z_j \times \sum_{i=1}^m z_i = 0\)</span>,<span class="math inline">\(\sum_{j=1}^m b_{ij} = z_i \times \sum_{j=1}^m z_j = 0\)</span>。</p></li>
<li><p>因此，<span class="math inline">\(tr(\mathbf{B})=||z_{i\ or \ j}||^2\)</span>,由(2)式推导得：</p>
<ul>
<li><p><span class="math display">\[
  \sum_{i=1}^m dist_{ij}^2 = \sum_{i=1}^m b_{ii} + m b_{jj} = tr(\mathbf{B}) + mb_{jj} \\
  \sum_{j=1}^m dist_{ij}^2 = \sum_{j=1}^m b_{jj} + m b_{ii} = tr(\mathbf{B}) + mb_{ii} \\
  \sum_{i=1}^m \sum_{j=1}^m dist_{ij}^2 = tr(\mathbf{B}) + \sum_{j=1}^m mb_{jj} = 2mtr(\mathbf{B})
  \]</span></p></li>
<li><p><span class="math display">\[
  dist_{i\cdot }^2  = \frac{1}{m} \sum_{j=1}^m dist_{ij}^2 = \frac{tr(\mathbf{B})}{m}  + b_{ii}\\
  dist_{\cdot j}^2  = \frac{1}{m} \sum_{i=1}^m dist_{ij}^2= \frac{tr(\mathbf{B})}{m}  + b_{jj}\\
  dist_{\cdot \cdot}^2  = \frac{1}{m^2} \sum_{j=1}^m \sum_{i=1}^m dist_{ij}^2 = 2\frac{tr(\mathbf{B})}{m}
  \]</span></p></li>
<li><p><span class="math display">\[
  b_{ij} = \frac{b_{ii} + b_{jj} - dist_{ij}^2}{2} \\
      = \frac{dist_{i\cdot }^2 - \frac{tr(\mathbf{B})}{m} + dist_{\cdot j }^2 - \frac{tr(\mathbf{B})}{m} - dist_{ij}^2 }{2} \\
      = \frac{dist_{i\cdot }^2  + dist_{\cdot j }^2  - dist_{ij}^2 - dist_{\cdot \cdot}^2}{2} 
  \]</span></p>
<p>至此，也就求出<span class="math inline">\(\mathbf{B}\)</span>矩阵了。</p></li>
</ul></li>
<li><p>而<span class="math inline">\(\mathbf{B}\)</span>是<span class="math inline">\(\mathbf{Z}\)</span>的内积矩阵，为了求得<span class="math inline">\(\mathbf{Z}\)</span>,我们需要找到一个矩阵，其内积为<span class="math inline">\(\mathbf{B}\)</span>。</p></li>
<li><p>一个想法是对<span class="math inline">\(\mathbf{B}\)</span>进行特征值分解，<span class="math inline">\(\mathbf{B} = \mathbf{V} \wedge \mathbf{V}^T\)</span> ,$<span class="math inline">\(是一个特征值构成的对角矩阵，\)</span><span class="math inline">\(是一个特征向量矩阵。如果假设有\)</span>d^*<span class="math inline">\(个非零特征值，其构成对角阵\)</span>_*$ ,那么<span class="math inline">\(\mathbf{Z}\)</span>就可以表示为<span class="math inline">\(\wedge_*^{1/2} \mathbf{V}_*^T\)</span> 。</p></li>
<li><p>而一般情况下，不要求降维后的距离严格不变，只要尽可能接近即可。此时，可以任意取<span class="math inline">\(\hat{d}\)</span>个非零特征值，其构成对角阵<span class="math inline">\(\hat{\wedge}_*\)</span> ,那么<span class="math inline">\(\mathbf{Z}\)</span>就可以表示为<span class="math inline">\(\hat{\wedge}_*^{1/2} \hat{\mathbf{V}_*}^T\)</span> 。</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292000691.png" alt="image-20211229200040605" style="zoom: 67%;" /></p></li>
</ul>
<h5 id="最一般的降维线性降维">最一般的降维——线性降维</h5>
<ul>
<li><p>一般，我们可以直接采取对<span class="math inline">\(\mathbf{X}\)</span>乘以一个变换矩阵<span class="math inline">\(\mathbf{W}\)</span>的形式得到<span class="math inline">\(\mathbf{Z}\)</span>,即<span class="math inline">\(\mathbf{Z} = \mathbf{W}^T \mathbf{X}\)</span></p>
<p>其中<span class="math inline">\(\mathbf{Z}\in R^{d^\prime \times m}\)</span>，<span class="math inline">\(\mathbf{X}\in R^{d \times m}\)</span>,<span class="math inline">\(\mathbf{W}\in R^{d \times d^\prime}\)</span> 。</p></li>
<li><p>其变换的含义在于对于每一个样本<span class="math inline">\(x_i\)</span>，<span class="math inline">\(z_i\)</span>都是<span class="math inline">\(x_i\)</span>与<span class="math inline">\(\mathbf{W}\)</span>中的<span class="math inline">\(d^\prime\)</span>个<span class="math inline">\(d\)</span>维向量内积的结果，即$z_i = ^T x_i $ 。如果基于<span class="math inline">\(z_i\)</span>来重构<span class="math inline">\(x_i\)</span>,那么<span class="math inline">\(x_i = \sum_{j=1}^{d^\prime} z_{ij} w_j\)</span>。原坐标系属性线性组合成了新坐标系中的属性。如果新坐标系是正交的，那么<span class="math inline">\(\mathbf{W}\)</span>就是一个正交变换。</p></li>
<li><p>PCA就是这种思想的典型代表。</p></li>
<li><p>PCA希望通过一个超平面对所有的样本点进行分隔。围绕这个目的，有两种等价的推导方式,在假设样本中心化以及<span class="math inline">\(\mathbf{W}\)</span>就是一个标准正交变换：</p>
<ul>
<li><p>最近重构性：所有的样本点到这个超平面距离都很近。</p>
<ul>
<li><p><span class="math display">\[
  ||\sum_{j=1}^{d^\prime} z_{ij} w_j - x_i||_2^2 \propto -tr(\mathbf{W}^T \mathbf{X}\mathbf{X}^T \mathbf{W})
  \]</span></p></li>
<li><p>优化目标：</p>
<ul>
<li><span class="math display">\[
  \min_{\mathbf{W}} -tr(\mathbf{W}^T \mathbf{X}\mathbf{X}^T \mathbf{W}) \\s.t. \mathbf{W}^T \mathbf{W} = \mathbf{I}
  \]</span></li>
</ul></li>
</ul></li>
<li><p>最大可分性：所有的样本点在这个超平面上的投影都尽可能分开。</p>
<ul>
<li><p>在这个超平面上的投影都尽可能分开-&gt;投影之后的方差最大化</p></li>
<li><p>投影也是一种线性变换，因此，投影后样本$ x_i<span class="math inline">\(变成\)</span>^T x_i<span class="math inline">\(,方差是\)</span>_i ^T x_i x_i^T  = tr(^T ^T )$ 。</p></li>
<li><p>优化目标：</p>
<ul>
<li><span class="math display">\[
  \max_{\mathbf{W}} tr(\mathbf{W}^T \mathbf{X}\mathbf{X}^T \mathbf{W}) \\
  s.t. \mathbf{W}^T \mathbf{W} = \mathbf{I}
  \]</span></li>
</ul></li>
</ul></li>
<li><p>对两个优化问题使用拉格朗日乘子法可以得到: <span class="math display">\[
  \mathbf{X}\mathbf{X}^T \mathbf{W} = \lambda \mathbf{W}
  \]</span></p></li>
<li><p>对协方差矩阵<span class="math inline">\(\mathbf{X}\mathbf{X}^T\)</span>进行特征值分解，就可以求得<span class="math inline">\(d\)</span>个特征值，按从大到小顺序取前<span class="math inline">\(d^\prime\)</span>个特征值即可得到PCA的解。</p></li>
<li><p>舍弃这<span class="math inline">\(d-d^\prime\)</span>个特征值，可以在采样相同样本数的情况下提升采样密度，并去除一部分噪声。</p></li>
<li><p><span class="math inline">\(d^\prime\)</span>一般由用户指定，也可以用其他分类器进行交叉验证，或者设定一个重构阈值<span class="math inline">\(t\)</span>,要求选取最小能够满足重构后的特征值大小<span class="math inline">\(\sum_{i=1}^{d^\prime} \lambda_i\)</span>与重构前的特征值大小<span class="math inline">\(\sum_{i=1}^{d} \lambda_i\)</span>的比值大于阈值$t $</p></li>
<li><p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292007828.png" alt="image-20211229200708759" style="zoom:67%;" /></p></li>
</ul></li>
</ul>
<h5 id="非线性降维核化线性降维">非线性降维——核化线性降维</h5>
<ul>
<li>上述介绍的PCA是线性降维方法，但是，事实上，我们通常需要一个非线性映射才能找到 恰当的低维嵌入,而非线性降维的常用方法是核化线性降维以及流形学习。这一节先介绍核化线性降维的想法。</li>
</ul>
<h5 id="流形学习">流形学习</h5>
<h5 id="距离度量学习">距离度量学习</h5>
<h5 id="等度量映射">等度量映射</h5>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292010562.png" alt="image-20211229201003497" style="zoom:67%;" /></p>
<h5 id="局部线性嵌入">局部线性嵌入</h5>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292012002.png" alt="image-20211229201243956" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292013211.png" alt="image-20211229201300156" style="zoom:67%;" /></p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112292011798.png" alt="image-20211229201114729" style="zoom:67%;" /></p>
]]></content>
      <categories>
        <category>ML Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>AML</tag>
      </tags>
  </entry>
  <entry>
    <title>近代史猜测的重点</title>
    <url>/2021/12/26/%E8%BF%91%E4%BB%A3%E5%8F%B2%E7%B4%A7%E6%80%A5%E5%A4%8D%E4%B9%A02/</url>
    <content><![CDATA[<h4 id="关于毛主席">关于毛主席</h4>
<p>1840年鸦片战争以后，在西方列强坚船利炮轰击下，中国危机四起、人民苦难深重，陷入半殖民地半封建社会的黑暗深渊。</p>
<p>实现中华民族伟大复兴始终是近代以来中国人民最伟大的梦想。</p>
<p>毛泽东同志在青年时期就立下拯救民族于危难的远大志向。</p>
<p>1919年，毛泽东同志在《〈湘江评论〉创刊宣言》中写道：“时机到了！世界的大潮卷得更急了！洞庭湖的闸门动了，且开了！浩浩荡荡的新思潮业已奔腾澎湃于湘江两岸了！顺他的生，逆他的死。”年轻的毛泽东同志，“书生意气，挥斥方遒。指点江山，激扬文字”，既有“问苍茫大地，谁主沉浮”的仰天长问，又有“到中流击水，浪遏飞舟”的浩然壮气。</p>
<span id="more"></span>
<p>十月革命一声炮响，给中国送来了马克思列宁主义。从纷然杂陈的各种观点和路径中，经过反复比较和鉴别，毛泽东同志毅然选择了马克思列宁主义，选择了为实现共产主义而奋斗的崇高理想。</p>
<p>马克思列宁主义，为中国人民点亮了前进的灯塔；1921年中国共产党的成立，使中国人民有了前进的主心骨</p>
<p>年轻的中国共产党，一度简单套用马克思列宁主义关于无产阶级革命的一般原理和照搬俄国十月革命城市武装起义的经验，中国革命遭受到严重挫折。</p>
<p>从革命斗争的这种失误教训中，毛泽东同志深刻认识到，面对中国的特殊国情，面对压在中国人民头上的三座大山，中国革命将是一个长期过程，不能以教条主义的观点对待马克思列宁主义，必须从中国实际出发，实现马克思主义中国化。</p>
<p>毛泽东同志创造性地解决了马克思列宁主义基本原理同中国实际相结合的一系列重大问题</p>
<p>提出通过新民主主义革命走向社会主义的两步走战略，制定了新民主主义革命总路线，开辟了以农村包围城市、最后夺取全国胜利的革命道路</p>
<p>把党建设成为用科学理论和革命精神武装起来的、同人民群众有着血肉联系的、思想上政治上组织上完全巩固的马克思主义政党</p>
<p>一支具有一往无前精神、能压倒一切敌人而决不被敌人所屈服的新型人民军队</p>
<p>毛泽东同志制定了过渡时期总路线，创造性地完成了由新民主主义革命向社会主义革命的转变，使中国这个占世界四分之一人口的东方大国进入了社会主义社会，成功实现了中国历史上最深刻最伟大的社会变革</p>
<p>毛泽东同志对适合中国情况的社会主义建设道路进行了艰苦探索,以苏联的经验教训为鉴戒，提出要把马克思列宁主义基本原理同中国实际进行“第二次结合”,带领中国建立起独立的比较完整的工业体系和国民经济体系，独立研制出“两弹一星”，成为在世界上有重要影响的大国</p>
<p>毛泽东同志毕生最突出最伟大的贡献，就是领导我们党和人民找到了新民主主义革命的正确道路，完成了反帝反封建的任务，建立了中华人民共和国，确立了社会主义基本制度，取得了社会主义建设的基础性成就，并为我们探索建设中国特色社会主义的道路积累了经验和提供了条件</p>
<h4 id="关于孙中山先生">关于孙中山先生</h4>
<p>孙中山先生是伟大的民族英雄、伟大的爱国主义者、中国民主革命的伟大先驱</p>
<p>青年时代，孙中山先生目睹山河破碎、生灵涂炭，高扬反对封建专制统治的旗帜，毅然投身民主革命事业。他创立兴中会、<strong>同盟会，提出民族、民权、民生的三民主义，积极传播革命思想</strong>，广泛联合革命力量，连续发动武装起义，为推进民主革命四处奔走、大声疾呼。</p>
<p>在他领导和影响下，震惊世界的辛亥革命取得成功，推翻了清王朝统治，结束了统治中国几千年的君主专制制度。建立中华民国。由于历史进程和社会条件的制约，辛亥革命虽然没有改变旧中国半殖民地半封建的社会性质，没有改变中国人民的悲惨命运，没有完成实现民族独立、人民解放的历史任务，但开创了完全意义上的近代民族民主革命，打开了中国进步闸门，传播了民主共和理念</p>
<p>孙中山先生的伟大，不仅在于他领导了辛亥革命，而且在于他为了实现革命理想，与时俱进完善自己的革命理念和斗争方略,十月革命爆发后，马克思列宁主义传入中国，为孙中山先生认识世界和中国打开了新的视野。中国共产党成立后，孙中山先生同中国共产党人真诚合作，在中国共产党帮助下，把旧三民主义发展为新三民主义，实行联俄、联共、扶助农工三大政策，改组中国国民党，推动北伐战争取得胜利，把反帝反封建的民主革命推向前进。</p>
<p>学习孙中山先生天下为公、心系民众的博大情怀</p>
<p>学习孙中山先生追求真理、与时俱进的优秀品质。</p>
<p>学习孙中山先生坚韧不拔、百折不挠的奋斗精神。</p>
<h4 id="关于邓小平同志">关于邓小平同志</h4>
<p>邓小平同志是全党全军全国各族人民公认的享有崇高威望的卓越领导人，伟大的马克思主义者，伟大的无产阶级革命家、政治家、军事家、外交家，久经考验的共产主义战士，中国社会主义改革开放和现代化建设的总设计师，中国特色社会主义道路的开创者，邓小平理论的主要创立者</p>
<p>新民主主义革命时期，邓小平同志为党领导的民族独立和人民解放事业建立了卓越功勋，是中华人民共和国的开国元勋。</p>
<p>土地革命战争期间，他先后在上海极端险恶的环境下从事地下工作，在广西领导发动百色起义和龙州起义、创立左右江革命根据地，参加艰苦卓绝的长征，亲历标志着党的历史伟大转折的遵义会议。抗日战争和解放战争期间，他坚决执行党中央和毛泽东同志的战略决策，军政兼任、勇挑重担，不畏艰险、出奇制胜，一直处在战略全局的关键位置，处在对敌斗争的最前线。特别是先后同刘伯承、陈毅等同志一起，开辟晋冀鲁豫抗日根据地，率部千里跃进大别山，组织实施淮海战役和渡江战役，进军解放大西南，建立了赫赫战功。</p>
<p>邓小平同志以他的远见卓识、丰富政治经验、高超领导艺术，强调实事求是是毛泽东思想的精髓，旗帜鲜明反对“两个凡是”的错误观点，支持和领导开展真理标准问题的讨论，推动进行各方面的拨乱反正。在邓小平同志指导下，1978年12月召开的党的十一届三中全会，重新确立了解放思想、实事求是的思想路线，停止使用“以阶级斗争为纲”的错误提法，确定把全党工作的着重点转移到社会主义现代化建设上来，作出实行改革开放的重大决策，实现了党的历史上具有深远意义的伟大转折。</p>
<p>邓小平同志始终站在时代要求、国家发展、人民期待的高度,彻底否定了“文化大革命”的错误实践和理论，坚决顶住否定毛泽东同志和毛泽东思想的错误思潮，为党和国家发展确定了正确方向。邓小平同志紧紧抓住“什么是社会主义、怎样建设社会主义”这个基本问题，响亮提出“走自己的道路，建设有中国特色的社会主义”的伟大号召</p>
<p>邓小平同志强调必须坚持以经济建设为中心，坚持四项基本原则，坚持改革开放，领导我们党制定了党在社会主义初级阶段的基本路线。邓小平同志指导我们党正确认识我国所处的发展阶段和根本任务，制定了现代化建设“三步走”发展战略。邓小平同志突出强调“改革是中国的第二次革命”</p>
<p>邓小平同志反复强调“两手抓、两手都要硬”，必须抓好社会主义精神文明建设和民主法制建设，实现社会全面进步。他创造性提出“一国两制”科学构想</p>
<p>求真务实,实事求是的理论品质</p>
<p>邓小平同志留给我们的最重要的思想和政治遗产，就是他带领党和人民开创的中国特色社会主义，就是他创立的邓小平理论。</p>
<p>中国特色社会主义是适合中国国情、符合中国特点、顺应时代发展要求的理论和实践，所以才能取得成功，并将继续取得成功。</p>
<h4 id="辛亥革命">辛亥革命</h4>
<p>辛亥革命，推翻了清朝政府，结束了在中国延续几千年的君主专制制度</p>
<p>1840年鸦片战争以后，西方列强在中华大地上恣意妄为，封建统治者孱弱无能，中国逐步成为半殖民地半封建社会，国家蒙辱、人民蒙难、文明蒙尘</p>
<p>辛亥革命极大促进了中华民族的思想解放，传播了民主共和的理念，打开了中国进步潮流的闸门，撼动了反动统治秩序的根基，在中华大地上建立起亚洲第一个共和制国家</p>
<p>由于历史进程和社会条件的制约，由于没有找到解决中国前途命运问题的正确道路和领导力量，辛亥革命没有改变旧中国半殖民地半封建的社会性质和中国人民的悲惨境遇，没有完成实现民族独立、人民解放的历史任务。</p>
<p>辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，必须有领导中国人民前进的坚强力量，这个坚强力量就是中国共产党。</p>
<p>辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，必须有领导中国人民前进的坚强力量，这个坚强力量就是中国共产党。</p>
<p>辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，必须依靠中国人民自己的英勇奋斗。</p>
<p>辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，中国人民和中华民族必须同舟共济，依靠团结战胜前进道路上一切风险挑战。</p>
<p>辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，不仅需要安定团结的国内环境，而且需要和平稳定的国际环境。</p>
<h4 id="五四运动"><strong>五四运动</strong></h4>
<p>五四运动，爆发于民族危难之际，是一场以先进青年知识分子为先锋、广大人民群众参加的彻底反帝反封建的伟大爱国革命运动，是一场中国人民为拯救民族危亡、捍卫民族尊严、凝聚民族力量而掀起的伟大社会革命运动，是一场传播新思想新文化新知识的伟大思想启蒙运动和新文化运动，</p>
<p>五四运动，以彻底反帝反封建的革命性、追求救国强国真理的进步性、各族各界群众积极参与的广泛性，推动了中国社会进步，促进了马克思主义在中国的传播，促进了马克思主义同中国工人运动的结合，为中国共产党成立做了思想上干部上的准备，为新的革命力量、革命文化、革命斗争登上历史舞台创造了条件，是中国旧民主主义革命走向新民主主义革命的转折点，在近代以来中华民族追求民族独立和发展进步的历史进程中具有里程碑意义。</p>
<p>五四运动以全民族的力量高举起爱国主义的伟大旗帜。五四运动，孕育了以爱国、进步、民主、科学为主要内容的伟大五四精神，其核心是爱国主义。爱国主义是我们民族精神的核心</p>
<p>五四运动以全民族的行动激发了追求真理、追求进步的伟大觉醒。五四运动前后，我国一批先进知识分子和革命青年，在追求真理中传播新思想新文化，勇于打破封建思想的桎梏，猛烈冲击了几千年来的封建旧礼教、旧道德、旧思想、旧文化。</p>
<p>五四运动以全民族的搏击培育了永久奋斗的伟大传统。中国人民和中华民族从斗争实践中懂得，中国社会发展，中华民族振兴，中国人民幸福，必须依靠自己的英勇奋斗来实现，没有人会恩赐给我们一个光明的中国。</p>
<p>新时代中国青年要树立远大理想。青年的理想信念关乎国家未来。</p>
<p>新时代中国青年要热爱伟大祖国。</p>
<p>新时代中国青年要担当时代责任。时代呼唤担当，民族振兴是青年的责任。</p>
<p>新时代中国青年要勇于砥砺奋斗。奋斗是青春最亮丽的底色。</p>
<p>新时代中国青年要练就过硬本领。青年是苦练本领、增长才干的黄金时期。“青春虚度无所成，白首衔悲亦何及。</p>
<p>第六，新时代中国青年要锤炼品德修为。人无德不立，品德是为人之本。止于至善，是中华民族始终不变的人格追求。</p>
<h4 id="庆祝中国共产党成立"><strong>庆祝中国共产党成立</strong></h4>
<p>在中国人民和中华民族的伟大觉醒中，在马克思列宁主义同中国工人运动的紧密结合中，中国共产党应运而生。</p>
<p>中国共产党一经诞生，就把为中国人民谋幸福、为中华民族谋复兴确立为自己的初心使命。一百年来，中国共产党团结带领中国人民进行的一切奋斗、一切牺牲、一切创造，归结起来就是一个主题：实现中华民族伟大复兴。</p>
<p>为了实现中华民族伟大复兴，中国共产党团结带领中国人民，浴血奋战、百折不挠，创造了<strong>新民主主义革命的伟大成就</strong>。我们经过北伐战争、土地革命战争、抗日战争、解放战争，以武装的革命反对武装的反革命，推翻帝国主义、封建主义、官僚资本主义三座大山，建立了人民当家作主的中华人民共和国，实现了民族独立、人民解放。新民主主义革命的胜利，彻底结束了旧中国半殖民地半封建社会的历史，彻底结束了旧中国一盘散沙的局面，彻底废除了列强强加给中国的不平等条约和帝国主义在中国的一切特权，为实现中华民族伟大复兴创造了根本社会条件。</p>
<p>为了实现中华民族伟大复兴，中国共产党团结带领中国人民，自力更生、发愤图强，创造了<strong>社会主义革命和建设的伟大成就</strong>。我们进行社会主义革命，消灭在中国延续几千年的封建剥削压迫制度，确立社会主义基本制度，推进社会主义建设，战胜帝国主义、霸权主义的颠覆破坏和武装挑衅，实现了中华民族有史以来最为广泛而深刻的社会变革，实现了一穷二白、人口众多的东方大国大步迈进社会主义社会的伟大飞跃，为实现中华民族伟大复兴奠定了根本政治前提和制度基础。</p>
<p>为了实现中华民族伟大复兴，中国共产党团结带领中国人民，解放思想、锐意进取，创造了<strong>改革开放和社会主义现代化建设的伟大成就</strong>。我们实现新中国成立以来党的历史上具有深远意义的伟大转折，确立党在社会主义初级阶段的基本路线，坚定不移推进改革开放，战胜来自各方面的风险挑战，开创、坚持、捍卫、发展中国特色社会主义，实现了从高度集中的计划经济体制到充满活力的社会主义市场经济体制、从封闭半封闭到全方位开放的历史性转变，实现了从生产力相对落后的状况到经济总量跃居世界第二的历史性突破，实现了人民生活从温饱不足到总体小康、奔向全面小康的历史性跨越，为实现中华民族伟大复兴提供了充满新的活力的体制保证和快速发展的物质条件</p>
<p>为了实现中华民族伟大复兴，中国共产党团结带领中国人民，自信自强、守正创新，统揽伟大斗争、伟大工程、伟大事业、伟大梦想，创造了新时代<strong>中国特色社会主义的伟大成就</strong>。统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，坚持和完善中国特色社会主义制度、推进国家治理体系和治理能力现代化，坚持依规治党、形成比较完善的党内法规体系，战胜一系列重大风险挑战，实现第一个百年奋斗目标，明确实现第二个百年奋斗目标的战略安排，</p>
<p>以史为鉴、开创未来，必须坚持中国共产党坚强领导。办好中国的事情，关键在党。</p>
<p>以史为鉴、开创未来，必须团结带领中国人民不断为美好生活而奋斗。</p>
<p>以史为鉴、开创未来，必须继续推进马克思主义中国化。</p>
<p>以史为鉴、开创未来，必须坚持和发展中国特色社会主义。走自己的路，是党的全部理论和实践立足点，更是党百年奋斗得出的历史结论。</p>
<p>以史为鉴、开创未来，必须加快国防和军队现代化。</p>
<p>以史为鉴、开创未来，必须不断推动构建人类命运共同体。</p>
<p>以史为鉴、开创未来，必须进行具有许多新的历史特点的伟大斗争。</p>
<p>以史为鉴、开创未来，必须加强中华儿女大团结。</p>
<p>以史为鉴、开创未来，必须不断推进党的建设新的伟大工程。</p>
<h4 id="红军长征"><strong>红军长征</strong></h4>
<p>红军第一、第二、第四方面军和第二十五军进行了伟大的长征。宣告了国民党反动派消灭中国共产党和红军的图谋彻底失败，宣告了中国共产党和红军肩负着民族希望胜利实现了北上抗日的战略转移，实现了中国共产党和中国革命事业从挫折走向胜利的伟大转折，开启了中国共产党为实现民族独立、人民解放而斗争的新的伟大进军。</p>
<p>长征是一次理想信念的伟大远征。崇高的理想，坚定的信念，永远是中国共产党人的政治灵魂。</p>
<p>长征是一次检验真理的伟大远征。真理只有在实践中才能得到检验，真理只有在实践中才能得到确立。经过长征，党和红军不是弱了，而是更强了，因为我们党找到了中国革命的正确道路，找到了指引这条道路的正确理论。</p>
<p>长征是一次唤醒民众的伟大远征。红军打胜仗，人民是靠山。长征是历史纪录上的第一次，长征是宣言书，长征是宣传队，长征是播种机。我们党始终植根于人民，联系群众、宣传群众、武装群众、团结群众、依靠群众，以自己的模范行动，赢得人民群众真心拥护和支持，广大人民群众是长征胜利的力量源泉。</p>
<p>长征是一次开创新局的伟大远征。长征的胜利，是方向和道路的胜利。长征的过程，不仅是战胜敌人、赢得胜利、实现战略目标的过程，而且是联系实际、创新理论、探索革命道路的过程。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须坚定共产主义远大理想和中国特色社会主义共同理想，为崇高理想信念而矢志奋斗。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须坚定中国特色社会主义道路自信、理论自信、制度自信、文化自信，为夺取中国特色社会主义伟大事业新胜利而矢志奋斗。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须坚定中国特色社会主义道路自信、理论自信、制度自信、文化自信，为夺取中国特色社会主义伟大事业新胜利而矢志奋斗。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须把握方向、统揽大局、统筹全局，为实现我们的总任务、总布局、总目标而矢志奋斗。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须建设同我国国际地位相称、同国家安全和发展利益相适应的巩固国防和强大军队，为维护国家安全和世界和平而矢志奋斗。</p>
<p>弘扬伟大长征精神，走好今天的长征路，必须加强党的领导，坚持全面从严治党，为推进党的建设新的伟大工程而矢志奋斗。</p>
<h4 id="抗日战争胜利">抗日战争胜利</h4>
<p>这是近代以来中国人民反抗外敌入侵持续时间最长、规模最大、牺牲最多的民族解放斗争，也是第一次取得完全胜利的民族解放斗争。这个伟大胜利，是中华民族从近代以来陷入深重危机走向伟大复兴的历史转折点、也是世界反法西斯战争胜利的重要组成部分，是中国人民的胜利、也是世界人民的胜利。</p>
<p>日本对华持续侵略是近代以来中国历史上最黑暗的一页，日本反动统治者一次次侵略中国，1894年挑起甲午战争，1895年侵占台湾和澎湖列岛，1900年伙同其他帝国主义列强侵入北京，1904年发动日俄战争、侵犯中国东北领土和主权，1914年侵占青岛，1915年提出“二十一条”，1931年策动九一八事变、侵占中国东北全境，1935年制造华北事变，1937年7月7日以炮轰宛平县城和进攻卢沟桥为标志发动全面侵华战争，妄图变中国为其独占的殖民地，进而吞并亚洲、称霸世界。日本军国主义的野蛮侵略给中国人民造成空前巨大的灾难，激起了中国人民的顽强反抗。</p>
<p>九一八事变后，中国人民就在白山黑水间奋起抵抗，成为中国人民抗日战争的起点，同时揭开了世界反法西斯战争的序幕。七七事变后，抗击侵略、救亡图存成为中国各党派、各民族、各阶级、各阶层、各团体以及海外华侨华人的共同意志和行动，中国由此进入全民族抗战阶段，并开辟了世界反法西斯战争的东方主战场。</p>
<p>中国人民抗日战争的伟大胜利，彻底粉碎了日本军国主义殖民奴役中国的图谋，有力捍卫了国家主权和领土完整，彻底洗刷了近代以来抗击外来侵略屡战屡败的民族耻辱！</p>
<p>中国人民抗日战争的伟大胜利，重新确立了中国在世界上的大国地位，中国人民赢得了世界爱好和平人民的尊敬，中华民族赢得了崇高的民族声誉！</p>
<p>中国人民抗日战争的伟大胜利，坚定了中国人民追求民族独立、自由、解放的意志，开启了古老中国凤凰涅槃、浴火重生的历史新征程！</p>
<p>中国人民抗日战争胜利是以爱国主义为核心的民族精神的伟大胜利。</p>
<p>中国人民抗日战争胜利是中国共产党发挥中流砥柱作用的伟大胜利。</p>
<p>中国人民抗日战争胜利是全民族众志成城奋勇抗战的伟大胜利。</p>
<p>中国人民抗日战争胜利是中国人民同反法西斯同盟国以及各国人民并肩战斗的伟大胜利。</p>
<h4 id="中国成立">中国成立</h4>
<p>​ 70年前的今天，毛泽东同志在这里向世界庄严宣告了中华人民共和国的成立，中国人民从此站起来了。这一伟大事件，彻底改变了近代以后100多年中国积贫积弱、受人欺凌的悲惨命运，中华民族走上了实现伟大复兴的壮阔道路。</p>
<p>​ 前进征程上，我们要坚持中国共产党领导，坚持人民主体地位，坚持中国特色社会主义道路，全面贯彻执行党的基本理论、基本路线、基本方略，不断满足人民对美好生活的向往，不断创造新的历史伟业。</p>
<p>　　前进征程上，我们要坚持“和平统一、一国两制”的方针，保持香港、澳门长期繁荣稳定，推动海峡两岸关系和平发展，团结全体中华儿女，继续为实现祖国完全统一而奋斗。</p>
<p>　　前进征程上，我们要坚持和平发展道路，奉行互利共赢的开放战略，继续同世界各国人民一道推动共建人类命运共同体。</p>
<h4 id="改革开放"><strong>改革开放</strong></h4>
<p>党的十一届三中全会是在党和国家面临何去何从的重大历史关头召开的。当时，世界经济快速发展，科技进步日新月异，而“文化大革命”十年内乱导致我国经济濒临崩溃的边缘，人民温饱都成问题，国家建设百业待兴。党内外强烈要求纠正“文化大革命”的错误，使党和国家从危难中重新奋起。邓小平同志指出：“如果现在再不实行改革，我们的现代化事业和社会主义事业就会被葬送。”</p>
<p>党的十一届三中全会冲破长期“左”的错误的严重束缚，批评“两个凡是”的错误方针，充分肯定必须完整、准确地掌握毛泽东思想的科学体系，高度评价关于真理标准问题的讨论，果断结束“以阶级斗争为纲”，重新确立马克思主义的思想路线、政治路线、组织路线。</p>
<p>建立中国共产党、成立中华人民共和国、推进改革开放和中国特色社会主义事业，是五四运动以来我国发生的三大历史性事件，是近代以来实现中华民族伟大复兴的三大里程碑。</p>
<p>以毛泽东同志为主要代表的中国共产党人，把马克思列宁主义基本原理同中国革命具体实践结合起来，创立了毛泽东思想，团结带领全党全国各族人民，经过长期浴血奋斗，完成了新民主主义革命，建立了中华人民共和国，确立了社会主义基本制度，成功实现了中国历史上最深刻最伟大的社会变革，为当代中国一切发展进步奠定了根本政治前提和制度基础。在探索过程中，虽然经历了严重曲折，但党在社会主义革命和建设中取得的独创性理论成果和巨大成就，为在新的历史时期开创中国特色社会主义提供了宝贵经验、理论准备、物质基础。</p>
<p>　　党的十一届三中全会以后，以邓小平同志为主要代表的中国共产党人，团结带领全党全国各族人民，深刻总结我国社会主义建设正反两方面经验，借鉴世界社会主义历史经验，创立了邓小平理论，作出把党和国家工作中心转移到经济建设上来、实行改革开放的历史性决策，深刻揭示社会主义本质，确立社会主义初级阶段基本路线，明确提出走自己的路、建设中国特色社会主义，科学回答了建设中国特色社会主义的一系列基本问题，制定了到21世纪中叶分三步走、基本实现社会主义现代化的发展战略，成功开创了中国特色社会主义。</p>
<p>　　党的十三届四中全会以后，以江泽民同志为主要代表的中国共产党人，团结带领全党全国各族人民，坚持党的基本理论、基本路线，加深了对什么是社会主义、怎样建设社会主义和建设什么样的党、怎样建设党的认识，积累了治党治国新的宝贵经验，形成了“三个代表”重要思想。在国内外形势十分复杂、世界社会主义出现严重曲折的严峻考验面前，捍卫了中国特色社会主义，确立了社会主义市场经济体制的改革目标和基本框架，确立了社会主义初级阶段的基本经济制度和分配制度，开创全面改革开放新局面，推进党的建设新的伟大工程，成功把中国特色社会主义推向21世纪。</p>
<p>　　党的十六大以后，以胡锦涛同志为主要代表的中国共产党人，团结带领全党全国各族人民，坚持以邓小平理论和“三个代表”重要思想为指导，根据新的发展要求，深刻认识和回答了新形势下实现什么样的发展、怎样发展等重大问题，形成了科学发展观，抓住重要战略机遇期，在全面建设小康社会进程中推进实践创新、理论创新、制度创新，强调坚持以人为本、全面协调可持续发展，形成中国特色社会主义事业总体布局，着力保障和改善民生，促进社会公平正义，推动建设和谐世界，推进党的执政能力建设和先进性建设，成功在新的历史起点上坚持和发展了中国特色社会主义。</p>
<p>​ 党的十八大以来，党中央团结带领全党全国各族人民，全面审视国际国内新的形势，通过总结实践、展望未来，深刻回答了新时代坚持和发展什么样的中国特色社会主义、怎样坚持和发展中国特色社会主义这个重大时代课题，形成了新时代中国特色社会主义思想，坚持统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局</p>
<p>始终坚持解放思想、实事求是、与时俱进、求真务实，坚持马克思主义指导地位不动摇，坚持科学社会主义基本原则不动摇</p>
<p>始终坚持以经济建设为中心，不断解放和发展社会生产力</p>
<p>始终坚持中国特色社会主义政治发展道路，不断深化政治体制改革，发展社会主义民主政治</p>
<p>始终坚持发展社会主义先进文化，加强社会主义精神文明建设，培育和践行社会主义核心价值观，传承和弘扬中华优秀传统文化</p>
<p>始终坚持在发展中保障和改善民生，全面推进幼有所育、学有所教、劳有所得、病有所医、老有所养、住有所居、弱有所扶，不断改善人民生活、增进人民福祉。</p>
<p>始终坚持保护环境和节约资源，坚持推进生态文明建设</p>
<p>始终坚持党对军队的绝对领导，不断推进国防和军队现代化</p>
<p>始终坚持推进祖国和平统一大业，实施“一国两制”基本方针，相继恢复对香港、澳门行使主权，洗雪了中华民族百年屈辱</p>
<p>始终坚持独立自主的和平外交政策，始终不渝走和平发展道路、奉行互利共赢的开放战略</p>
<p>始终坚持加强和改善党的领导</p>
<p>改革开放40年积累的宝贵经验是党和人民弥足珍贵的精神财富，对新时代坚持和发展中国特色社会主义有着极为重要的指导意义。改革开放40年积累的宝贵经验是党和人民弥足珍贵的精神财富，对新时代坚持和发展中国特色社会主义有着极为重要的指导意义.第二，必须坚持以人民为中心，不断实现人民对美好生活的向往。第三，必须坚持马克思主义指导地位，不断推进实践基础上的理论创新。第四，必须坚持走中国特色社会主义道路，不断坚持和发展中国特色社会主义。第五，必须坚持完善和发展中国特色社会主义制度，不断发挥和增强我国制度优势。第六，必须坚持以发展为第一要务，不断增强我国综合国力。第七，必须坚持扩大开放，不断推动共建人类命运共同体。第八，必须坚持全面从严治党，不断提高党的创造力、凝聚力、战斗力。第九，必须坚持辩证唯物主义和历史唯物主义世界观和方法论，正确处理改革发展稳定关系。</p>
<h4 id="抗美援朝">抗美援朝</h4>
<p>1950</p>
<p>70年前，由中华优秀儿女组成的中国人民志愿军，肩负着人民的重托、民族的期望，高举保卫和平、反抗侵略的正义旗帜，雄赳赳、气昂昂，跨过鸭绿江，发扬伟大的爱国主义精神和革命英雄主义精神，同朝鲜人民和军队一道，历经两年零9个月艰苦卓绝的浴血奋战，赢得了抗美援朝战争伟大胜利。</p>
<p>伟大的抗美援朝战争，抵御了帝国主义侵略扩张，捍卫了新中国安全，保卫了中国人民和平生活，稳定了朝鲜半岛局势，维护了亚洲和世界和平。</p>
<p>抗美援朝战争，是在交战双方力量极其悬殊条件下进行的一场现代化战争。当时，中美两国国力相差巨大。在这样极不对称、极为艰难的情况下，中国人民志愿军同朝鲜军民密切配合，首战两水洞、激战云山城、会战清川江、鏖战长津湖等，连续进行5次战役，此后又构筑起铜墙铁壁般的纵深防御阵地，实施多次进攻战役，粉碎“绞杀战”、抵御“细菌战”、血战上甘岭，创造了威武雄壮的战争伟业。</p>
<p>最终用伟大胜利向世界宣告“西方侵略者几百年来只要在东方一个海岸上架起几尊大炮就可霸占一个国家的时代是一去不复返了”！</p>
<p>抗美援朝战争伟大胜利，是中国人民站起来后屹立于世界东方的宣言书，是中华民族走向伟大复兴的重要里程碑，对中国和世界都有着重大而深远的意义。</p>
<p>经此一战，中国人民粉碎了侵略者陈兵国门、进而将新中国扼杀在摇篮之中的图谋，</p>
<p>经此一战，中国人民彻底扫除了近代以来任人宰割、仰人鼻息的百年耻辱，彻底扔掉了“东亚病夫”的帽子，</p>
<p>经此一战，中国人民打败了侵略者，震动了全世界，奠定了新中国在亚洲和国际事务中的重要地位</p>
<p>经此一战，人民军队在战争中学习战争，愈战愈勇，越打越强，取得了重要军事经验</p>
<p>经此一战，第二次世界大战结束后亚洲乃至世界的战略格局得到深刻塑造，全世界被压迫民族和人民争取民族独立和人民解放的正义事业受到极大鼓舞，有力推动了世界和平与人类进步事业。</p>
<p>无论时代如何发展，我们都要砥砺不畏强暴、反抗强权的民族风骨。</p>
<p>无论时代如何发展，我们都要汇聚万众一心、勠力同心的民族力量。</p>
<p>无论时代如何发展，我们都要锻造舍生忘死、向死而生的民族血性。</p>
<p>无论时代如何发展，我们都要激发守正创新、奋勇向前的民族智慧。</p>
<p>铭记伟大胜利，推进伟大事业，必须坚持中国共产党领导，把党锻造得更加坚强有力。</p>
<p>铭记伟大胜利，推进伟大事业，必须坚持以人民为中心，一切为了人民、一切依靠人民</p>
<p>铭记伟大胜利，推进伟大事业，必须坚持推进经济社会发展，不断壮大我国综合国力。</p>
<p>铭记伟大胜利，推进伟大事业，必须加快推进国防和军队现代化，把人民军队全面建成世界一流军队。</p>
<p>铭记伟大胜利，推进伟大事业，必须维护世界和平和正义，推动构建人类命运共同体。</p>
<h4 id="校邠庐抗议">《校邠庐抗议》</h4>
<p>《校邠庐抗议》是一部政论集，也是近代思想家<a href="https://baike.baidu.com/item/冯桂芬/1453159">冯桂芬</a>的代表作。作者针对清<a href="https://baike.baidu.com/item/咸丰/653">咸丰</a>朝以后的社会大变动，以及当时科技水平落后于西方国家的状况，向当权者提出了一系列改革方案。冯桂芬写定《校邠庐抗议》时，正是中国在<a href="https://baike.baidu.com/item/第二次鸦片战争/282781">第二次鸦片战争</a>中战败，《北京条约》签订以后。《北京条约》包括增开通商口岸、外国使臣驻京、赔偿巨款、传教士传教自由等众多条款，是中国对外被迫妥协、丧失大量主权的不平等条约。冯桂芬以“校邠”为“庐”名，以《校邠庐抗议》为书名，似含有对清廷一味妥协外交政策的不满之意。</p>
<h4 id="三座大山">三座大山</h4>
<p>帝国主义、封建主义、官僚资本主义。推翻三座大山，是新民主主义革命的主要任务。</p>
<p>新民主主义革命的基本目标是建立工人阶级领导的工农联盟为基础人民民主专政的人民共和国</p>
<p>资本—帝国主义，涵盖自由竞争阶段的资本主义和垄断阶段的资本主义即帝国主义</p>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112271127525.png" alt="image-20211227112714401" style="zoom:50%;" /></p>
<h4 id="近代社会的主要矛盾和两大历史任务">近代社会的主要矛盾和两大历史任务</h4>
<p>帝国主义与中华民族的矛盾是最主要的矛盾(最主要)</p>
<p>封建主义和人民大众的矛盾</p>
<p>使中国人民过上幸福、富裕的生活，就必须推翻帝国主义、封建主义联合统治的半殖民地半封建的社会制度，争得民族独立和人民解放</p>
<h4 id="领事裁判权">领事裁判权</h4>
<p>资本-帝国主义列强在中国还享有领事裁判权| 1843年中英《五口逋商章程》规定，在通商口岸，中国人如与英侨“遇有交涉诉讼”，英国领事有“查察”“听诉”之权，英人如何科罪，由英国议定章程、法律，发给管事官照办</p>
<p>1844年中美《望厦条约》更扩大领事裁判权的范围，即所有美国人在华之一切民事、刑事诉讼，均由美国领事等官询明办理，从把持中国海关，是外国侵略者控制中国政治的重要手段之一：近代中国海关的职权范围，除了征收进出口关税外，还管理港口，主办邮政，县至涉及与外国人交涉的各种事务：中国海关的高级职员全部由外国人充任。</p>
<p>操纵中国的经济命脉,在中国的近代工业中,外国资本很快形成了垄断地位,资本-帝国主义列强不仅勒索中国的赔款，而且迫使中国举借外债来偿付这些赔款,外国资本在中国设立的银行，是它们对中国进行资本输出的枢纽,资本-帝国主义列强还控制了中国的现代交通运输,资本-帝国主义的经济侵略不仅阻碍中国民族工商业的发展，而且对中国的农业经济也造成严重破坏,帝国主义者为了制造侵略有理的舆论，还大肆宣扬“种族优劣论</p>
<h4 id="列强瓜分中国图谋破产">列强瓜分中国图谋破产</h4>
<p>列强瓜分中国图谋破产的主要原因在于帝国主义列强的矛盾和互相制约，最根本的原因，是中华民族进行的不屈不挠的反侵略斗争,其中1900年前后兴起的义和团就是一个突出的例子。尽管义和团在粉碎帝国列强瓜分中国的斗争中发挥了重大历史作用，但是，义和团内部也存在排他主义错误、蒙受封建主义欺骗，存在迷信、欺骗的倾向。</p>
<h4 id="反侵略战争失败以及原因">反侵略战争失败以及原因</h4>
<p>社会制度的腐败，经济技术的落后。</p>
<p>但是决定因素是人不是物，武器装备十分落后，而且反动统治阶级压制人民群众的动员。</p>
<h4 id="慈禧">慈禧</h4>
<p>慈禧大后寿辰，恰好是日军攻陷大连之口：慈禧太后却照样在宫中升殿受贺，大宴群中，还让皇帝与大臣们陪坐听戏二日，不问国事:，指挥战争的李鸿章为了迎合慈禧并保存自己控制的北洋海军和淮军的实力，消极避 战，积极求和':清政府还卜令不许接济和支援台湾军民的浴血抗战」在这种情况下，中日甲午战争最后只能以中国的失败而告终，八国联军侵华战争开始以后，以慈禧太后为首的清政府守旧派虽然一度想利用义和团的力量与列强讨价还价及排斥异己,实际匕却一百在背后牵制、破坏义和团和部分清军官兵与八国联军的战斗</p>
<p>镇压义和团</p>
<p>戊戌政变</p>
<p>封建守旧势力的代表</p>
<p>1901年《辛丑条约》的签订，标志着以慈禧太后为首的清政府已经 彻底放弃了抵抗外国侵略者的念头，甘当“洋人的朝廷”；</p>
<h4 id="李鸿章">李鸿章</h4>
<p><strong>有才气而无学识，有阅历而无血性”，他说“敬李鸿章之才”，“惜李鸿章之识”，“悲李鸿章之遇”。</strong></p>
<p>洋务运动</p>
<p>甲午战争失败</p>
<h4 id="魏源-海国图志">魏源 海国图志</h4>
<p>在《海国图志》中，魏源提出了 “师夷长技以制夷”的思想，主张学习外国先进的军事和科学技术，以 期富国强兵，抵御外国侵略。</p>
<h4 id="严复-天演论">严复 天演论</h4>
<p>严复翻译了《天演论）（1898年正式出版）：他用“物竞大择”“适者生存”的社会进化论思想，为这种危机意识和民族意识提供了理论根据</p>
<h4 id="太平天国-天朝田亩制度">太平天国 天朝田亩制度</h4>
<p>太平天国定都夫京后，进行了一系列制度建设，并颁布了《大朝田亩制制度》和《资政新篇》</p>
<p>《大朝田亩制制度》它确立了平均分配土地的方案，</p>
<p>太平天国的领导者们希望通过施行这样的方案，建立“有田同耕，有饭同食,有衣同穿，有钱同使，无处不均匀，无人不饱暖”的理想社会。</p>
<p>是对以往农民战争中“均贫富”“等贵贱”和“均平”“均山”思想的发展和超越</p>
<p>具有进步意义，不过,它并没有超出农民小牛产者的狭隘眼界，，住很大程度匕具有不切实际的空想性，平分土地的政策即使在天平天国区域也没有实现</p>
<h4 id="太平天国-资政新篇">太平天国 资政新篇</h4>
<p>《资政新篇》是太平天国'后期颁布的社会发展</p>
<p>加强中央集权，并学习西方，在经济方面，主张发展近代丁.矿、交通、邮政、银行等事业，奖励科技发明和机器制造，在文化方面，建议设立新闻馆以报时事，破除陈规陋俗，提倡兴办学校、医院和社会福利，在外交方面，主张同外国平等交往、白由通商，《资政新篇》是一个具有资本主义色彩的方案</p>
<h4 id="太平天国失败的原因">太平天国失败的原因</h4>
<p>农民阶级不是新的生产力和牛产关系的代表，无法从根本上提出完整的、正确的政治纲领和社会改革方案</p>
<p>太平天国后期无法制止和克服领导集团自身腐败现象的滋生，领导集的一些人在生活上追求享乐，在政治上争权夺利</p>
<p>太平天国军事战略上出现了重大失误</p>
<p>拜上帝教教义不仅不能正确指导斗争，而且给农民战争带来了危害。</p>
<p>太平夭国也未能正确地对待儒学。</p>
<p>们对于西方资本主义侵略者还缺乏理性的认识。</p>
<h4 id="洋务运动李鸿章">洋务运动（李鸿章）</h4>
<p>兴办近代企业——军用工业、民用企业；</p>
<p>建立新式海陆军——福建水师、广东水师、南洋水师和北洋水师</p>
<p>创办新式学堂，派遣留学生</p>
<p>在客观上对中国的早期工业和民族资本主义的发展起了某些促进作用。但是，洋务派兴办洋务新政，主要是为了维护封建统治，并不是要使中国朝着独立的资本主义方向发展。</p>
<p>洋务运动失败的原因在于其封建性、对列强的依赖性、洋务企业管理的腐朽性</p>
<h4 id="维新运动-康有为梁启超">维新运动 （康有为、梁启超）</h4>
<p>在此后的103天中，接连发布了一系列推行新政的政令，史称“戊成变 法”，又称“百日维新'</p>
<p>政治方面：改革行政机构，裁撤闲散、重叠机构</p>
<p>经济方面：保护、奖励农工商业和交通采矿业，中央设立农工商总局 与铁路矿务总局，各省设立商务局；提倡开办实业，奖励发明创造；注重 农业发展，提倡西法垦殖，建立新式农场；广办邮政，修筑铁路；开办商 学、商报，设立商会等各类组织；改革财政，编制国家预决算。</p>
<p>军事方面：裁减旧式绿营兵，改练新式陆军；采用西洋兵制</p>
<p>文化教育方面：创设京师大学堂，各省书院改为高等学堂，在各地设 立中、小学堂；提倡西学，废除八股，改试策论，开经济特科；</p>
<p>温和的不彻底的改革</p>
<p>遭到了封建守旧势力的激烈反对戊戌维新运动宣告失败。以慈禧太后为首的保守势力扼杀维新变法 的政变，史称“戊戌政变”。</p>
<p>戊戌维新运动是一次爱国救亡运动，救亡图存</p>
<p>戊戌维新运动是一场资产阶级性质的政治改良运动，“中体西用”思想的局限，主张用君主立宪制取代君主专制制度</p>
<p>戊戌维新运动更是一场思想启蒙运</p>
<p>不敢否定封建主义、对帝国主义有幻想、不敢拥抱人民群众</p>
<h4 id="辛亥革命-1">辛亥革命</h4>
<p>1901年《辛丑条约》的签订，标志着以慈禧太后为首的清政府已经彻底放弃了抵抗外国侵略者的念头，甘当“洋人的朝廷”；</p>
<p>1901年4月，宣布实行新政。预备立宪并没有能够挽救清王朝，反而激化了社会矛盾，加重了危机</p>
<p>孙中山领导的同盟会不仅提出了革命纲领，而且进行实际的革命活动，先后发动了多次武装起义，黄花岗起义</p>
<p>爆发的导火索在于保路运动，铁路干线收归国有，借“国有”名义把铁路利权出卖给帝国主义，同时借此“劫夺”商股。这激起了湖北、湖南、广东、四川四省的保 路风潮</p>
<p>武昌起义掀起了辛亥革命的高潮，打开了清王朝统治的缺口</p>
<p>中华民国临时政府宣告成立1911年底，孙中山从海外回到上海』 “独立”各省的代表在南京选举孙中山为临时大总统’1912年1月1日， 孙中山在南京宣誓就职，改国号为中华民国，定1912年为民国元年，并 成立中华民国临时政府。 南京临时政府是一个资产阶级共和国性质的革命政权</p>
<p><strong>辛亥革命的历史意义：</strong></p>
<p>辛亥革命推翻了封建势力的政治代表、帝国主义在中国的代理人清王朝的统治，沉重打击了中外反动势力，辛亥革命结束了中国延续两千多年的封建君主专制制度，辛亥革命结束了中国延续两千多年的封建君主专制制度，辛亥革命推动了中国的社会变革，促使中国的社会经济、思想习惯和社会风俗等方面发生了新的积极变化。辛亥革命不仅在一定程度上打击了帝国主义的侵略势力，而且推动了亚洲各国民族解放运动的高涨。</p>
<p>袁世凯窃国，辛亥革命流产</p>
<p><strong>失败原因：</strong></p>
<p>第一，没有提出彻底的反帝反封建的革命纲领。</p>
<p>第二，不能充分发动和依靠人民群众。</p>
<p>笫二，不能建立坚强的革命政党</p>
<p>资产阶级革命派的这些弱点、错误，根源于中国民族资产阶级的软弱性和妥协</p>
<h4 id="三民主义">三民主义</h4>
<p>康有为、梁启超坚持反对用革命手段推翻清朝统治，属于是改良派</p>
<p>同盟会的政治纲领是“驱除鞑虏，恢复中华，创立民国，平均地权</p>
<p>没有从正面鲜明地提出反对帝国主义的主张</p>
<p>民族主义：驱除鞑虏，恢复中华，以革命手段推翻清朝政府，建立中华民族“独立的国家</p>
<p>民权主义：创立民国，推翻封建君主专制制度，建立资产阶级民主共和国。政治革命。</p>
<p>民生主义：平均地权，社会革命</p>
<h4 id="北洋军阀">北洋军阀</h4>
<p>在政治上，北洋政府实行军阀官僚的专制统治</p>
<p>为了达到专制独裁的目的，袁世凯公然进行帝制复辟活动</p>
<p>在经济上，北洋政府竭力维护帝国主义、地主阶级和买办资产阶级的利益</p>
<p>尊孔复占思潮猖獗一时</p>
<h4 id="新文化运动">新文化运动</h4>
<p>从1915年9月陈独秀在上海创办《青年杂志》（后改名 《新青年》）开始的0</p>
<p>护“德先生”坦以）和“赛先生” （既血1建），即提倡民主和科学</p>
<h4 id="十月革命">十月革命</h4>
<p>十月革命发生在其国情与中国相同（封建压迫严重）或近似（经济文化落后）的俄国</p>
<p>二十月革命诞生的社会主义俄国号召反对帝国主义，并以新的平等的态度对待中国，有力推动了社会上义思想在中国的传播</p>
<p>十月革命中俄国工人、农民和士兵群众的广泛发动并由此赢得胜利的事实，给「中国先进分,新的革命方法的启示</p>
<p>率先举起马克思主义旗帜的，是李大钊:《我的马克思主义观》</p>
<h4 id="五四运动新民主主义革命的开端">五四运动：新民主主义革命的开端</h4>
<p>背景：</p>
<p>新的社会力量的成长、壮大</p>
<p>新文化运动掀起的思想解放的潮流</p>
<p>俄国十月革命对中国的影响</p>
<p>五四运动的直接导火线，是巴黎和会上中国外交的失败</p>
<p>意义:</p>
<p>五四运动是中国旧民主主义革命走向新民主主义革命的转折,</p>
<p>五四运动孕育了以爱国、进步、民主、科学为主要内容的伟大五四精神，其核心是爱国主义,实现了中国人民和中华民族自鸦片战争以来的第一次全面觉醒：</p>
<h4 id="中国共产党成立的历史意义">中国共产党成立的历史意义</h4>
<p>中国共产党一经成立，就把实现共产主义作为党的最高理想和最终目标，义无反顾肩负起实现中华民族伟大复兴的历史使命,深刻改变了近代以后中华民族发展的方向和进程，深刻改变了中国人民和中华民族的前途和命运，深刻改变了世界发展 的趋势和格局。没有先进的坚强的政党作为凝聚力量的核心。</p>
<h4 id="新三民主义">新三民主义</h4>
<p>“新三民主义”。其在民族主义中突出了反对帝国 主义的内容；在民权主义中强调民主权利应“为一般平民所共有”；把民 生主义概括为“平均地权”和“节制资本”两大原则(后来乂提出“耕者 有其田”〔的主张人</p>
<h4 id="大革命">大革命</h4>
<p>是由于反革命力量强大，资产阶级发生严重动摇,汪精卫、蒋介石先后叛变革命；是由于中共中央领导机关在大革命后期犯了右倾机会主义错误，放弃了无产阶级对于农民群众、城市小资产阶级和民族资产阶级的领导</p>
<p>是由于这时的中国共产党还处在幼年时期，缺乏应对复杂环境的政治经验,缺乏对中国社会和中国革命基本问题的深刻认识，还不善于将马克思列宁主义基本原理同中国革命的具体实际结合起来</p>
<h4 id="武装反抗国民党反动派">武装反抗国民党反动派</h4>
<p>1927中央在汉口秘密召开紧急会议(即八七会议)，会议确定了土地革命和武装起义的方针</p>
<p>八七会议给正处在思想混乱和组织涣散中的中国共产党指明了新的出路，这是由大革命失败到土地革命战争兴起的历史性转变也</p>
<p>秋收起义 9.9</p>
<p>三湾改编 9.29</p>
<h4 id="井冈山根据地">井冈山根据地</h4>
<p>点燃了工农武装割据的星星之火，为中国革命开辟出了农村包围城市、武装夺取政权这样一条前人没有走过的正确道路。大革命失败后，中国共产党人正是沿着这条独特的道路，引导中国革命走向复兴并逐步赢得胜利的0</p>
<p>《中国的红色政权为什么能够存在？》和《井冈山的斗争》</p>
<p>在《星星之火，可以燎原》</p>
<p>《反对本本主义》一文中，提出“没有调查，没有发言权” 1和“中国革命斗争的胜利要靠中国同志了解中国情况”</p>
<h4 id="古田会议">古田会议</h4>
<p>思想建党，政治建军</p>
<p>创造性地解决了在农村环境中、在党组织和军队以农民为主要成分的条件 下，如何保持党的无产阶级先锋队性质和建设党领导的新型人民军队的电</p>
<h4 id="遵义会议">遵义会议</h4>
<p>遵义会议是党的历史上一个生死攸关的转折点。这次会议事实上确立 了毛泽东在党中央和红军的领导地位</p>
<p>开始形成以毛泽东同志为核心的第一代中央领导集体，在最危急关头挽救了党、挽救了红军、挽救了中国革命。遵义会议的鲜明特点是坚持真理、修正错误，确立党中央的正确领导，创造性地制定和实施符合中国革命特点的战略策领导，创造性地制定和实施符合中国革命特点的战略策略。遵义会议开启了中国共产党独立自主解决中国革命实际问题的新阶段</p>
<h4 id="长征胜利的意义">长征胜利的意义</h4>
<p>中国工农红军长征是一次理想信念的伟大远征，是一次检验真理的伟 大远征，是一次唤醒民众的伟大远征，是一次开创新局的伟大远征。 长征的胜利，极大地促进了党在政治上和思想上的成熟-中国共产党 进一步认识到，只有把马克思主义基本原理同中国革命具体实际结合起 来，独立自主解决中国革命的重大问题，才能把革命乎业引向胜利： 长征的胜利，是中国革命转危为安的关键：</p>
<p>这宣告了国民党反动派消灭中国共产党和红军的图谋彻底失败，宣 告了中国共产党利红军肩负着民族希望胜利实现了北上抗日的战略转移， 实现了中国共产党和中国革命事业从挫折走向胜利的伟大转折，开启了中 国共产党为实现民族独立、人民解放而斗争的新的伟大进军一 长征铸就了伟大的氏征精神，这就是：把全国人民和中华民族的根木 利益看得高于一切，坚定革命的理想和信念，坚信正义事业必然胜利的精 神；为了救国救民，不怕任何艰难险阻，不惜付出一切牺牲的精神；坚持 独立自主、实事求是，一切从实际出发的精神；顾全大局、严守纪律、紧 密团结的精神；紧紧依靠人民群众，同人民群众生死相依、患难与共、艰 苦奋斗的精神，氏征精神为中国革命不断从胜利走向胜利提供了强大精神 动力</p>
<h4 id="抗日战争">抗日战争</h4>
<p>1931.7 九一八事变 蒋介石 攘外必先安内</p>
<p>1937.7.7 七七（卢沟桥）事变 全面侵华</p>
<p>日军罪状：屠杀、掠夺资源财富、奴化教育、摧残文化</p>
<p>1935 政治局扩大会议 反对内战 12.9运动 学生游行</p>
<p>1936 西安事变</p>
<p>抗日民族政权 —— 三三制 共产党、党外进步、中间派 1/3</p>
<p>1938 六届六中全会 马克思主义中国化</p>
<h4 id="抗日战争胜利原因及意义">抗日战争胜利原因及意义</h4>
<p>以爱国主义为核心的民族精神是中国人民抗日战争胜利的决定因</p>
<p>中国共产党的中流砥柱作用是中国人民抗日战争胜利的关键。</p>
<p>同世界所有爱好和平和正义的国家人民、国际组织以及各种反法西斯力量的同情和支持也是分不开的</p>
<p>全民抗战</p>
<p>意义：</p>
<p>是中华民族从近代以来陷入深重危机走向伟大复兴的历史转折点。为赢得新民主主义革命胜利，奠定了重要基础</p>
<h4 id="重庆谈判">重庆谈判</h4>
<p>双十协定、长期合作、坚决避免内战、和平建国</p>
<h4 id="土地革命">土地革命</h4>
<p>废除封建性及半封建性剥削的土地制度，实行耕者有其田的土地制度”</p>
<h4 id="抗美援朝战争胜利的意义">抗美援朝战争胜利的意义</h4>
<p>是中华民族走向伟大复兴的重要里程碑</p>
<p>经此一战，新中国真正站稳了脚跟</p>
<p>中国人民真正扬眉吐气了，彰显了新中国的大国地位，极大促进了国防和军队现代化，有力推动了世界和平与人类进步事业:</p>
<h4 id="过渡时期总路线">过渡时期总路线</h4>
<p>在一个相当长的时期内，逐步实现国家的社会主义工业化，并逐步实现国家对 农业、对手工业和对资本主义工商业的社会主义改造，一化三改</p>
<p>反映了历史的必然性</p>
<ul>
<li>社会主义工业化是国家独立富强的首要条件</li>
<li>第二，资本主义经济力量弱小，发展困难，不可能成为中国工业起 飞的基础</li>
<li>第二，对个体农业进行社会主义改造，是保证工业发展、实现国家工 业化的一个必要条件。</li>
<li>第四，当时的国际环境也促使中国选择社会主义。</li>
</ul>
<h4 id="一五计划">一五计划</h4>
<p>“一五”计划确定的经济建设指导方针，突出了集中主要力景发展重 工业，建立国家工业化和国防现代化的初步基础的核心要点，</p>
<p>，相应地培养建设人才，保证国民经济中社会主义成分的比重稳步增长，保证在发展生产的基础上逐步提高人民的物质生活和文化生活的水平</p>
<h4 id="社会主义基本制度的确立">社会主义基本制度的确立</h4>
<p>随着社会主义改造的完成，以生产资料公有制、按劳分配和计划经济 体制为特征的社会主义经济制度建立起来，这是中国进入社会主义社会最 主要的标志</p>
<p>1954 中华人民共和国宪法 确立人民代表大会制度，“中华人民共和国是工人阶级领导的、以工农联盟为基础的人民民主国家。</p>
<p>人民代表大会的根本政治制度、中国共产党领导的多党合作和政治协 商制度、民族区域日治制度等基本政治制度的建</p>
<p>意义：</p>
<ul>
<li><p>社会主义基本制度的确立极大地提高了工人阶级和广大劳动人社会主义基本制度的确立极大地提高了工人阶级和广大劳动人</p></li>
<li><p>社会主义基本制度的确立为当代中国的一切发展进步提供了根 本政治保障</p></li>
<li><p>社会主义基本制度的确立为社会主义先进文化的发展指明了前 进方</p></li>
</ul>
<h4 id="全面建设社会主义的开始">全面建设社会主义的开始</h4>
<p>有一个如何把马克思列宁主义基本原理同中国具体实际相结合的问题 毛泽东明确提出： “最重要的是要独立思考，把马列主义的基本原理同中国革命和建设的具 体实际相结合。民主革命时期，我们吃了大亏之后才成功地实现了这种结</p>
<p>合，取得了新民主主义革命的胜利。现在是社会主义革命和 建设时期，我们要进行第二次结合，找出在中国怎样建设社 会主义的道路</p>
<h4 id="中共八大">中共八大</h4>
<p>1956</p>
<p>八大正确分析了国内形势和主要矛盾的变化，明确提出 新形势下党和人民的主要任</p>
<p>是人民对于经济文化迅速发展的需要同当前经济文化不能满足人民需要的状况之间的矛盾，全国人民的主要任务是集中力量发展社会生产力，实现国家工业化</p>
<p>八大坚持党中央提出的既反保守又反冒进，即在综合平衡中稳步前进 的经济建设方针。</p>
<p>八大通过的新党章是中国共产党在全国执政以后制定的第一部党章。</p>
<h4 id="四个现代化">四个现代化</h4>
<p>在不太长的历史时期内，把我国建设成为一个具有现代农业、现代工业、现代国防和现代科学技术的社会主义强国，赶上和超过世界先进水平</p>
<h4 id="文化大革命">文化大革命</h4>
<p>教训：</p>
<ul>
<li>一是必须科学对待马克思列宁主义，准确把握中国基本国情</li>
<li>是必须正确认识社会主义社会的主要矛盾和 党和国家的主要任务，集中力量发展生产力</li>
<li>三是必须改革和完善党和国家的领导制度，健全民主集中制和集体领导原则。</li>
<li>四是必须发展社会主义民主，加强社会主义法制</li>
<li>五是必须制定正确的党的建设的方针和政策,不断加强执政党的建设</li>
</ul>
<h4 id="两个凡是">两个凡是</h4>
<p>“凡是毛主席作出的决策，我们都坚决维护，凡是毛主席的指示，我们都始终不渝地遵循</p>
<h4 id="中共十一届三中全会">中共十一届三中全会</h4>
<p>1978</p>
<p>党的十一届二中全会在北京召开二全会 冲破长期“左”的错误的严重束缚，彻底否定“两个凡是”的错误方针， 高度评价关于真理标准问题的讨论，果断停止使用“以阶级斗争为纲”的 口号，决定从1979年1月起把全党的工作重心转移到社会主义现代化建 设上来。全会提出了改革开放的任务。指出，实现四个现代化是一场广 泛、深刻的革命。要采取一系列新的重大的经济措施，对经济管理体制和 经营管理方法进行认真的改革，在自力更生的基础上积极发展同世界各国 平等互利的经济合作。</p>
<p>党的十一届三中全会的胜利召开，结束了粉碎“四人帮”后党和国家 工作在徘徊中前进的局面，标志着中国共产党重新确立了马克思主义的思 想路线、政治路线、组织路线，实现了新中国成立以来党的历史上具有深 远意义的伟大转折，开启了我国改革开放和社会主义现代化建设新时期。 全会作出实行改革开放的历史性决策，是基于对党和国家前途命运的深刻 把握，是基于对社会主义革命和建设实践的深刻总结，是基于对时代潮流 的深刻洞察，是基于对人民群众期盼和需要的深刻体悟。</p>
<p>从这次全会开始，改革开放和开创中国特色社会主义的大幕拉 开，邓小平理论也逐步形成和发展起来</p>
<h4 id="坚持四项基本原则">坚持四项基本原则</h4>
<p>1979</p>
<p>邓小平在党的理论工作务虚会上发表《坚持四项基本原则》的讲话。他指出：坚持社会主义道路，坚持人民民主专政，坚持共产党的领导，坚持马克思列宁主义、 毛泽东思想这四项基本原则，“是实现四个现代化的根本前提</p>
]]></content>
  </entry>
  <entry>
    <title>近代史讲话文献</title>
    <url>/2021/12/26/%E8%BF%91%E4%BB%A3%E5%8F%B2%E7%B4%A7%E6%80%A5%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="文献内容">文献内容</h4>
<p><img src="https://gitee.com/DespairL/typora-drawing-bed/raw/master/202112262213393.png" alt="image-20211226221327238" style="zoom: 25%;" /></p>
<h4 id="习近平在纪念毛泽东同志诞辰120周年座谈会上的讲话">习近平在纪念毛泽东同志诞辰120周年座谈会上的讲话</h4>
<p>同志们，朋友们：</p>
<p>　　今天，我们怀着十分崇敬的心情，在这里隆重集会，纪念中国共产党、中国人民解放军、中华人民共和国的主要缔造者，中国各族人民的伟大领袖毛泽东同志诞辰120周年。</p>
<p>　　毛泽东同志是伟大的马克思主义者，伟大的无产阶级革命家、战略家、理论家，是马克思主义中国化的伟大开拓者，是近代以来中国伟大的爱国者和民族英雄，是党的第一代中央领导集体的核心，是领导中国人民彻底改变自己命运和国家面貌的一代伟人。</p>
<span id="more"></span>
<p>　　毛泽东同志等老一辈革命家，都是从近代以来中国历史发展的时势中产生的伟大人物，都是从近代以来中国人民抵御外敌入侵、反抗民族压迫和阶级压迫的艰苦卓绝斗争中产生的伟大人物，都是走在中华民族和世界进步潮流前列的伟大人物。</p>
<p>　　中华民族，具有5000多年绵延不绝的文明历史，为人类文明进步作出了不可磨灭的贡献。但是，由于封建制度的腐朽没落，中国在近代被世界快速发展的浪潮甩在了后面。1840年鸦片战争以后，在西方列强坚船利炮轰击下，中国危机四起、人民苦难深重，陷入半殖民地半封建社会的黑暗深渊。</p>
<p>　　实现中华民族伟大复兴始终是近代以来中国人民最伟大的梦想。无数志士仁人前仆后继、不懈探索，寻找救国救民道路，却在很长时间内都抱憾而终。太平天国运动、戊戌变法、义和团运动、辛亥革命接连而起，但农民起义、君主立宪、资产阶级共和制等种种救国方案都相继失败了。战乱频仍，民生凋敝，丧权辱国，成了旧中国长期无法消除的病疠。</p>
<p>　　中华民族是一个有志气的民族。为了探求救亡图存的正确道路，中国的先进分子带领中国人民始终坚持在苦难和挫折中求索、在风雨飘摇中前进，敢于挽狂澜于既倒、扶大厦之将倾，表现出了百折不挠的英雄气概。</p>
<p>　　毛泽东同志在青年时期就立下拯救民族于危难的远大志向。1919年，毛泽东同志在《〈湘江评论〉创刊宣言》中写道：“时机到了！世界的大潮卷得更急了！洞庭湖的闸门动了，且开了！浩浩荡荡的新思潮业已奔腾澎湃于湘江两岸了！顺他的生，逆他的死。”年轻的毛泽东同志，“书生意气，挥斥方遒。指点江山，激扬文字”，既有“问苍茫大地，谁主沉浮”的仰天长问，又有“到中流击水，浪遏飞舟”的浩然壮气。</p>
<p>　　十月革命一声炮响，给中国送来了马克思列宁主义。从纷然杂陈的各种观点和路径中，经过反复比较和鉴别，毛泽东同志毅然选择了马克思列宁主义，选择了为实现共产主义而奋斗的崇高理想。在此后的革命生涯中，不管是“倒海翻江卷巨澜”，还是“雄关漫道真如铁”，毛泽东同志始终都矢志不移、执着追求。</p>
<p>　　马克思列宁主义，为中国人民点亮了前进的灯塔；1921年中国共产党的成立，使中国人民有了前进的主心骨。</p>
<p>　　然而，在一个半殖民地半封建的东方大国进行革命，面对的特殊国情是农民占人口的绝大多数，落后分散的小农经济、小生产及其社会影响根深蒂固，又遭受着西方列强侵略和压迫，经济文化十分落后，选择一条什么样的道路才能把中国革命引向胜利成为首要问题，也是马克思主义发展史上前所未有过的难题。年轻的中国共产党，一度简单套用马克思列宁主义关于无产阶级革命的一般原理和照搬俄国十月革命城市武装起义的经验，中国革命遭受到严重挫折。</p>
<p>　　从革命斗争的这种失误教训中，毛泽东同志深刻认识到，面对中国的特殊国情，面对压在中国人民头上的三座大山，中国革命将是一个长期过程，不能以教条主义的观点对待马克思列宁主义，必须从中国实际出发，实现马克思主义中国化。毛泽东同志创造性地解决了马克思列宁主义基本原理同中国实际相结合的一系列重大问题，深刻分析中国社会形态和阶级状况，经过不懈探索，弄清了中国革命的性质、对象、任务、动力，提出通过新民主主义革命走向社会主义的两步走战略，制定了新民主主义革命总路线，开辟了以农村包围城市、最后夺取全国胜利的革命道路。毛泽东同志创造性地解决了在中国这种特殊的社会历史条件下建设马克思主义政党的一系列重大问题，把党建设成为用科学理论和革命精神武装起来的、同人民群众有着血肉联系的、思想上政治上组织上完全巩固的马克思主义政党。毛泽东同志创造性地解决了缔造一个在党的绝对领导下的人民武装力量的一系列重大问题，建成一支具有一往无前精神、能压倒一切敌人而决不被敌人所屈服的新型人民军队。毛泽东同志创造性地解决了团结全民族最大多数人共同奋斗的革命统一战线的一系列重大问题，为党和人民事业凝聚了一支最广大的同盟军。毛泽东同志带领我们党创造性地提出和实施了一系列正确的战略策略，及时解决了中国革命进程中一道道极为复杂的难题，引导中国革命航船不断乘风破浪前进。</p>
<p>　　“为有牺牲多壮志，敢叫日月换新天。”经过28年浴血奋战和顽强奋斗，我们党和人民历经千辛万苦、付出巨大牺牲，在战胜日本军国主义侵略者后，经过人民解放战争，以摧枯拉朽之势推翻了帝国主义、封建主义、官僚资本主义的统治，夺取了新民主主义革命胜利，实现了几代中国人梦寐以求的民族独立和人民解放。</p>
<p>　　中华人民共和国的成立，使中国人民成为国家、社会和自己命运的主人，实现了中国向人民民主制度的伟大跨越，实现了中国高度统一和各民族空前团结，彻底结束了旧中国半殖民地半封建社会的历史，彻底结束了旧中国一盘散沙的局面，彻底废除了外国列强强加给中国的不平等条约和帝国主义在中国的一切特权。</p>
<p>　　中国人从此站立起来了！中国人民从此把命运牢牢掌握在自己手中！中华民族发展进步从此开启了新纪元！</p>
<p>　　这个伟大历史胜利，是毛泽东同志和他的战友们，是千千万万革命志士和革命烈士，是亿万中国人民，共同为中华民族建立的伟大历史功勋。这一伟大奋斗历程和成果充分证明了毛泽东同志所说的：“我们中华民族有同自己的敌人血战到底的气概，有在自力更生的基础上光复旧物的决心，有自立于世界民族之林的能力。”</p>
<p>　　新中国成立后，以毛泽东同志为核心的党的第一代中央领导集体带领人民，在迅速医治战争创伤、恢复国民经济的基础上，不失时机提出了过渡时期总路线，创造性地完成了由新民主主义革命向社会主义革命的转变，使中国这个占世界四分之一人口的东方大国进入了社会主义社会，成功实现了中国历史上最深刻最伟大的社会变革。新民主主义革命的胜利，社会主义基本制度的确立，为当代中国一切发展进步奠定了根本政治前提和制度基础。</p>
<p>　　社会主义基本制度确立以后，如何在中国建设社会主义，是党面临的崭新课题。毛泽东同志对适合中国情况的社会主义建设道路进行了艰苦探索。他以苏联的经验教训为鉴戒，提出要创造新的理论、写出新的著作，把马克思列宁主义基本原理同中国实际进行“第二次结合”，找出在中国进行社会主义革命和建设的正确道路，制定把我国建设成为一个强大的社会主义国家的战略思想。</p>
<p>　　在中国共产党领导下，我国各族人民意气风发投身中国历史上从来不曾有过的热气腾腾的社会主义建设。在不长的时间里，我国社会就发生了翻天覆地的变化，建立起独立的比较完整的工业体系和国民经济体系，独立研制出“两弹一星”，成为在世界上有重要影响的大国，积累起在中国这样一个社会生产力水平十分落后的东方大国进行社会主义建设的重要经验。</p>
<p>　　毛泽东同志为中国新民主主义革命的胜利、社会主义革命的成功、社会主义建设的全面展开，为实现中华民族独立和振兴、中国人民解放和幸福，作出了彪炳史册的贡献。毛泽东同志毕生最突出最伟大的贡献，就是领导我们党和人民找到了新民主主义革命的正确道路，完成了反帝反封建的任务，建立了中华人民共和国，确立了社会主义基本制度，取得了社会主义建设的基础性成就，并为我们探索建设中国特色社会主义的道路积累了经验和提供了条件，为我们党和人民事业胜利发展、为中华民族阔步赶上时代发展潮流创造了根本前提，奠定了坚实的理论和实践基础。</p>
<h4 id="在纪念孙中山先生诞辰150周年大会上的讲话"><strong>在纪念孙中山先生诞辰150周年大会上的讲话</strong></h4>
<p>同志们，朋友们：</p>
<p>　　今天，我们在这里隆重集会，纪念孙中山先生诞辰150周年，缅怀他为民族独立、社会进步、人民幸福建立的不朽功勋，弘扬他的革命精神和崇高品德，激励海内外中华儿女为实现中华民族伟大复兴而团结奋斗。</p>
<p>　　孙中山先生是伟大的民族英雄、伟大的爱国主义者、中国民主革命的伟大先驱，一生以革命为己任，立志救国救民，为中华民族作出了彪炳史册的贡献。</p>
<p>　　时代造就伟大人物，伟大人物又影响时代。150年前，孙中山先生出生之时，中国正遭受帝国主义列强的野蛮侵略和封建专制制度的腐朽统治，战乱频发，民生凋敝，中华民族陷入内忧外患的灾难深渊，中国人民处于水深火热的悲惨境地。在那个风雨如晦的年代，中华民族从未屈服，无数仁人志士前仆后继，探求救国救民的道路，进行可歌可泣的抗争。孙中山先生就是他们中的杰出代表。</p>
<p>　　青年时代，孙中山先生目睹山河破碎、生灵涂炭，誓言“亟拯斯民于水火，切扶大厦之将倾”，高扬反对封建专制统治的旗帜，毅然投身民主革命事业。他创立兴中会、同盟会，提出民族、民权、民生的三民主义，积极传播革命思想，广泛联合革命力量，连续发动武装起义，为推进民主革命四处奔走、大声疾呼。</p>
<p>　　1911年，在他领导和影响下，震惊世界的辛亥革命取得成功，推翻了清王朝统治，结束了统治中国几千年的君主专制制度。由于历史进程和社会条件的制约，辛亥革命虽然没有改变旧中国半殖民地半封建的社会性质，没有改变中国人民的悲惨命运，没有完成实现民族独立、人民解放的历史任务，但开创了完全意义上的近代民族民主革命，打开了中国进步闸门，传播了民主共和理念，极大推动了中华民族思想解放，以巨大的震撼力和影响力推动了中国社会变革。</p>
<p>　　孙中山先生的伟大，不仅在于他领导了辛亥革命，而且在于他为了实现革命理想，与时俱进完善自己的革命理念和斗争方略，毫不妥协同逆时代潮流而动的各种势力进行斗争。他坚决反对军阀分裂割据，坚定维护民主共和制度和国家完整统一。十月革命爆发后，马克思列宁主义传入中国，为孙中山先生认识世界和中国打开了新的视野。中国共产党成立后，孙中山先生同中国共产党人真诚合作，在中国共产党帮助下，把旧三民主义发展为新三民主义，实行联俄、联共、扶助农工三大政策，改组中国国民党，推动北伐战争取得胜利，把反帝反封建的民主革命推向前进。毛泽东同志把三民主义纲领、统一战线政策、艰苦奋斗精神并称为孙中山先生“留给我们的最中心最本质最伟大的遗产”，是“对于中华民族最伟大的贡献”。</p>
<p>　　孙中山先生为当时中国的积贫积弱痛心疾首，第一个响亮喊出“振兴中华”的口号。他认为，“建设为革命之唯一目的”。他坚信，革命成功以后，经过全民族努力，中国一定能够迎头赶上世界先进国家。他满怀豪情地说：“一旦我们革新中国的伟大目标得以完成，不但在我们的美丽的国家将会出现新纪元的曙光，整个人类也将得以共享更为光明的前景”。</p>
<p>　　孙中山先生为中国人民和中华民族作出了杰出贡献，在中国人民心中享有崇高威望，受到全体中华儿女景仰。今天，缅怀孙中山先生建立的历史功勋，缅怀孙中山先生为中国人民鞠躬尽瘁的光辉一生，我们心中充满着深深的崇敬之情。</p>
<p>　　同志们、朋友们！</p>
<p>　　中国共产党人是孙中山先生革命事业最坚定的支持者、最忠诚的合作者、最忠实的继承者。在他生前，中国共产党人坚定支持孙中山先生的事业。在他身后，中国共产党人忠实继承孙中山先生的遗志，团结带领全国各族人民英勇奋斗、继续前进，付出巨大牺牲，完成了孙中山先生的未竟事业，取得新民主主义革命胜利，建立了人民当家作主的中华人民共和国，实现了民族独立、人民解放。在这个基础上，中国共产党人团结带领中国人民继续奋斗，完成了社会主义革命，确立了社会主义制度。</p>
<p>　　新中国成立67年特别是改革开放30多年来，在中国共产党领导下，中国人民在社会主义道路上实现了一个又一个伟大飞跃，取得举世瞩目的伟大成就。今天，我们可以告慰孙中山先生的是，我们比历史上任何时期都更接近中华民族伟大复兴的目标，比历史上任何时期都更有信心、有能力实现这个目标。</p>
<p>　　同志们、朋友们！</p>
<p>　　我们对孙中山先生最好的纪念，就是学习和继承他的宝贵精神，团结一切可以团结的力量，调动一切可以调动的因素，为他梦寐以求的振兴中华而继续奋斗。</p>
<p>　　——我们要学习孙中山先生热爱祖国、献身祖国的崇高风范。孙中山先生最大的特点是热爱祖国，一生追求实现民族独立和发展振兴的理想，对此矢志不移、无比坚定。孙中山先生说：“做人的最大事情是什么呢？就是要知道怎么样爱国”。他总是以“爱国若命”、“一息尚存，不忘救国”等鞭策自己。孙中山先生具有高度的民族自尊和民族自信，不泥古、不守旧，不崇洋、不媚外，强调“中国的社会既然是和欧美的不同，所以管理社会的政治自然也是和欧美不同”；“发展之权，操之在我则存，操之在人则亡”。他从坎坷人生经历和长期斗争实践中得出一个道理，就是改造中国必须从中国实际出发，走适合中国国情的道路。</p>
<p>　　古今中外的历史都告诉我们，世界上没有一个民族能够亦步亦趋走别人的道路实现自己的发展振兴，也没有一种一成不变的道路可以引导所有民族实现发展振兴；一切成功发展振兴的民族，都是找到了适合自己实际的道路的民族。今天，我们要开创中华民族伟大复兴新局面，必须大力弘扬伟大的爱国主义精神，坚信中华民族有能力走出一条成功的复兴之路。爱国主义是具体的、现实的。在当代中国，弘扬爱国主义就必须深刻认识到，中国共产党领导和中国社会主义制度必须长期坚持，不可动摇；中国共产党领导中国人民开辟的中国特色社会主义必须长期坚持，不可动摇；中国共产党和中国人民扎根中国大地、借鉴人类文明优秀成果、独立自主实现国家发展的大政方针必须长期坚持，不可动摇。我们要增强中国特色社会主义道路自信、理论自信、制度自信、文化自信，坚定不移沿着中国特色社会主义道路守护好、建设好我们伟大的国家。</p>
<p>　　——我们要学习孙中山先生天下为公、心系民众的博大情怀。孙中山先生有着深厚的为民情怀，一生坚持以“天下为公”为最高思想境界，致力于“除去人民的那些忧愁，替人民谋幸福”，对此矢志不移、无比坚定。孙中山先生深知人民是最伟大的力量，强调要实现革命的目的，必须唤起民众。他关心民众疾苦，强调“国家之本，在于人民”，“民生为社会进化的重心”，“人民所做不到的，我们要替他们去做；人民没有权利的，我们要替他们去争”。他谆谆告诫大家，“要立心做大事，不要立心做大官”。孙中山先生对人民的深厚感情，是他追求真理、矢志革命的力量源泉，是他奋斗不息、永不言弃的深厚基础。</p>
<p>　　任何一项伟大事业要成功，都必须从人民中找到根基，从人民中集聚力量，由人民共同来完成。违背人民意愿，脱离人民支持，任何事业都会成为无源之水、无本之木，都是不能成功的。今天，要开创中华民族伟大复兴新局面，我们党就必须始终把全心全意为人民服务作为根本宗旨，始终把人民拥护和支持作为力量源泉，坚持把人民放在心中最高位置。我们要坚持一切为了人民、一切依靠人民，永远保持对人民的赤子之心，永远同人民站在一起，推动改革发展成果更多更公平惠及全体人民，朝着实现全体人民共同富裕的目标不断迈进，把13亿多中国人民凝聚成推动中华民族发展壮大的磅礴力量。</p>
<p>　　——我们要学习孙中山先生追求真理、与时俱进的优秀品质。孙中山先生眼界宽广、胸襟开阔，一生追求真理、坚持真理，对此矢志不移、无比坚定。世界上没有先知先觉的人物。孙中山先生以“世界潮流，浩浩荡荡，顺之则昌，逆之则亡”为座右铭，善于从实践中学习，包括从失败的教训中学习，因而能够“适乎世界之潮流，合乎人群之需要”。他说：“我一生的嗜好，除了革命外，只有好读书，我一天不读书，便不能生活。”他从不停止探索前进的步伐，从不拒绝修正自己的思想和主张。他总是内审中国之情势，外察世界之潮流，兼收众长，益以新创，努力赶上时代潮流。无论是从社会改良主义者转变为坚定的民主革命者，还是把旧三民主义发展成新三民主义，都体现了他敢于突破局限、不断自我革新的可贵精神。</p>
<p>　　历史的车轮滚滚向前，跟不上的人必将成为落伍者，必将被历史所淘汰。历史只会眷顾坚定者、奋进者、搏击者，而不会等待犹豫者、懈怠者、畏难者。今天，我们要开创中华民族伟大复兴新局面，就必须树立宏大历史视野，把握世界发展大势，聆听时代声音，勇于坚持真理、修正错误，不断推进理论创新、实践创新、制度创新、文化创新以及其他各方面创新，在时代前进的洪流中书写中华民族发展新篇章。</p>
<p>　　——我们要学习孙中山先生坚韧不拔、百折不挠的奋斗精神。孙中山先生“致力国民革命凡四十年”，一生坚持“吾志所向，一往无前，愈挫愈奋，再接再厉”，对此矢志不移、无比坚定。孙中山先生说：“以吾人数十年必死之生命，立国家亿万年不死之根基，其价值之重可知。”孙中山先生的革命生涯屡经挫折、备尝艰辛，但为了“造成独立自由之国家，以拥护国家及民众之利益”，他从不因失败而灰心，也从不因困难而退缩，坚信“吾心信其可行，则移山填海之难，终有成功之日；吾心信其不可行，则反掌折枝之易，亦无收效之期也”，坚信只要“精神贯注，猛力向前，应乎世界进步之潮流，合乎善长恶消之天理，则终有最后成功之一日”。任何外来威胁、内部分裂、暂时失败都不能动摇孙中山先生的革命意志，直到卧病弥留之际，他念念不忘的仍是“和平、奋斗、救中国”。孙中山先生以毕生奋斗践行了他的誓言，表现出一个伟大革命者的英雄气概和执着追求。</p>
<p>　　伟大的事业之所以伟大，不仅因为这种事业是正义的、宏大的，而且因为这种事业不是一帆风顺的。伟大的人物之所以伟大，不仅因为这样的人物为人民、为民族、为人类建立了丰功伟绩，而且因为这样的人物在艰苦磨砺中铸就了坚强意志和高尚人格。今天，我们要开创中华民族伟大复兴新局面，就必须冷静审视深刻复杂变化的国际形势，全面把握艰巨繁重的改革发展稳定任务，进行长期不懈的艰苦努力，什么时候都不要想象可以敲锣打鼓、顺顺当当实现我们的奋斗目标。我们要把责任扛在肩上，时刻准备应对重大挑战、抵御重大风险、克服重大阻力、解决重大矛盾，以不畏艰险、攻坚克难的勇气，以昂扬向上、奋发有为的锐气，不断把中华民族伟大复兴事业推向前进。</p>
<h4 id="在纪念邓小平同志诞辰110周年座谈会上的讲话">在纪念邓小平同志诞辰110周年座谈会上的讲话</h4>
<p>同志们，朋友们：</p>
<p>　　今天，我们在这里隆重集会，纪念敬爱的邓小平同志诞辰110周年，深切缅怀他为党、为祖国、为人民建立的不朽功勋，追思和学习他为党和人民事业不懈奋斗的崇高风范，进一步激励全党全国各族人民在新的时代条件下把中国特色社会主义事业推向前进。</p>
<p>　　邓小平同志是全党全军全国各族人民公认的享有崇高威望的卓越领导人，伟大的马克思主义者，伟大的无产阶级革命家、政治家、军事家、外交家，久经考验的共产主义战士，中国社会主义改革开放和现代化建设的总设计师，中国特色社会主义道路的开创者，邓小平理论的主要创立者。</p>
<p>　　110年前，邓小平同志出生在四川省广安县协兴乡牌坊村。当时，中国正处于半殖民地半封建社会的黑暗之中，中国正遭受着帝国主义列强的欺凌和封建统治的压迫，社会动荡不已，人民饥寒交迫，民族危在旦夕。面对深重的民族灾难和激烈的社会矛盾，为改变中华民族的悲惨命运，中国人民和无数仁人志士进行着艰辛探索和顽强抗争。那个风雨如晦的年代，孕育了邓小平同志救国救民的理想和追求。他16岁远渡重洋勤工俭学，并在那里接受了马克思主义，加入中国共产党，从此矢志不渝为党和人民事业奋斗了70多年。</p>
<p>　　邓小平同志的一生，同中国共产党、中国人民解放军、中华人民共和国创建和发展的历史进程紧紧相连，同中国革命、建设、改革的历史进程紧紧相连，同中华民族抗争、独立、振兴的历史进程紧紧相连，是光辉的一生、战斗的一生、伟大的一生。</p>
<p>　　新民主主义革命时期，邓小平同志为党领导的民族独立和人民解放事业建立了卓越功勋，是中华人民共和国的开国元勋。新民主主义革命时期，邓小平同志作为毛泽东同志的亲密战友，始终坚持正确路线，以充沛的革命热情，先后担任党和军队许多重要领导职务，为创建发展新型人民军队、赢得革命战争胜利作出了重要贡献。北伐战争期间，他从苏联回国直接参加革命斗争。土地革命战争期间，他先后在上海极端险恶的环境下从事地下工作，在广西领导发动百色起义和龙州起义、创立左右江革命根据地，参加艰苦卓绝的长征，亲历标志着党的历史伟大转折的遵义会议。抗日战争和解放战争期间，他坚决执行党中央和毛泽东同志的战略决策，军政兼任、勇挑重担，不畏艰险、出奇制胜，一直处在战略全局的关键位置，处在对敌斗争的最前线。特别是先后同刘伯承、陈毅等同志一起，开辟晋冀鲁豫抗日根据地，率部千里跃进大别山，组织实施淮海战役和渡江战役，进军解放大西南，建立了赫赫战功。</p>
<p>　　在社会主义革命和建设时期，邓小平同志为胜利完成社会主义革命、探索我国社会主义建设道路作出了杰出贡献。新中国成立初期，邓小平同志主政西南，不久就参加中央领导工作，先后担任中共中央秘书长、中共中央政治局委员、政府副总理。1956年党的八届一中全会上，他当选中共中央政治局常委、中共中央总书记，成为以毛泽东同志为核心的党的第一代中央领导集体的重要成员。此后10年间，他负责党中央大量日常工作，为探索适合我国情况的社会主义建设道路、为克服经济困难提出许多正确主张，进行了卓有成效的工作。“文化大革命”开始后不久，他受到错误批判和斗争，被剥夺一切职务，直到1973年复出。1975年他开始主持党、国家、军队日常工作，为扭转“文化大革命”造成的严重混乱局面，开展大刀阔斧的全面整顿，同“四人帮”进行针锋相对的斗争。不久，他再次被错误撤职、批判。</p>
<p>　　在改革开放新时期，邓小平同志成为党的第二代中央领导集体的核心，为开创中国特色社会主义作出了历史性贡献。“文化大革命”结束，“中国向何处去”又成为摆在中国人民面前头等重要的问题。邓小平同志以他的远见卓识、丰富政治经验、高超领导艺术，强调实事求是是毛泽东思想的精髓，旗帜鲜明反对“两个凡是”的错误观点，支持和领导开展真理标准问题的讨论，推动进行各方面的拨乱反正。在邓小平同志指导下，1978年12月召开的党的十一届三中全会，重新确立了解放思想、实事求是的思想路线，停止使用“以阶级斗争为纲”的错误提法，确定把全党工作的着重点转移到社会主义现代化建设上来，作出实行改革开放的重大决策，实现了党的历史上具有深远意义的伟大转折。</p>
<p>　　党的十一届三中全会以后，邓小平同志始终站在时代要求、国家发展、人民期待的高度，同中央领导集体一起，领导我们党作出一系列重大决策，把改革开放和社会主义现代化建设一步一步推向前进。邓小平同志指导我们党系统总结建国以来的历史经验，解决了科学评价毛泽东同志的历史地位和毛泽东思想的科学体系、根据新的实际和发展要求确立中国社会主义现代化建设的正确道路这样两个相互联系的重大历史课题，彻底否定了“文化大革命”的错误实践和理论，坚决顶住否定毛泽东同志和毛泽东思想的错误思潮，为党和国家发展确定了正确方向。邓小平同志紧紧抓住“什么是社会主义、怎样建设社会主义”这个基本问题，响亮提出“走自己的道路，建设有中国特色的社会主义”的伟大号召，领导我们党在新中国成立以来革命和建设实践的基础上，成功走出了一条中国特色社会主义新道路。邓小平同志强调必须坚持以经济建设为中心，坚持四项基本原则，坚持改革开放，领导我们党制定了党在社会主义初级阶段的基本路线。邓小平同志指导我们党正确认识我国所处的发展阶段和根本任务，制定了现代化建设“三步走”发展战略。邓小平同志突出强调“改革是中国的第二次革命”，领导我们党有步骤地展开各方面体制改革，勇敢打开对外开放的大门。邓小平同志反复强调“两手抓、两手都要硬”，必须抓好社会主义精神文明建设和民主法制建设，实现社会全面进步。他创造性提出“一国两制”科学构想，指导我们实现香港、澳门平稳过渡和顺利回归，推动海峡两岸关系打开新局面。邓小平同志明确提出和平与发展是当代世界的两大问题，领导我们党及时调整各方面政策，为改革开放和社会主义现代化建设创造了难得历史机遇和良好外部环境。邓小平同志强调加强党的领导必须改善党的领导，必须聚精会神抓党的建设，使党的建设充满新的生机活力。正是这些重大思想理论和实践，使20世纪的中国又一次发生天翻地覆的变化。</p>
<p>　　邓小平同志对党和人民的贡献，是历史性的，也是世界性的。正是由于有邓小平同志的卓越领导，正是由于有邓小平同志大力倡导和全力推进的改革开放，中国特色社会主义才能欣欣向荣，中国人民才能过上小康生活，中华民族和中华人民共和国才能以新的姿态屹立于世界东方。</p>
<p>　　邓小平同志的贡献，不仅改变了中国人民的历史命运，而且改变了世界的历史进程。邓小平同志赢得了中国人民衷心爱戴，也赢得了世界人民广泛尊敬。</p>
<p>　　像我们党的其他老一辈革命家一样，邓小平同志之所以能够为祖国和人民建立彪炳史册的功勋，就在于他看清了世界和中国的发展大势，深刻了解中国人民和中华民族的深沉愿望，把握住中国发展的历史规律，紧紧依靠党和人民建立了前所未有的历史性伟业。正如江泽民同志、胡锦涛同志指出的那样：如果没有邓小平同志，中国人民就不可能有今天的新生活，中国就不可能有今天改革开放的新局面和社会主义现代化的光明前景。</p>
<p>　　邓小平同志为中华民族独立、繁荣、振兴和中国人民解放、自由、幸福奋斗的辉煌人生和伟大贡献，将永远书写在祖国辽阔的大地之上。邓小平同志始终在人民中间，也始终在人民心间。在这里，我们要说：小平您好！祖国和人民永远怀念您！</p>
<p>　　同志们、朋友们！</p>
<p>　　伟大的时代造就伟大的人物。邓小平同志就是从中国人民和中华民族近代以来伟大斗争中产生的伟人，是我们大家衷心热爱的伟人。我们很多同志都曾经在他的领导和指导下工作过，他的崇高风范对我们来说是那样熟悉、那样亲切。邓小平同志崇高鲜明又独具魅力的革命风范，将激励我们在实现“两个一百年”奋斗目标、实现中华民族伟大复兴中国梦的征程上奋勇前进。</p>
<p>　　——我们纪念邓小平同志，就要学习他对共产主义远大理想和中国特色社会主义信念无比坚定的崇高品格。信念坚定，是邓小平同志一生最鲜明的政治品格，也永远是中国共产党人应该挺起的精神脊梁。</p>
<p>　　早在苏联求学期间，邓小平同志就立志“更坚决的把我的身子交给我们的党，交给本阶级”。在此后70多年的革命生涯中，无论个人处境如何艰难，无论革命道路如何坎坷，邓小平同志都坚信马克思主义的科学性和真理性，坚信社会主义、共产主义的光明前景。他说：“对马克思主义的信仰，是中国革命胜利的一种精神动力。”面对革命战争的枪林弹雨，他浴血奋战、视死如归；面对新中国建设的艰难局面，他励精图治、百折不挠；面对“文化大革命”的十年内乱，他信念执着、从不消沉；面对国际国内政治风波，他冷静观察、从容应对，坚信马克思主义、坚守共产主义理想，坚持在社会主义道路上推进我国现代化事业。</p>
<p>　　1992年，88岁高龄的邓小平同志在南方谈话中说：“我坚信，世界上赞成马克思主义的人会多起来的，因为马克思主义是科学。它运用历史唯物主义揭示了人类社会发展的规律。”“不要惊慌失措，不要认为马克思主义就消失了，没用了，失败了。哪有这回事！”</p>
<p>　　邓小平同志对理想信念的重要性具有深刻认识，他说：“我认为，最重要的是人的团结，要团结就要有共同的理想和坚定的信念。我们过去几十年艰苦奋斗，就是靠用坚定的信念把人民团结起来，为人民自己的利益而奋斗。”</p>
<p>　　革命理想高于天。没有一大批具有坚定共产主义理想的中华儿女，就没有中国共产党，也就没有新中国，更没有今天我国的发展进步。要把我国发展得更好，离不开理想信念的力量。我们共产党人锤炼党性，首要的就是坚定共产主义远大理想和中国特色社会主义共同理想。我们要学习邓小平同志矢志不渝为社会主义、共产主义而奋斗的执着精神，坚定中国特色社会主义道路自信、理论自信、制度自信，坚忍不拔、风雨无阻朝着我们的目标奋勇前进。</p>
<p>　　——我们纪念邓小平同志，就要学习他对人民无比热爱的伟大情怀。热爱人民，是邓小平同志一生最深厚的情感寄托，也永远是中国共产党人应该坚守的力量源泉。</p>
<p>　　邓小平同志曾经写道：“我是中国人民的儿子，我深情地爱着我的祖国和人民。”邓小平同志从对人民的挚爱，延伸到对党、对祖国的挚爱。他说过：“我的生命是属于党、属于国家的。”这质朴的语言，集中表达了邓小平同志对党、对祖国、对人民的大爱。</p>
<p>　　邓小平同志高度重视人民群众的地位和作用，他强调：“群众是我们力量的源泉，群众路线和群众观点是我们的传家宝。党的组织、党员和党的干部，必须同群众打成一片，绝对不能同群众相对立。如果哪个党组织严重脱离群众而不能坚决改正，那就丧失了力量的源泉，就一定要失败，就会被人民抛弃。”在他的一生中，无论身居要职还是身陷困苦，都始终与人民群众同甘共苦，努力为党和国家分忧解难。</p>
<p>　　邓小平同志孜孜以求的是增进人民福祉。他多次讲：“贫穷不是社会主义，社会主义要消灭贫穷。不发展生产力，不提高人民的生活水平，不能说是符合社会主义要求的。”他领导改革开放和社会主义现代化建设，心中想着的就是最广大人民。</p>
<p>　　邓小平同志坚持从人民创造历史的活动中吸取思想营养和前进力量。他说：“改革开放中许许多多的东西，都是群众在实践中提出来的”，“绝不是一个人脑筋就可以钻出什么新东西来”，“这是群众的智慧，集体的智慧”。他反复强调，要把人民拥护不拥护、赞成不赞成、高兴不高兴、答应不答应作为制定方针政策和作出决断的出发点和归宿。邓小平同志始终以人民利益为最高准则来开展领导工作。</p>
<p>　　爱祖国、爱人民，是最深沉、最有力量的情感，是博大之爱。我们要学习邓小平同志对祖国、对人民的深情大爱，始终为人民利益而奋斗，任何时候任何条件下都忠于祖国、忠于人民，脚踏实地践行党的宗旨，把自己的一生交给党和人民，为党和人民事业鞠躬尽瘁、死而后已。</p>
<p>　　——我们纪念邓小平同志，就要学习他始终坚持实事求是的理论品质。实事求是，是邓小平同志一生最重要的思想特点，也永远是中国共产党人应该遵循的思想方法。</p>
<p>　　邓小平同志坚持党的思想路线，坚持一切从实际出发，常说自己是“实事求是派”，反复强调“拿事实来说话”，“实事求是是马克思主义的精髓。要提倡这个，不要提倡本本。我们改革开放的成功，不是靠本本，而是靠实践，靠实事求是。”“要取信于民，要干出实绩”。“领导者必须多干实事。”邓小平同志以一生的实践证明，他是一位高瞻远瞩的思想家、政治家、战略家，也是一位求实、务实、踏实的实干家。</p>
<p>　　上个世纪60年代初期，面对国家困难，邓小平同志提醒各级干部要“实事求是地说明情况”。当时为了推动恢复和发展农业生产，他说：“生产关系究竟以什么形式为最好，恐怕要采取这样一种态度，就是哪种形式在哪个地方能够比较容易比较快地恢复和发展农业生产，就采取哪种形式；群众愿意采取哪种形式，就应该采取哪种形式，不合法的使它合法起来。”</p>
<p>　　进入改革开放新时期，邓小平同志更加强调坚持彻底的求真务实精神。他说：“我读的书并不多，就是一条，相信毛主席讲的实事求是。过去我们打仗靠这个，现在搞建设、搞改革也靠这个。”他强调，要把是否有利于发展社会主义社会的生产力、是否有利于增强社会主义国家的综合国力、是否有利于提高人民的生活水平作为判断一切工作是非得失的标准。正是因为具有这种彻底的求真务实精神，邓小平同志果断从容处理了党和国家面对的一系列重大问题，指导党和人民劈波斩浪开创了党和国家事业新局面。</p>
<p>　　事实是真理的依据，实干是成就事业的必由之路。这也是“空谈误国，实干兴邦”的真谛。我国革命、建设、改革的历史反复证明，只有制定符合实际的政策措施，采取符合实际的工作方法，党和人民事业才能走上正确轨道，才能取得人民满意的成效。我们要学习邓小平同志善于运用辩证唯物主义和历史唯物主义观察世界、处理问题的思想方法和领导艺术，掌握真实情况，把握客观规律，发扬务实高效、不尚空谈的工作作风，踏踏实实把党的基本理论、基本路线、基本纲领、基本经验、基本要求贯彻落实好。</p>
<p>　　——我们纪念邓小平同志，就要学习他不断开拓创新的政治勇气。开拓创新，是邓小平同志一生最鲜明的领导风范，也永远是中国共产党人应该具有的历史担当。</p>
<p>　　综观邓小平同志70多年的革命生涯，可以清楚地看到，他身上始终洋溢着一种革故鼎新、一往无前的勇气，一种善于创造性思维、善于打开新局面的锐气。</p>
<p>　　1975年，邓小平同志在领导全国大刀阔斧的整顿工作期间，斩钉截铁地说：“现在问题相当多，要解决，没有一股劲不行。要敢字当头，横下一条心。”1977年复出后，面对长期形成的思想禁锢状况，邓小平同志鲜明提出，不能“书上没有的，文件上没有的，领导人没有讲过的，就不敢多说一句话，多做一件事，一切照抄照搬照转”。他谆谆告诫我们：“世界形势日新月异，特别是现代科学技术发展很快。现在的一年抵得上过去古老社会几十年、上百年甚至更长的时间。不以新的思想、观点去继承、发展马克思主义，不是真正的马克思主义者。”“一个党，一个国家，一个民族，如果一切从本本出发，思想僵化，迷信盛行，那它就不能前进，它的生机就停止了，就要亡党亡国。”</p>
<p>　　邓小平同志强调：“改革开放胆子要大一些，敢于试验，不能像小脚女人一样。看准了的，就大胆地试，大胆地闯”，“走不出一条新路，就干不出新的事业”。邓小平同志第一次比较系统地初步回答了在中国这样经济文化比较落后的国家如何建设社会主义、如何巩固和发展社会主义的一系列基本问题，深刻揭示了社会主义的本质，实现了马克思主义同中国实际相结合的又一次历史性飞跃。邓小平同志的南方谈话，从理论上深刻回答了长期困扰和束缚人们思想的许多重大问题，推动改革开放和社会主义现代化建设进入新阶段。正是在邓小平同志倡导和支持下，改革大潮汇聚成时代洪流，使中国人民的面貌、社会主义中国的面貌、中国共产党的面貌发生了历史性变化。</p>
<p>　　越是伟大的事业，往往越是充满艰难险阻，越是需要开拓创新。中国特色社会主义是前无古人的伟大事业，改革开放和社会主义现代化建设还有很长的路要走。在前进道路上，我们将进行许多具有新的历史特点的伟大斗争。我们要学习邓小平同志敢于开拓创新的政治勇气，细心观察新的实践和新的发展，尊重地方、基层、群众首创精神，果断作出决策，把开拓创新作为一种常态，不断用发展着的马克思主义指导新的实践，又从实践中作出新的理论概括，敢破敢立、敢闯敢试，义无反顾把改革开放不断向前推进。</p>
<p>　　——我们纪念邓小平同志，就要学习他高瞻远瞩的战略思维。战略思维，是邓小平同志一生最恢宏的革命气度，也永远是中国共产党人应该树立的思维方式。</p>
<p>　　邓小平同志思想敏锐、目光远大，多谋善断、举要驭繁，总是站在国内大局和国际大局相互联系的高度审视中国和世界的发展，善于从全局上思考问题，善于在关键时刻作出战略决策。进入改革开放新时期，邓小平同志洞察国内外发展大势，作出了一系列事关党和国家事业长远发展、事关社会主义前途命运的重大战略决策。</p>
<p>　　邓小平同志深刻分析当今时代特征和世界大势，指出：“现在的世界是开放的世界”，“总结历史经验，中国长期处于停滞和落后状态的一个重要原因是闭关自守。经验证明，关起门来搞建设是不能成功的，中国的发展离不开世界。”同时，邓小平同志高度珍惜并坚决维护中国人民经过长期奋斗得来的独立自主权利，告诫人们：“中国的事情要按照中国的情况来办，要依靠中国人自己的力量来办。独立自主，自力更生，无论过去、现在和将来，都是我们的立足点。”“任何外国不要指望中国做他们的附庸，不要指望中国会吞下损害我国利益的苦果。”</p>
<p>　　邓小平同志高度关注世界和平与发展问题，提出“应当把发展问题提到全人类的高度来认识，要从这个高度去观察问题和解决问题”。他关注广大发展中国家的命运，强调我们搞的是主张和平的社会主义，“中国和所有第三世界国家的命运是共同的。中国永远不会称霸，永远不会欺负别人，永远站在第三世界一边。”他强调，要反对任何形式的霸权主义，维护世界和平。</p>
<p>　　战略问题是一个政党、一个国家的根本性问题。战略上判断得准确，战略上谋划得科学，战略上赢得主动，党和人民事业就大有希望。我们要学习邓小平同志“放眼世界，放眼未来，也放眼当前，放眼一切方面”的世界眼光和战略思维，学习他善于抓住关键、纲举目张的思想方法和工作方法，站在时代前沿观察思考问题，把党和人民事业放到历史长河和全球视野中来谋划，以小见大、见微知著，在解决突出问题中实现战略突破，在把握战略全局中推进各项工作。</p>
<p>　　——我们纪念邓小平同志，就要学习他坦荡无私的博大胸襟。坦荡无私，是邓小平同志一生最光辉的人格魅力，也永远是中国共产党人应该锤炼的品质修养。</p>
<p>　　邓小平同志始终以劳动人民的一员看待自己，始终以共产党员的标准要求自己，不屈不挠面对困难，有情有义对待同志，一以贯之严格自律，自始至终谦虚谨慎，为我们树立了共产党人自觉加强党性修养的光辉典范。</p>
<p>　　邓小平同志始终把党和国家前途命运放在心中最高的位置，从不计较个人得失。他说：“我自从十八岁加入革命队伍，就是想把革命干成功，没有任何别的考虑”。他一生“三落三起”都是因为敢于坚持真理、修正错误，每次被错误批判打倒都豁达乐观、沉着坚韧，对未来充满希望；每次复出重新回到工作岗位都无私无畏、以顽强的意志排除各种干扰，坚定不移推动正确路线方针政策的形成和实践。“文化大革命”结束后，邓小平同志再度出来工作，依然表示：“我出来工作，可以有两种态度，一个是做官，一个是做点工作。我想，谁叫你当共产党人呢，既然当了，就不能够做官，不能够有私心杂念，不能够有别的选择。”邓小平同志真正做到了心底无私天地宽。</p>
<p>　　邓小平同志客观公正对待党的历史、对待同志、对待自己，谦逊随和，平易近人，善于同人合作共事。革命战争年代，他同刘伯承同志共事13年，形成亲密无间的革命友谊。他善于团结和使用同自己意见不同的人一道工作，从不以个人恩怨待人处事。他说：“要抛弃个人恩怨来选择人，反对过自己的人也要用。”邓小平同志一贯反对特权、反对腐败，对亲属和身边工作人员总是严格要求。</p>
<p>　　邓小平同志功高至伟却从不居功自傲。他多次讲：“永远不要过分突出我个人。我所做的事，无非反映了中国人民和中国共产党人的愿望”。他以唯物主义者的精神看待生死问题，对家人说：“我哪天去，哪天走，不关紧要。自然规律违背不得，你们要想透这个问题。”他逝世后，按照他的遗愿，把角膜捐献给了医院，遗体供医学解剖，骨灰撒入大海，奉献了自己的一切。</p>
<p>　　共产党人拥有人格力量，才能无愧于自己的称号，才能赢得人民赞誉。我们要学习邓小平同志公而忘私、无私无畏的博大胸怀，加强党性修养，严于律己、宽以待人，正确对待组织，正确对待同志，正确对待自己，正确对待权力，积极践行社会主义核心价值观，为党和人民事业赤诚奉献，以身作则推动营造风清气正的党风、政风和社会风气。</p>
<p>　　同志们、朋友们！</p>
<p>　　邓小平同志留给我们的最重要的思想和政治遗产，就是他带领党和人民开创的中国特色社会主义，就是他创立的邓小平理论。马克思说：“人们自己创造自己的历史，但是他们并不是随心所欲地创造，并不是在他们自己选定的条件下创造，而是在直接碰到的、既定的、从过去承继下来的条件下创造。”邓小平同志最鲜明的思想和实践特点，就是从实际出发、从世界大势出发、从国情出发，始终坚持我们党一贯倡导的实事求是、群众路线、独立自主。</p>
<p>　　中国特色社会主义是适合中国国情、符合中国特点、顺应时代发展要求的理论和实践，所以才能取得成功，并将继续取得成功。邓小平同志说：“特别是像我们这样第三世界的发展中国家，没有民族自尊心，不珍惜自己民族的独立，国家是立不起来的。”我们的国权，我们的国格，我们的民族自尊心，我们的民族独立，关键是道路、理论、制度的独立。</p>
<p>　　中华民族创造了具有5000多年悠久历史的辉煌文明，中国人民在中国共产党领导下创造了建设社会主义的辉煌成就，我们应该在这个基础上继续创造。我们自己不足、不好的东西，要努力改革。外国有益、好的东西，我们要虚心学习。但是，不能全盘照搬外国，更不能接受外国不好的东西；不能妄自菲薄，不能数典忘祖。</p>
<p>　　邓小平同志说过，中华人民共和国的成立，“中国取得了一个资格：人们不敢轻视我们”。所以，新民主主义革命的胜利成果决不能丢失，社会主义革命和建设的成就决不能否定，改革开放和社会主义现代化建设的方向决不能动摇。这是党和人民在当今世界安身立命、风雨前行的资格。中国近代以来的全部历史告诉我们，中国的事情必须按照中国的特点、中国的实际来办，这是解决中国所有问题的正确之道。</p>
<p>　　同志们、朋友们！</p>
<p>　　邓小平同志离开我们17年来，国际形势风云变幻，国内改革发展任务艰巨繁重，在以江泽民同志为核心的党的第三代中央领导集体、以胡锦涛同志为总书记的党中央领导下，我们党团结带领全国各族人民，坚持党的十一届三中全会以来的路线方针政策不动摇，推动党和国家各项事业不断取得新的伟大成就。党的十八大以来，党中央团结带领全国各族人民，全面贯彻党的十八大和十八届三中全会精神，高举中国特色社会主义伟大旗帜，坚持以马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观为指导，统筹国内国际两个大局，全面深化改革，推动经济持续健康发展，全面加强作风建设，努力开创中国特色社会主义事业更加广阔的前景。</p>
<p>　　邓小平同志为我们擘画的社会主义现代化蓝图正在一步步变成美好现实，我们伟大的祖国正在一天天走向繁荣富强，中华民族正在一步步走向伟大复兴。对此，我们感到无比自豪。</p>
<p>　　此时此刻，我们必须牢记邓小平同志语重心长说过的这段话：“我们搞社会主义才几十年，还处在初级阶段。巩固和发展社会主义制度，还需要一个很长的历史阶段，需要我们几代人、十几代人，甚至几十代人坚持不懈地努力奋斗”；“社会主义的本质，是解放生产力，发展生产力，消灭剥削，消除两极分化，最终达到共同富裕。”实现社会主义现代化，实现祖国完全统一，实现中华民族伟大复兴，这是毛泽东同志、邓小平同志等老一辈革命家和千百万革命先辈的深切夙愿，是全体中华儿女的共同心愿。</p>
<p>　　邓小平同志曾经嘱托全党：“从现在起到下世纪中叶，将是很要紧的时期，我们要埋头苦干。我们肩膀上的担子重，责任大啊！”今天，历史的接力棒传到了我们手里，责任重于泰山。全党一定要紧密团结起来，敢于担当、埋头苦干，团结带领全国各族人民，以与时俱进、时不我待的精神不断夺取新胜利，不断完善和发展中国特色社会主义，不断为人类和平与发展的崇高事业作出新的更大的贡献。</p>
<p>　　我们相信，在20世纪赢得了伟大历史性胜利的中国共产党和中国人民，必将在21世纪赢得更伟大的历史性胜利！</p>
<h4 id="在纪念辛亥革命110周年大会上的讲话"><strong>在纪念辛亥革命110周年大会上的讲话</strong></h4>
<p>同志们，朋友们：</p>
<p>　　110年前，以孙中山先生为代表的革命党人发动了震惊世界的辛亥革命，推翻了清朝政府，结束了在中国延续几千年的君主专制制度，近代以来中国发生的深刻社会变革由此拉开了序幕。这是中国人民和中国先进分子为实现民族独立、人民解放进行的一次伟大而艰辛探索。</p>
<p>　　今年是辛亥革命110周年，是中国共产党成立100周年，中国人民正意气风发向着全面建成社会主义现代化强国的第二个百年奋斗目标迈进。在这个重要时刻，我们在这里隆重集会，缅怀孙中山先生等革命先驱的历史功勋，就是要学习和弘扬他们为振兴中华而矢志不渝的崇高精神，激励和团结海内外全体中华儿女为实现中华民族伟大复兴而共同奋斗。</p>
<p>　　同志们、朋友们！</p>
<p>　　辛亥革命的发生，有着深刻的社会历史背景，是近代以来中国社会矛盾激化和中国人民顽强斗争的必然结果。中华民族是世界上古老而伟大的民族，有着5000多年源远流长的文明历史，为人类文明进步作出了不可磨灭的贡献。1840年鸦片战争以后，西方列强在中华大地上恣意妄为，封建统治者孱弱无能，中国逐步成为半殖民地半封建社会，国家蒙辱、人民蒙难、文明蒙尘，中国人民和中华民族遭受了前所未有的劫难。英雄的中国人民始终没有屈服，在救亡图存的道路上一次次抗争、一次次求索，展现了不畏强暴、自强不息的顽强意志。</p>
<p>　　从那时起，实现中华民族伟大复兴就成为中华民族最伟大的梦想。</p>
<p>　　孙中山先生是伟大的民族英雄、伟大的爱国主义者、中国民主革命的伟大先驱。孙中山先生大声疾呼“亟拯斯民于水火，切扶大厦之将倾”，高扬反对封建专制统治的斗争旗帜，提出民族、民权、民生的三民主义政治纲领，率先发出“振兴中华”的呐喊。在孙中山先生领导和影响下，大批革命党人和无数爱国志士集聚在振兴中华旗帜之下，广泛传播革命思想，积极兴起进步浪潮，连续发动武装起义，推动了革命大势的形成。</p>
<p>　　<strong>1911年10月10日，武昌城头枪声一响，拉开了中国完全意义上的近代民族民主革命的序幕</strong>。辛亥革命极大促进了中华民族的思想解放，传播了民主共和的理念，打开了中国进步潮流的闸门，撼动了反动统治秩序的根基，在中华大地上建立起亚洲第一个共和制国家，以巨大的震撼力和深刻的影响力推动了中国社会变革，为实现中华民族伟大复兴探索了道路。</p>
<p>　　孙中山先生和辛亥革命先驱为中华民族建立的历史功绩彪炳千秋！在辛亥革命中英勇奋斗和壮烈牺牲的志士们名垂青史！辛亥革命永远是中华民族伟大复兴征程上一座巍然屹立的里程碑！</p>
<p>　　同志们、朋友们！</p>
<p>　　历史发展总是螺旋式上升、波浪式前进的。由于历史进程和社会条件的制约，由于没有找到解决中国前途命运问题的正确道路和领导力量，<strong>辛亥革命没有改变旧中国半殖民地半封建的社会性质和中国人民的悲惨境遇，没有完成实现民族独立、人民解放的历史任务</strong>。辛亥革命之后，在这场革命中接受洗礼的中国人民和中国先进分子继续探寻救国救民道路。<strong>十月革命一声炮响，给中国送来了马克思列宁主义，促进了中国人民的伟大觉醒，在马克思列宁主义同中国工人运动的紧密结合中，中国共产党应运而生。中国共产党一经诞生，就把为中国人民谋幸福、为中华民族谋复兴确立为自己的初心和使命，点亮了实现中华民族伟大复兴的灯塔。</strong></p>
<p>　　中国共产党人是孙中山先生革命事业最坚定的支持者、最忠诚的合作者、最忠实的继承者。中国共产党在成立之初就提出反帝反封建的民主革命纲领，并同孙中山先生领导的中国国民党携手合作，帮助国民党完成改组，<strong>建立最广泛的革命统一战线，掀起轰轰烈烈的大革命</strong>，给北洋军阀反动统治以沉重打击。</p>
<p>　　孙中山先生逝世后，中国共产党人继承他的遗愿，同一切忠于他的事业的人们继续奋斗，不断实现和发展了孙中山先生和辛亥革命先驱的伟大抱负。中国共产党团结带领中国人民浴血奋战、百折不挠，打败国内外一切反动势力，取得了新民主主义革命伟大胜利，建立了人民当家作主的中华人民共和国，完成了民族独立、人民解放的历史任务，开启了中华民族发展进步的历史新纪元。</p>
<p>　　新中国成立后，中国共产党团结带领中国人民，自力更生、发愤图强，创造了社会主义革命和建设的伟大成就；解放思想、锐意进取，创造了改革开放和社会主义现代化建设的伟大成就；自信自强、守正创新，统揽伟大斗争、伟大工程、伟大事业、伟大梦想，创造了新时代坚持和发展中国特色社会主义的伟大成就。</p>
<p>　　抚今追昔，孙中山先生振兴中华的深切夙愿，辛亥革命先驱对中华民族发展的美好憧憬，近代以来中国人民梦寐以求并为之奋斗的伟大梦想已经或正在成为现实，中华民族迎来了从站起来、富起来到强起来的伟大飞跃，中华民族伟大复兴进入了不可逆转的历史进程！</p>
<p>　　同志们、朋友们！</p>
<p>　　孙中山先生在《建国方略》中说：“吾心信其可行，则移山填海之难，终有成功之日”。今天，经过长期奋斗，实现中华民族伟大复兴具备了更为完善的制度保证、更为坚实的物质基础、更为主动的精神力量。前景光明辽阔，但前路不会平坦。我们要以史为鉴、开创未来，在全面建设社会主义现代化国家新征程上继续担当历史使命，掌握历史主动，不断把中华民族伟大复兴的历史伟业推向前进。</p>
<p>　　——辛亥革命110年来的历史启示我们，<strong>实现中华民族伟大复兴，必须有领导中国人民前进的坚强力量，这个坚强力量就是中国共产党。</strong>中国共产党领导是历史的选择、人民的选择，是党和国家的根本所在、命脉所在，是全国各族人民的利益所系、命运所系。没有中国共产党，就没有新中国，就没有中华民族伟大复兴。</p>
<p>　　新的征程上，我们必须坚持和加强党的全面领导，充分发挥党总揽全局、协调各方的领导核心作用，提高党科学执政、民主执政、依法执政水平。要弘扬伟大建党精神，推进党的建设新的伟大工程，增强自我净化、自我完善、自我革新、自我提高能力，确保中国共产党始终成为中国人民和中华民族最可靠的主心骨。</p>
<p>　　——辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，道路是最根本的问题。中国特色社会主义是实现中华民族伟大复兴的唯一正确道路。这条道路符合中国实际、反映中国人民意愿、适应时代发展要求，不仅走得对、走得通，而且也一定能够走得稳、走得好。</p>
<p>　　新的征程上，我们必须坚持和发展中国特色社会主义不动摇，继续推进马克思主义中国化时代化，坚定志不改、道不变的决心，牢牢把中国发展进步的命运掌握在自己手中。我们要统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，全面深化改革和扩大开放，推进国家治理体系和治理能力现代化，不断满足人民过上美好生活的新期待，不断推进全体人民共同富裕。</p>
<p>　　——辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，必须依靠中国人民自己的英勇奋斗。历史发展从来不是风平浪静的，而是充满曲折和艰辛的。正如毛泽东同志所说的：“我们的先人以不屈不挠的斗争反对内外压迫者，从来没有停止过”，“中国人民的不屈不挠的努力必将稳步地达到自己的目的”。</p>
<p>　　新的征程上，我们必须统筹中华民族伟大复兴战略全局和世界百年未有之大变局，抓住历史机遇，增强忧患意识、始终居安思危，保持革命精神和革命斗志，勇于进行具有许多新的历史特点的伟大斗争，以敢于斗争、善于斗争的意志品质，坚决战胜任何有可能阻碍中华民族复兴进程的重大风险挑战，坚决维护国家主权、安全、发展利益。</p>
<p>　　——辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，中国人民和中华民族必须同舟共济，依靠团结战胜前进道路上一切风险挑战。孙中山先生说过：“要恢复民族的地位，便先要恢复民族的精神。”近代以来，中国人民和中华民族弘扬伟大爱国主义精神，心聚在了一起、血流到了一起，共同书写了抵御外来侵略、推翻反动统治、建设人民国家、推进改革开放的英雄史诗。统一战线始终是中国共产党凝聚人心、汇聚力量的重要法宝。</p>
<p>　　新的征程上，我们必须大力弘扬爱国主义精神，树立高度的民族自尊心和民族自信心，铸牢中华民族共同体意识，紧紧依靠全体中华儿女共同奋斗，坚持大团结大联合，不断巩固和发展最广泛的爱国统一战线，广泛凝聚中华民族一切智慧和力量，形成海内外全体中华儿女万众一心、共襄民族复兴伟业的生动局面。</p>
<p>　　——辛亥革命110年来的历史启示我们，实现中华民族伟大复兴，不仅需要安定团结的国内环境，而且需要和平稳定的国际环境。孙中山先生曾经说过：“中国如果强盛起来，我们不但是要恢复民族的地位，还要对于世界负一个大责任。”中华民族的血液中没有侵略他人、称王称霸的基因，中国人民不仅希望自己发展得好，也希望各国人民都能拥有幸福安宁的生活。</p>
<p>　　新的征程上，我们必须始终高举和平、发展、合作、共赢旗帜，推动构建人类命运共同体，推动完善全球治理体系，弘扬和平、发展、公平、正义、民主、自由的全人类共同价值，加强同世界各国人民的团结，共同反对霸权主义和强权政治，做世界和平的建设者、全球发展的贡献者、国际秩序的维护者，努力为人类作出新的更大贡献。</p>
<p>　　同志们、朋友们！</p>
<p>　　孙中山先生说过：“‘统一’是中国全体国民的希望。能够统一，全国人民便享福；不能统一，便要受害。”台湾问题因民族弱乱而产生，必将随着民族复兴而解决。这是中华民族历史演进大势所决定的，更是全体中华儿女的共同意志，正像孙中山先生所说：“世界潮流，浩浩荡荡，顺之则昌，逆之则亡”。</p>
<p>　　以和平方式实现祖国统一，最符合包括台湾同胞在内的中华民族整体利益。我们坚持“和平统一、一国两制”的基本方针，坚持一个中国原则和“九二共识”，推动两岸关系和平发展。两岸同胞都要站在历史正确的一边，共同创造祖国完全统一、民族伟大复兴的光荣伟业。</p>
<p>　　中华民族具有反对分裂、维护统一的光荣传统。“台独”分裂是祖国统一的最大障碍，是民族复兴的严重隐患。凡是数典忘祖、背叛祖国、分裂国家的人，从来没有好下场，必将遭到人民的唾弃和历史的审判！台湾问题纯属中国内政，不容任何外来干涉。任何人都不要低估中国人民捍卫国家主权和领土完整的坚强决心、坚定意志、强大能力！祖国完全统一的历史任务一定要实现，也一定能够实现！</p>
<p>　　同志们、朋友们！</p>
<p>　　经过近代以来的长期艰苦奋斗，中国人民创造了令世界刮目相看的伟大成就，迎来了民族复兴的光明前景。实现中华民族伟大复兴是全体中华儿女的共同光荣，也是全体中华儿女的共同使命。孙中山先生说：“惟愿诸君将振兴中国之责任，置之于自身之肩上。”我呼吁，海内外全体中华儿女更加紧密地团结起来，发扬孙中山先生等辛亥革命先驱的伟大精神，携手向着中华民族伟大复兴的目标继续奋勇前进！</p>
<h4 id="在纪念五四运动100周年大会上的讲话"><strong>在纪念五四运动100周年大会上的讲话</strong></h4>
<p>共青团员们，青年朋友们，同志们：</p>
<p>100年前，中国大地爆发了震惊中外的五四运动，这是中国近现代史上具有划时代意义的一个重大事件。</p>
<p>今年是五四运动100周年，也是中华人民共和国成立70周年。在这个具有特殊意义的历史时刻，我们在这里隆重集会，缅怀五四先驱崇高的爱国情怀和革命精神，总结党和人民探索实现民族复兴道路的宝贵经验，这对发扬五四精神，激励全党全国各族人民特别是新时代中国青年为全面建成小康社会、加快建设社会主义现代化国家、实现中华民族伟大复兴的中国梦而奋斗，具有十分重大的意义。</p>
<p>青年朋友们、同志们！</p>
<p>五四运动，爆发于民族危难之际，是一场以先进青年知识分子为先锋、广大人民群众参加的彻底反帝反封建的伟大爱国革命运动，是一场中国人民为拯救民族危亡、捍卫民族尊严、凝聚民族力量而掀起的伟大社会革命运动，是一场传播新思想新文化新知识的伟大思想启蒙运动和新文化运动，以磅礴之力鼓动了中国人民和中华民族实现民族复兴的志向和信心。</p>
<p>五四运动，以彻底反帝反封建的革命性、追求救国强国真理的进步性、各族各界群众积极参与的广泛性，推动了中国社会进步，促进了马克思主义在中国的传播，促进了马克思主义同中国工人运动的结合，为中国共产党成立做了思想上干部上的准备，为新的革命力量、革命文化、革命斗争登上历史舞台创造了条件，是中国旧民主主义革命走向新民主主义革命的转折点，在近代以来中华民族追求民族独立和发展进步的历史进程中具有里程碑意义。</p>
<p>——五四运动以全民族的力量高举起爱国主义的伟大旗帜。五四运动，孕育了以爱国、进步、民主、科学为主要内容的伟大五四精神，其核心是爱国主义。爱国主义是我们民族精神的核心，是中华民族团结奋斗、自强不息的精神纽带。五四运动时，面对国家和民族生死存亡，一批爱国青年挺身而出，全国民众奋起抗争，誓言“国土不可断送、人民不可低头”，奏响了浩气长存的爱国主义壮歌。</p>
<p>历史深刻表明，爱国主义自古以来就流淌在中华民族血脉之中，去不掉，打不破，灭不了，是中国人民和中华民族维护民族独立和民族尊严的强大精神动力，只要高举爱国主义的伟大旗帜，中国人民和中华民族就能在改造中国、改造世界的拼搏中迸发出排山倒海的历史伟力！</p>
<p>——五四运动以全民族的行动激发了追求真理、追求进步的伟大觉醒。五四运动前后，我国一批先进知识分子和革命青年，在追求真理中传播新思想新文化，勇于打破封建思想的桎梏，猛烈冲击了几千年来的封建旧礼教、旧道德、旧思想、旧文化。五四运动改变了以往只有觉悟的革命者而缺少觉醒的人民大众的斗争状况，实现了中国人民和中华民族自鸦片战争以来第一次全面觉醒。经过五四运动洗礼，越来越多中国先进分子集合在马克思主义旗帜下，1921年中国共产党宣告正式成立，中国历史掀开了崭新一页。</p>
<p>历史深刻表明，有了马克思主义，有了中国共产党领导，有了中国人民和中华民族的伟大觉醒，中国人民和中华民族追求真理、追求进步的潮流从此就是任何人都阻挡不了的！</p>
<p>——五四运动以全民族的搏击培育了永久奋斗的伟大传统。早在80年前，毛泽东同志就指出：“中国的青年运动有很好的革命传统，这个传统就是‘永久奋斗’。”通过五四运动，中国青年发现了自己的力量，中国人民和中华民族发现了自己的力量。中国人民和中华民族从斗争实践中懂得，中国社会发展，中华民族振兴，中国人民幸福，必须依靠自己的英勇奋斗来实现，没有人会恩赐给我们一个光明的中国。</p>
<p>历史深刻表明，只要中国人民和中华民族勇于为改变自己的命运而奋斗牺牲，我们的国家就一定能够走向富强，我们的民族就一定能够实现伟大复兴！</p>
<p>五四运动以来的100年，是中国青年一代又一代接续奋斗、凯歌前行的100年，是中国青年用青春之我创造青春之中国、青春之民族的100年。</p>
<p>100年来，中国青年满怀对祖国和人民的赤子之心，积极投身党领导的革命、建设、改革伟大事业，为人民战斗、为祖国献身、为幸福生活奋斗，把最美好的青春献给祖国和人民，谱写了一曲又一曲壮丽的青春之歌。</p>
<p>实践充分证明，中国青年是有远大理想抱负的青年！中国青年是有深厚家国情怀的青年！中国青年是有伟大创造力的青年！无论过去、现在还是未来，中国青年始终是实现中华民族伟大复兴的先锋力量！</p>
<p>青年朋友们、同志们！</p>
<p>今天，在中国共产党领导下，我们开辟了中国特色社会主义道路，形成了中国特色社会主义理论体系，建立了中国特色社会主义制度，发展了中国特色社会主义文化，推动中国特色社会主义进入了新时代。中国人民拥有了前所未有的道路自信、理论自信、制度自信、文化自信，中华民族伟大复兴展现出前所未有的光明前景！</p>
<p>新时代中国青年运动的主题，新时代中国青年运动的方向，新时代中国青年的使命，就是坚持中国共产党领导，同人民一道，为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦而奋斗。</p>
<p>青年是整个社会力量中最积极、最有生气的力量，国家的希望在青年，民族的未来在青年。今天，新时代中国青年处在中华民族发展的最好时期，既面临着难得的建功立业的人生际遇，也面临着“天将降大任于斯人”的时代使命。新时代中国青年要继续发扬五四精神，以实现中华民族伟大复兴为己任，不辜负党的期望、人民期待、民族重托，不辜负我们这个伟大时代。</p>
<p>第一，新时代中国青年要树立远大理想。青年的理想信念关乎国家未来。青年理想远大、信念坚定，是一个国家、一个民族无坚不摧的前进动力。青年志存高远，就能激发奋进潜力，青春岁月就不会像无舵之舟漂泊不定。正所谓“立志而圣则圣矣，立志而贤则贤矣”。青年的人生目标会有不同，职业选择也有差异，但只有把自己的小我融入祖国的大我、人民的大我之中，与时代同步伐、与人民共命运，才能更好实现人生价值、升华人生境界。离开了祖国需要、人民利益，任何孤芳自赏都会陷入越走越窄的狭小天地。</p>
<p>新时代中国青年要树立对马克思主义的信仰、对中国特色社会主义的信念、对中华民族伟大复兴中国梦的信心，到人民群众中去，到新时代新天地中去，让理想信念在创业奋斗中升华，让青春在创新创造中闪光！</p>
<p>第二，新时代中国青年要热爱伟大祖国。孙中山先生说，做人最大的事情，“就是要知道怎么样爱国”。一个人不爱国，甚至欺骗祖国、背叛祖国，那在自己的国家、在世界上都是很丢脸的，也是没有立足之地的。对每一个中国人来说，爱国是本分，也是职责，是心之所系、情之所归。对新时代中国青年来说，热爱祖国是立身之本、成才之基。当代中国，爱国主义的本质就是坚持爱国和爱党、爱社会主义高度统一。</p>
<p>新时代中国青年要听党话、跟党走，胸怀忧国忧民之心、爱国爱民之情，不断奉献祖国、奉献人民，以一生的真情投入、一辈子的顽强奋斗来体现爱国主义情怀，让爱国主义的伟大旗帜始终在心中高高飘扬！</p>
<p>第三，新时代中国青年要担当时代责任。时代呼唤担当，民族振兴是青年的责任。鲁迅先生说，青年“所多的是生力，遇见深林，可以辟成平地的，遇见旷野，可以栽种树木的，遇见沙漠，可以开掘井泉的”。在实现中华民族伟大复兴的新征程上，应对重大挑战、抵御重大风险、克服重大阻力、解决重大矛盾，迫切需要迎难而上、挺身而出的担当精神。只要青年都勇挑重担、勇克难关、勇斗风险，中国特色社会主义就能充满活力、充满后劲、充满希望。青年要保持初生牛犊不怕虎、越是艰险越向前的刚健勇毅，勇立时代潮头，争做时代先锋。一切视探索尝试为畏途、一切把负重前行当吃亏、一切“躲进小楼成一统”逃避责任的思想和行为，都是要不得的，都是成不了事的，也是难以真正获得人生快乐的。</p>
<p>新时代中国青年要珍惜这个时代、担负时代使命，在担当中历练，在尽责中成长，让青春在新时代改革开放的广阔天地中绽放，让人生在实现中国梦的奋进追逐中展现出勇敢奔跑的英姿，努力成为德智体美劳全面发展的社会主义建设者和接班人！</p>
<p>第四，新时代中国青年要勇于砥砺奋斗。奋斗是青春最亮丽的底色。“自信人生二百年，会当水击三千里。”民族复兴的使命要靠奋斗来实现，人生理想的风帆要靠奋斗来扬起。没有广大人民特别是一代代青年前赴后继、艰苦卓绝的接续奋斗，就没有中国特色社会主义新时代的今天，更不会有实现中华民族伟大复兴的明天。千百年来，中华民族历经苦难，但没有任何一次苦难能够打垮我们，最后都推动了我们民族精神、意志、力量的一次次升华。今天，我们的生活条件好了，但奋斗精神一点都不能少，中国青年永久奋斗的好传统一点都不能丢。在实现中华民族伟大复兴的新征程上，必然会有艰巨繁重的任务，必然会有艰难险阻甚至惊涛骇浪，特别需要我们发扬艰苦奋斗精神。奋斗不只是响亮的口号，而是要在做好每一件小事、完成每一项任务、履行每一项职责中见精神。奋斗的道路不会一帆风顺，往往荆棘丛生、充满坎坷。强者，总是从挫折中不断奋起、永不气馁。</p>
<p>新时代中国青年要勇做走在时代前列的奋进者、开拓者、奉献者，毫不畏惧面对一切艰难险阻，在劈波斩浪中开拓前进，在披荆斩棘中开辟天地，在攻坚克难中创造业绩，用青春和汗水创造出让世界刮目相看的新奇迹！</p>
<p>第五，新时代中国青年要练就过硬本领。青年是苦练本领、增长才干的黄金时期。“青春虚度无所成，白首衔悲亦何及。”当今时代，知识更新不断加快，社会分工日益细化，新技术新模式新业态层出不穷。这既为青年施展才华、竞展风采提供了广阔舞台，也对青年能力素质提出了新的更高要求。不论是成就自己的人生理想，还是担当时代的神圣使命，青年都要珍惜韶华、不负青春，努力学习掌握科学知识，提高内在素质，锤炼过硬本领，使自己的思维视野、思想观念、认识水平跟上越来越快的时代发展。</p>
<p>新时代中国青年要增强学习紧迫感，如饥似渴、孜孜不倦学习，努力学习马克思主义立场观点方法，努力掌握科学文化知识和专业技能，努力提高人文素养，在学习中增长知识、锤炼品格，在工作中增长才干、练就本领，以真才实学服务人民，以创新创造贡献国家！</p>
<p>第六，新时代中国青年要锤炼品德修为。人无德不立，品德是为人之本。止于至善，是中华民族始终不变的人格追求。我们要建设的社会主义现代化强国，不仅要在物质上强，更要在精神上强。精神上强，才是更持久、更深沉、更有力量的。青年要把正确的道德认知、自觉的道德养成、积极的道德实践紧密结合起来，不断修身立德，打牢道德根基，在人生道路上走得更正、走得更远。面对复杂的世界大变局，要明辨是非、恪守正道，不人云亦云、盲目跟风。面对外部诱惑，要保持定力、严守规矩，用勤劳的双手和诚实的劳动创造美好生活，拒绝投机取巧、远离自作聪明。面对美好岁月，要有饮水思源、懂得回报的感恩之心，感恩党和国家，感恩社会和人民。要在奋斗中摸爬滚打，体察世间冷暖、民众忧乐、现实矛盾，从中找到人生真谛、生命价值、事业方向。</p>
<p>新时代中国青年要自觉树立和践行社会主义核心价值观，善于从中华民族传统美德中汲取道德滋养，从英雄人物和时代楷模的身上感受道德风范，从自身内省中提升道德修为，明大德、守公德、严私德，自觉抵制拜金主义、享乐主义、极端个人主义、历史虚无主义等错误思想，追求更有高度、更有境界、更有品位的人生，让清风正气、蓬勃朝气遍布全社会！</p>
<p>青年朋友们、同志们！</p>
<p>中国共产党自成立之日起，就始终把青年工作作为党的一项极为重要的工作。一代又一代中国共产党人，大多数都是在青年时代就满怀信仰和豪情加入了党组织，并为党和人民奋斗终身。党的队伍中始终活跃着怀抱崇高理想、充满奋斗精神的青年人，这是我们党历经百年风雨而始终充满生机活力的一个重要原因。中国共产党立志于中华民族千秋伟业，必须始终代表广大青年、赢得广大青年、依靠广大青年，用极大力量做好青年工作，确保党的事业薪火相传，确保中华民族永续发展。</p>
<p>把青年一代培养造就成德智体美劳全面发展的社会主义建设者和接班人，是事关党和国家前途命运的重大战略任务，是全党的共同政治责任。各级党委和政府、各级领导干部以及全社会都要充分信任青年、热情关心青年、严格要求青年，关注青年愿望、帮助青年发展、支持青年创业，做青年朋友的知心人、青年工作的热心人、青年群众的引路人。</p>
<p>我们要主动走近青年、倾听青年，做青年朋友的知心人。当代青年思想活跃、思维敏捷，观念新颖、兴趣广泛，探索未知劲头足，接受新生事物快，主体意识、参与意识强，对实现人生发展有着强烈渴望。这种青春天性赋予青年活力、激情、想象力和创造力，应该充分肯定。同时，青年人阅历不广，容易从自身角度、从理想状态的角度来认识和理解世界，难免给他们带来局限性。这是青年成长的规律，我们要尊重这个规律。信任是理解的前提。要尊重青年天性，照顾青年特点，经常到青年中去，同青年零距离接触、面对面交流，了解他们的思想动态、价值取向、行为方式、生活方式，倾听他们对社会问题和现象的看法，对党和政府工作的意见和建议。即便听到了尖锐的甚至是偏颇的批评，也要有则改之、无则加勉，成为青年愿意讲真话、交真心、诉真情的知心朋友。青年要向年长者学习，年长者也要向青年学习，相互取长补短，相互信任帮助。</p>
<p>我们要真情关心青年、关爱青年，做青年工作的热心人。青年处于人生道路的起步阶段，在学习、工作、生活方面往往会遇到各种困难和苦恼，需要社会及时伸出援手。当代青年遇到了很多我们过去从未遇到过的困难。压力是青年成长的动力，而在青年成长的关键处、要紧时拉一把、帮一下，则可能是青年顶过压力、发展成才的重要支点。我们要关注青年所思、所忧、所盼，帮助青年解决好他们在毕业求职、创新创业、社会融入、婚恋交友、老人赡养、子女教育等方面的操心事、烦心事，努力为青年创造良好发展条件，让他们感受到关爱就在身边、关怀就在眼前。</p>
<p>我们要悉心教育青年、引导青年，做青年群众的引路人。青年要顺利成长成才，就像幼苗需要精心培育，该培土时就要培土，该浇水时就要浇水，该施肥时就要施肥，该打药时就要打药，该整枝时就要整枝。要坚持关心厚爱和严格要求相统一、尊重规律和积极引领相统一，教育引导青年正确认识世界，全面了解国情，把握时代大势。既要理解青年所思所想，为他们驰骋思想打开浩瀚天空，也要积极教育引导青年，推动他们脚踏实地走上大有作为的广阔舞台。当青年思想认识陷入困惑彷徨、人生抉择处于十字路口时要鼓励他们振奋精神、勇往直前，当青年在工作上取得进步时要给予他们热情鼓励，当青年在事业上遇到困难时要帮助他们重拾信心，当青年犯了错误、做了错事时要及时指出并帮助他们纠正，对一些青年思想上的一时冲动或偏激要多教育引导，能包容要包容，多给他们一点提高自我认识的时间和空间，不要过于苛责。要积极鼓励青年到艰苦的一线吃苦磨练、增长才干，放手让青年在重要领域和重要岗位上攻坚克难、施展才华，积极为青年创造人人努力成才、人人皆可成才、人人尽展其才的发展条件。</p>
<p>青年朋友们、同志们！</p>
<p>自古英雄出少年。在漫漫历史长河中，人类社会青年英雄辈出，中华民族青年英雄辈出。《共产党宣言》发表时马克思是30岁，恩格斯是28岁。列宁最初参加革命活动时只有17岁。牛顿和莱布尼茨发现微积分时分别是22岁和28岁，达尔文开始环球航行时是22岁，爱因斯坦提出狭义相对论时是26岁。贾谊写出“西汉一代最好的政论”时不到30岁，王勃写下千古名篇《滕王阁序》时才20多岁。在我们党领导人民进行革命、建设、改革的伟大历史进程中更是青年英雄辈出。中共一大召开时毛泽东是28岁，周恩来参加中国共产党时是23岁，邓小平参加旅欧中国少年共产党时是18岁。杨靖宇牺牲时是35岁，赵一曼牺牲时是31岁，江姐牺牲时是29岁，红三十四师师长陈树湘牺牲时是29岁，邱少云牺牲时是26岁，雷锋牺牲时是22岁，黄继光牺牲时是21岁，刘胡兰牺牲时只有15岁。守岛32年的王继才第一次登上开山岛时是26岁，航天报国的嫦娥团队、神舟团队平均年龄是33岁，北斗团队平均年龄是35岁。这样的青年英杰数不胜数！我们要用欣赏和赞许的眼光看待青年的创新创造，积极支持他们在人生中出彩，为青年取得的成就和成绩点赞、喝彩，让青春成为中华民族生气勃发、高歌猛进的持久风景，让青年英雄成为驱动中华民族加速迈向伟大复兴的蓬勃力量！</p>
<p>青年朋友们、同志们！</p>
<p>共青团是党的助手和后备军，是党的青年工作的重要力量。在中国青年运动的光辉历程中，共青团发扬“党有号召、团有行动”的优良传统，为党争取青年人心、汇聚青年力量，在革命、建设、改革各个历史时期作出了积极贡献、发挥了重要作用。党旗所指就是团旗所向。共青团要毫不动摇坚持党的领导，增强“四个意识”、坚定“四个自信”、做到“两个维护”，坚定不移走中国特色社会主义群团发展道路，不断保持和增强政治性、先进性、群众性，坚持把培养社会主义建设者和接班人作为根本任务，把巩固和扩大党执政的青年群众基础作为政治责任，把围绕中心、服务大局作为工作主线，认真履行引领凝聚青年、组织动员青年、联系服务青年的职责，不断创新工作思路，增强对青年的凝聚力、组织力、号召力，团结带领新时代中国青年在实现中华民族伟大复兴中国梦的进程中不断开拓创新、奋发有为。</p>
<p>关心和支持青年是全社会的共同责任。一切党政机关、企业事业单位，人民解放军和武警部队，各人民团体和社会团体，广大城乡基层自治组织，各新经济组织和新社会组织，都要关心青年成长、支持青年发展，给予青年更多机会，更好发挥青年作用。</p>
<p>青年朋友们、同志们！</p>
<p>青年是国家的未来，也是世界的未来。中国梦与世界梦息息相通，中华民族应该对人类社会作出更大贡献。新时代中国青年，要有家国情怀，也要有人类关怀，发扬中华文化崇尚的四海一家、天下为公精神，为实现中华民族伟大复兴而奋斗，为推动共建“一带一路”、推动构建人类命运共同体而努力。</p>
<p>青年朋友们！一代人有一代人的长征，一代人有一代人的担当。建成社会主义现代化强国，实现中华民族伟大复兴，是一场接力跑。我们有决心为青年跑出一个好成绩，也期待现在的青年一代将来跑出更好的成绩。衷心希望新时代中国青年积极拥抱新时代、奋进新时代，让青春在为祖国、为人民、为民族、为人类的奉献中焕发出更加绚丽的光彩！</p>
<p>再过几天，就是五四青年节了。在这里，我代表党中央，向全国各族青年致以节日的热烈祝贺！</p>
<h4 id="在庆祝中国共产党成立100周年大会上的讲话"><strong>在庆祝中国共产党成立100周年大会上的讲话</strong></h4>
<p>同志们，朋友们：</p>
<p>　　今天，在中国共产党历史上，在中华民族历史上，都是一个十分重大而庄严的日子。我们在这里隆重集会，同全党全国各族人民一道，庆祝中国共产党成立一百周年，回顾中国共产党百年奋斗的光辉历程，展望中华民族伟大复兴的光明前景。</p>
<p>　　首先，我代表党中央，向全体中国共产党员致以节日的热烈祝贺！</p>
<p>　　在这里，我代表党和人民庄严宣告，经过全党全国各族人民持续奋斗，我们实现了第一个百年奋斗目标，在中华大地上全面建成了小康社会，历史性地解决了绝对贫困问题，正在意气风发向着全面建成社会主义现代化强国的第二个百年奋斗目标迈进。这是中华民族的伟大光荣！这是中国人民的伟大光荣！这是中国共产党的伟大光荣！</p>
<p>　　同志们、朋友们！</p>
<p>　　中华民族是世界上伟大的民族，有着5000多年源远流长的文明历史，为人类文明进步作出了不可磨灭的贡献。1840年鸦片战争以后，中国逐步成为半殖民地半封建社会，国家蒙辱、人民蒙难、文明蒙尘，中华民族遭受了前所未有的劫难。从那时起，实现中华民族伟大复兴，就成为中国人民和中华民族最伟大的梦想。</p>
<p>　　为了拯救民族危亡，中国人民奋起反抗，仁人志士奔走呐喊，太平天国运动、戊戌变法、义和团运动、辛亥革命接连而起，各种救国方案轮番出台，但都以失败而告终。中国迫切需要新的思想引领救亡运动，迫切需要新的组织凝聚革命力量。</p>
<p>　　十月革命一声炮响，给中国送来了马克思列宁主义。在中国人民和中华民族的伟大觉醒中，在马克思列宁主义同中国工人运动的紧密结合中，中国共产党应运而生。中国产生了共产党，这是开天辟地的大事变，深刻改变了近代以后中华民族发展的方向和进程，深刻改变了中国人民和中华民族的前途和命运，深刻改变了世界发展的趋势和格局。</p>
<p>　　中国共产党一经诞生，就把为中国人民谋幸福、为中华民族谋复兴确立为自己的初心使命。一百年来，中国共产党团结带领中国人民进行的一切奋斗、一切牺牲、一切创造，归结起来就是一个主题：实现中华民族伟大复兴。</p>
<p>　　——为了实现中华民族伟大复兴，中国共产党团结带领中国人民，浴血奋战、百折不挠，创造了新民主主义革命的伟大成就。我们经过北伐战争、土地革命战争、抗日战争、解放战争，以武装的革命反对武装的反革命，推翻帝国主义、封建主义、官僚资本主义三座大山，建立了人民当家作主的中华人民共和国，实现了民族独立、人民解放。新民主主义革命的胜利，彻底结束了旧中国半殖民地半封建社会的历史，彻底结束了旧中国一盘散沙的局面，彻底废除了列强强加给中国的不平等条约和帝国主义在中国的一切特权，为实现中华民族伟大复兴创造了根本社会条件。中国共产党和中国人民以英勇顽强的奋斗向世界庄严宣告，中国人民站起来了，中华民族任人宰割、饱受欺凌的时代一去不复返了！</p>
<p>　　——为了实现中华民族伟大复兴，中国共产党团结带领中国人民，自力更生、发愤图强，创造了社会主义革命和建设的伟大成就。我们进行社会主义革命，消灭在中国延续几千年的封建剥削压迫制度，确立社会主义基本制度，推进社会主义建设，战胜帝国主义、霸权主义的颠覆破坏和武装挑衅，实现了中华民族有史以来最为广泛而深刻的社会变革，实现了一穷二白、人口众多的东方大国大步迈进社会主义社会的伟大飞跃，为实现中华民族伟大复兴奠定了根本政治前提和制度基础。中国共产党和中国人民以英勇顽强的奋斗向世界庄严宣告，中国人民不但善于破坏一个旧世界、也善于建设一个新世界，只有社会主义才能救中国，只有社会主义才能发展中国！</p>
<p>　　——为了实现中华民族伟大复兴，中国共产党团结带领中国人民，解放思想、锐意进取，创造了改革开放和社会主义现代化建设的伟大成就。我们实现新中国成立以来党的历史上具有深远意义的伟大转折，确立党在社会主义初级阶段的基本路线，坚定不移推进改革开放，战胜来自各方面的风险挑战，开创、坚持、捍卫、发展中国特色社会主义，实现了从高度集中的计划经济体制到充满活力的社会主义市场经济体制、从封闭半封闭到全方位开放的历史性转变，实现了从生产力相对落后的状况到经济总量跃居世界第二的历史性突破，实现了人民生活从温饱不足到总体小康、奔向全面小康的历史性跨越，为实现中华民族伟大复兴提供了充满新的活力的体制保证和快速发展的物质条件。中国共产党和中国人民以英勇顽强的奋斗向世界庄严宣告，改革开放是决定当代中国前途命运的关键一招，中国大踏步赶上了时代！</p>
<p>　　——为了实现中华民族伟大复兴，中国共产党团结带领中国人民，自信自强、守正创新，统揽伟大斗争、伟大工程、伟大事业、伟大梦想，创造了新时代中国特色社会主义的伟大成就。党的十八大以来，中国特色社会主义进入新时代，我们坚持和加强党的全面领导，统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，坚持和完善中国特色社会主义制度、推进国家治理体系和治理能力现代化，坚持依规治党、形成比较完善的党内法规体系，战胜一系列重大风险挑战，实现第一个百年奋斗目标，明确实现第二个百年奋斗目标的战略安排，党和国家事业取得历史性成就、发生历史性变革，为实现中华民族伟大复兴提供了更为完善的制度保证、更为坚实的物质基础、更为主动的精神力量。中国共产党和中国人民以英勇顽强的奋斗向世界庄严宣告，中华民族迎来了从站起来、富起来到强起来的伟大飞跃，实现中华民族伟大复兴进入了不可逆转的历史进程！</p>
<p>　　一百年来，中国共产党团结带领中国人民，以“为有牺牲多壮志，敢教日月换新天”的大无畏气概，书写了中华民族几千年历史上最恢宏的史诗。这一百年来开辟的伟大道路、创造的伟大事业、取得的伟大成就，必将载入中华民族发展史册、人类文明发展史册！</p>
<p>　　同志们、朋友们！</p>
<p>　　一百年前，中国共产党的先驱们创建了中国共产党，形成了坚持真理、坚守理想，践行初心、担当使命，不怕牺牲、英勇斗争，对党忠诚、不负人民的伟大建党精神，这是中国共产党的精神之源。</p>
<p>　　一百年来，中国共产党弘扬伟大建党精神，在长期奋斗中构建起中国共产党人的精神谱系，锤炼出鲜明的政治品格。历史川流不息，精神代代相传。我们要继续弘扬光荣传统、赓续红色血脉，永远把伟大建党精神继承下去、发扬光大！</p>
<p>　　同志们、朋友们！</p>
<p>　　一百年来，我们取得的一切成就，是中国共产党人、中国人民、中华民族团结奋斗的结果。以毛泽东同志、邓小平同志、江泽民同志、胡锦涛同志为主要代表的中国共产党人，为中华民族伟大复兴建立了彪炳史册的伟大功勋！我们向他们表示崇高的敬意！</p>
<p>　　此时此刻，我们深切怀念为中国革命、建设、改革，为中国共产党建立、巩固、发展作出重大贡献的毛泽东、周恩来、刘少奇、朱德、邓小平、陈云同志等老一辈革命家，深切怀念为建立、捍卫、建设新中国英勇牺牲的革命先烈，深切怀念为改革开放和社会主义现代化建设英勇献身的革命烈士，深切怀念近代以来为民族独立和人民解放顽强奋斗的所有仁人志士。他们为祖国和民族建立的丰功伟绩永载史册！他们的崇高精神永远铭记在人民心中！</p>
<p>　　人民是历史的创造者，是真正的英雄。我代表党中央，向全国广大工人、农民、知识分子，向各民主党派和无党派人士、各人民团体、各界爱国人士，向人民解放军指战员、武警部队官兵、公安干警和消防救援队伍指战员，向全体社会主义劳动者，向统一战线广大成员，致以崇高的敬意！向香港特别行政区同胞、澳门特别行政区同胞和台湾同胞以及广大侨胞，致以诚挚的问候！向一切同中国人民友好相处，关心和支持中国革命、建设、改革事业的各国人民和朋友，致以衷心的谢意！</p>
<p>　　同志们、朋友们！</p>
<p>　　初心易得，始终难守。以史为鉴，可以知兴替。我们要用历史映照现实、远观未来，从中国共产党的百年奋斗中看清楚过去我们为什么能够成功、弄明白未来我们怎样才能继续成功，从而在新的征程上更加坚定、更加自觉地牢记初心使命、开创美好未来。</p>
<p>　　——以史为鉴、开创未来，必须坚持中国共产党坚强领导。办好中国的事情，关键在党。中华民族近代以来180多年的历史、中国共产党成立以来100年的历史、中华人民共和国成立以来70多年的历史都充分证明，没有中国共产党，就没有新中国，就没有中华民族伟大复兴。历史和人民选择了中国共产党。中国共产党领导是中国特色社会主义最本质的特征，是中国特色社会主义制度的最大优势，是党和国家的根本所在、命脉所在，是全国各族人民的利益所系、命运所系。</p>
<p>　　新的征程上，我们必须坚持党的全面领导，不断完善党的领导，增强“四个意识”、坚定“四个自信”、做到“两个维护”，牢记“国之大者”，不断提高党科学执政、民主执政、依法执政水平，充分发挥党总揽全局、协调各方的领导核心作用！</p>
<p>　　——以史为鉴、开创未来，必须团结带领中国人民不断为美好生活而奋斗。江山就是人民、人民就是江山，打江山、守江山，守的是人民的心。中国共产党根基在人民、血脉在人民、力量在人民。中国共产党始终代表最广大人民根本利益，与人民休戚与共、生死相依，没有任何自己特殊的利益，从来不代表任何利益集团、任何权势团体、任何特权阶层的利益。任何想把中国共产党同中国人民分割开来、对立起来的企图，都是绝不会得逞的！9500多万中国共产党人不答应！14亿多中国人民也不答应！</p>
<p>　　新的征程上，我们必须紧紧依靠人民创造历史，坚持全心全意为人民服务的根本宗旨，站稳人民立场，贯彻党的群众路线，尊重人民首创精神，践行以人民为中心的发展思想，发展全过程人民民主，维护社会公平正义，着力解决发展不平衡不充分问题和人民群众急难愁盼问题，推动人的全面发展、全体人民共同富裕取得更为明显的实质性进展！</p>
<p>　　——以史为鉴、开创未来，必须继续推进马克思主义中国化。马克思主义是我们立党立国的根本指导思想，是我们党的灵魂和旗帜。中国共产党坚持马克思主义基本原理，坚持实事求是，从中国实际出发，洞察时代大势，把握历史主动，进行艰辛探索，不断推进马克思主义中国化时代化，指导中国人民不断推进伟大社会革命。中国共产党为什么能，中国特色社会主义为什么好，归根到底是因为马克思主义行！</p>
<p>　　新的征程上，我们必须坚持马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观，全面贯彻新时代中国特色社会主义思想，坚持把马克思主义基本原理同中国具体实际相结合、同中华优秀传统文化相结合，用马克思主义观察时代、把握时代、引领时代，继续发展当代中国马克思主义、21世纪马克思主义！</p>
<p>　　——以史为鉴、开创未来，必须坚持和发展中国特色社会主义。走自己的路，是党的全部理论和实践立足点，更是党百年奋斗得出的历史结论。中国特色社会主义是党和人民历经千辛万苦、付出巨大代价取得的根本成就，是实现中华民族伟大复兴的正确道路。我们坚持和发展中国特色社会主义，推动物质文明、政治文明、精神文明、社会文明、生态文明协调发展，创造了中国式现代化新道路，创造了人类文明新形态。</p>
<p>　　新的征程上，我们必须坚持党的基本理论、基本路线、基本方略，统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，全面深化改革开放，立足新发展阶段，完整、准确、全面贯彻新发展理念，构建新发展格局，推动高质量发展，推进科技自立自强，保证人民当家作主，坚持依法治国，坚持社会主义核心价值体系，坚持在发展中保障和改善民生，坚持人与自然和谐共生，协同推进人民富裕、国家强盛、中国美丽。</p>
<p>　　中华民族拥有在5000多年历史演进中形成的灿烂文明，中国共产党拥有百年奋斗实践和70多年执政兴国经验，我们积极学习借鉴人类文明的一切有益成果，欢迎一切有益的建议和善意的批评，但我们绝不接受“教师爷”般颐指气使的说教！中国共产党和中国人民将在自己选择的道路上昂首阔步走下去，把中国发展进步的命运牢牢掌握在自己手中！</p>
<p>　　——以史为鉴、开创未来，必须加快国防和军队现代化。强国必须强军，军强才能国安。坚持党指挥枪、建设自己的人民军队，是党在血与火的斗争中得出的颠扑不破的真理。人民军队为党和人民建立了不朽功勋，是保卫红色江山、维护民族尊严的坚强柱石，也是维护地区和世界和平的强大力量。</p>
<p>　　新的征程上，我们必须全面贯彻新时代党的强军思想，贯彻新时代军事战略方针，坚持党对人民军队的绝对领导，坚持走中国特色强军之路，全面推进政治建军、改革强军、科技强军、人才强军、依法治军，把人民军队建设成为世界一流军队，以更强大的能力、更可靠的手段捍卫国家主权、安全、发展利益！</p>
<p>　　——以史为鉴、开创未来，必须不断推动构建人类命运共同体。和平、和睦、和谐是中华民族5000多年来一直追求和传承的理念，中华民族的血液中没有侵略他人、称王称霸的基因。中国共产党关注人类前途命运，同世界上一切进步力量携手前进，中国始终是世界和平的建设者、全球发展的贡献者、国际秩序的维护者！</p>
<p>　　新的征程上，我们必须高举和平、发展、合作、共赢旗帜，奉行独立自主的和平外交政策，坚持走和平发展道路，推动建设新型国际关系，推动构建人类命运共同体，推动共建“一带一路”高质量发展，以中国的新发展为世界提供新机遇。中国共产党将继续同一切爱好和平的国家和人民一道，弘扬和平、发展、公平、正义、民主、自由的全人类共同价值，坚持合作、不搞对抗，坚持开放、不搞封闭，坚持互利共赢、不搞零和博弈，反对霸权主义和强权政治，推动历史车轮向着光明的目标前进！</p>
<p>　　中国人民是崇尚正义、不畏强暴的人民，中华民族是具有强烈民族自豪感和自信心的民族。中国人民从来没有欺负、压迫、奴役过其他国家人民，过去没有，现在没有，将来也不会有。同时，中国人民也绝不允许任何外来势力欺负、压迫、奴役我们，谁妄想这样干，必将在14亿多中国人民用血肉筑成的钢铁长城面前碰得头破血流！</p>
<p>　　——以史为鉴、开创未来，必须进行具有许多新的历史特点的伟大斗争。敢于斗争、敢于胜利，是中国共产党不可战胜的强大精神力量。实现伟大梦想就要顽强拼搏、不懈奋斗。今天，我们比历史上任何时期都更接近、更有信心和能力实现中华民族伟大复兴的目标，同时必须准备付出更为艰巨、更为艰苦的努力。</p>
<p>　　新的征程上，我们必须增强忧患意识、始终居安思危，贯彻总体国家安全观，统筹发展和安全，统筹中华民族伟大复兴战略全局和世界百年未有之大变局，深刻认识我国社会主要矛盾变化带来的新特征新要求，深刻认识错综复杂的国际环境带来的新矛盾新挑战，敢于斗争，善于斗争，逢山开道、遇水架桥，勇于战胜一切风险挑战！</p>
<p>　　——以史为鉴、开创未来，必须加强中华儿女大团结。在百年奋斗历程中，中国共产党始终把统一战线摆在重要位置，不断巩固和发展最广泛的统一战线，团结一切可以团结的力量、调动一切可以调动的积极因素，最大限度凝聚起共同奋斗的力量。爱国统一战线是中国共产党团结海内外全体中华儿女实现中华民族伟大复兴的重要法宝。</p>
<p>　　新的征程上，我们必须坚持大团结大联合，坚持一致性和多样性统一，加强思想政治引领，广泛凝聚共识，广聚天下英才，努力寻求最大公约数、画出最大同心圆，形成海内外全体中华儿女心往一处想、劲往一处使的生动局面，汇聚起实现民族复兴的磅礴力量！</p>
<p>　　——以史为鉴、开创未来，必须不断推进党的建设新的伟大工程。勇于自我革命是中国共产党区别于其他政党的显著标志。我们党历经千锤百炼而朝气蓬勃，一个很重要的原因就是我们始终坚持党要管党、全面从严治党，不断应对好自身在各个历史时期面临的风险考验，确保我们党在世界形势深刻变化的历史进程中始终走在时代前列，在应对国内外各种风险挑战的历史进程中始终成为全国人民的主心骨！</p>
<p>　　新的征程上，我们要牢记打铁必须自身硬的道理，增强全面从严治党永远在路上的政治自觉，以党的政治建设为统领，继续推进新时代党的建设新的伟大工程，不断严密党的组织体系，着力建设德才兼备的高素质干部队伍，坚定不移推进党风廉政建设和反腐败斗争，坚决清除一切损害党的先进性和纯洁性的因素，清除一切侵蚀党的健康肌体的病毒，确保党不变质、不变色、不变味，确保党在新时代坚持和发展中国特色社会主义的历史进程中始终成为坚强领导核心！</p>
<p>　　同志们、朋友们！</p>
<p>　　我们要全面准确贯彻“一国两制”、“港人治港”、“澳人治澳”、高度自治的方针，落实中央对香港、澳门特别行政区全面管治权，落实特别行政区维护国家安全的法律制度和执行机制，维护国家主权、安全、发展利益，维护特别行政区社会大局稳定，保持香港、澳门长期繁荣稳定。</p>
<p>　　解决台湾问题、实现祖国完全统一，是中国共产党矢志不渝的历史任务，是全体中华儿女的共同愿望。要坚持一个中国原则和“九二共识”，推进祖国和平统一进程。包括两岸同胞在内的所有中华儿女，要和衷共济、团结向前，坚决粉碎任何“台独”图谋，共创民族复兴美好未来。任何人都不要低估中国人民捍卫国家主权和领土完整的坚强决心、坚定意志、强大能力！</p>
<p>　　同志们、朋友们！</p>
<p>　　未来属于青年，希望寄予青年。一百年前，一群新青年高举马克思主义思想火炬，在风雨如晦的中国苦苦探寻民族复兴的前途。一百年来，在中国共产党的旗帜下，一代代中国青年把青春奋斗融入党和人民事业，成为实现中华民族伟大复兴的先锋力量。新时代的中国青年要以实现中华民族伟大复兴为己任，增强做中国人的志气、骨气、底气，不负时代，不负韶华，不负党和人民的殷切期望！</p>
<p>　　同志们、朋友们！</p>
<p>　　一百年前，中国共产党成立时只有50多名党员，今天已经成为拥有9500多万名党员、领导着14亿多人口大国、具有重大全球影响力的世界第一大执政党。</p>
<p>　　一百年前，中华民族呈现在世界面前的是一派衰败凋零的景象。今天，中华民族向世界展现的是一派欣欣向荣的气象，正以不可阻挡的步伐迈向伟大复兴。</p>
<p>　　过去一百年，中国共产党向人民、向历史交出了一份优异的答卷。现在，中国共产党团结带领中国人民又踏上了实现第二个百年奋斗目标新的赶考之路。</p>
<p>　　全体中国共产党员！党中央号召你们，牢记初心使命，坚定理想信念，践行党的宗旨，永远保持同人民群众的血肉联系，始终同人民想在一起、干在一起，风雨同舟、同甘共苦，继续为实现人民对美好生活的向往不懈努力，努力为党和人民争取更大光荣！</p>
<p>　　同志们、朋友们！</p>
<p>　　中国共产党立志于中华民族千秋伟业，百年恰是风华正茂！回首过去，展望未来，有中国共产党的坚强领导，有全国各族人民的紧密团结，全面建成社会主义现代化强国的目标一定能够实现，中华民族伟大复兴的中国梦一定能够实现！</p>
<p>　　伟大、光荣、正确的中国共产党万岁！</p>
<p>　　伟大、光荣、英雄的中国人民万岁！</p>
<h4 id="在纪念红军长征胜利80周年大会上的讲话"><strong>在纪念红军长征胜利80周年大会上的讲话</strong></h4>
<p>同志们：</p>
<p>今天，我们在这里隆重集会，纪念中国工农红军长征胜利80周年。</p>
<p>红军长征的那个年代，中国处在半殖民地半封建社会的黑暗境地，社会危机四伏，日寇野蛮侵略，国民党反动派置民族危亡于不顾，向革命根据地连续发动大规模“围剿”，中国共产党和红军到了危急关头，中国革命到了危急关头，中华民族到了危急关头。</p>
<p>面对生死存亡的严峻考验，从1934年10月至1936年10月，红军第一、第二、第四方面军和第二十五军进行了伟大的长征。我们党领导红军，以非凡的智慧和大无畏的英雄气概，战胜千难万险，付出巨大牺牲，胜利完成震撼世界、彪炳史册的长征，宣告了国民党反动派消灭中国共产党和红军的图谋彻底失败，宣告了中国共产党和红军肩负着民族希望胜利实现了北上抗日的战略转移，实现了中国共产党和中国革命事业从挫折走向胜利的伟大转折，开启了中国共产党为实现民族独立、人民解放而斗争的新的伟大进军。</p>
<p>这一惊天动地的革命壮举，是中国共产党和红军谱写的壮丽史诗，是中华民族伟大复兴历史进程中的巍峨丰碑。</p>
<p>在这里，我代表党中央、国务院和中央军委，代表全党全军全国各族人民，向领导红军创造这一历史伟业的毛泽东、周恩来、朱德同志等老一辈革命家，向在长征中浴血奋战和在各地坚持革命斗争的红军指战员，向当年支援红军长征的各族人民特别是各革命根据地人民，向所有健在的红军老战士，致以崇高的敬意！</p>
<p>我提议，全体起立，为在长征途中和在各地革命斗争中英勇牺牲的革命烈士默哀！</p>
<p>同志们！</p>
<p>穿越历史的沧桑巨变，回望80年前那段苦难和辉煌，我们更加深刻地认识到，长征在我们党、国家、军队发展史上具有十分伟大的意义，对中华民族历史进程具有十分深远的影响。</p>
<p>——长征是一次理想信念的伟大远征。崇高的理想，坚定的信念，永远是中国共产党人的政治灵魂。中国共产党从成立之日起，就把共产主义确立为远大理想，始终团结带领中国人民朝着这个伟大理想前行。党和红军几经挫折而不断奋起，历尽苦难而淬火成钢，归根到底在于心中的远大理想和革命信念始终坚定执着，始终闪耀着火热的光芒。</p>
<p>长征途中，英雄的红军，血战湘江，四渡赤水，巧渡金沙江，强渡大渡河，飞夺泸定桥，鏖战独树镇，勇克包座，转战乌蒙山，击退上百万穷凶极恶的追兵阻敌，征服空气稀薄的冰山雪岭，穿越渺无人烟的沼泽草地，纵横十余省，长驱二万五千里。主力红军长征后，留在根据地的红军队伍和游击队，在极端困难的条件下，紧紧依靠人民群众，坚持游击战争。西北地区红军创建陕甘革命根据地，同先期到达陕北的红二十五军一起打破了敌人的重兵“围剿”，为党中央把中国革命的大本营安置在西北创造了条件。东北抗日联军、坚持在国民党统治区工作的党组织以及党领导的各方面力量都进行了艰苦卓绝的斗争，都为长征胜利作出了不可磨灭的贡献。</p>
<p>长征的胜利，是中国共产党人理想的胜利，是中国共产党人信念的胜利。“风雨浸衣骨更硬，野菜充饥志越坚；官兵一致同甘苦，革命理想高于天。”在风雨如磐的长征路上，崇高的理想，坚定的信念，激励和指引着红军一路向前。在红一方面军二万五千里的征途上，平均每300米就有一名红军牺牲。长征这条红飘带，是无数红军的鲜血染成的。艰难可以摧残人的肉体，死亡可以夺走人的生命，但没有任何力量能够动摇中国共产党人的理想信念。</p>
<p>长征的胜利，靠的是红军将士压倒一切敌人而不被任何敌人所压倒、征服一切困难而不被任何困难所征服的英雄气概和革命精神。长征向全中国、向全世界庄严宣告，中国共产党及其领导的人民军队，是用马克思主义武装的、以共产主义为崇高理想和坚定信念的。长征路上的苦难、曲折、死亡，检验了中国共产党人的理想信念，向世人证明了中国共产党人的理想信念是坚不可摧的。</p>
<p>——长征是一次检验真理的伟大远征。真理只有在实践中才能得到检验，真理只有在实践中才能得到确立。长征途中，红军面临着凶恶残暴的追兵阻敌，面临着严酷恶劣的自然环境，还面临着同党内错误思想的激烈斗争。经过长征，党和红军不是弱了，而是更强了，因为我们党找到了中国革命的正确道路，找到了指引这条道路的正确理论。</p>
<p>长征途中，党中央召开的遵义会议，是我们党历史上一个生死攸关的转折点。这次会议确立了毛泽东同志在红军和党中央的领导地位，开始确立了以毛泽东同志为主要代表的马克思主义正确路线在党中央的领导地位，开始形成以毛泽东同志为核心的党的第一代中央领导集体，这是我们党和革命事业转危为安、不断打开新局面最重要的保证。</p>
<p>长征的胜利，使我们党进一步认识到，只有把马克思列宁主义基本原理同中国革命具体实际结合起来，独立自主解决中国革命的重大问题，才能把革命事业引向胜利。这是在血的教训和斗争考验中得出的真理。</p>
<p>长征的胜利，实现了在追求真理、坚持真理的基础上全党的空前团结、红军的空前团结。没有这种思想上政治上的大团结，中国革命胜利是不可能实现的。经过长征的千锤百炼，我们党在思想上不断成熟，成为中国人民进行抗日战争的中流砥柱，成为中国革命赢得最后胜利的中坚力量。</p>
<p>——长征是一次唤醒民众的伟大远征。红军打胜仗，人民是靠山。长征是历史纪录上的第一次，长征是宣言书，长征是宣传队，长征是播种机。面对正义和邪恶两种力量的交锋、光明和黑暗两种前途的抉择，我们党始终植根于人民，联系群众、宣传群众、武装群众、团结群众、依靠群众，以自己的模范行动，赢得人民群众真心拥护和支持，广大人民群众是长征胜利的力量源泉。</p>
<p>长征途中，我们党高举全民族团结抗战的大旗，推动了抗日民族统一战线的形成，吹响了全民族觉醒和奋起的号角，汇聚起团结抗日、一致对外的强大力量。广大人民群众深刻认识到，中国共产党是为人民谋利益的党，红军是人民的军队、真正抗日的力量，中国共产党指引的道路是人民群众翻身得解放的正确道路。</p>
<p>长征的胜利，宣传了我们党的主张，播撒下革命的火种，扩大了党和红军的影响，巩固了党同人民群众的血肉联系，使党牢牢扎根在人民之中。</p>
<p>长征的胜利，充分展示了中国共产党性质和宗旨的力量，充分说明了中国共产党必须在人民中间生根开花，必须紧紧依靠人民来克服困难、赢得胜利。</p>
<p>——长征是一次开创新局的伟大远征。长征的胜利，是方向和道路的胜利。长征的过程，不仅是战胜敌人、赢得胜利、实现战略目标的过程，而且是联系实际、创新理论、探索革命道路的过程。长征出发前，由于党内“左”倾教条主义的错误领导，中央革命根据地第五次反“围剿”失败，其他根据地也遭受挫折，中国革命面临着方向和道路的抉择。面对乱云飞渡、惊涛骇浪，我们党表现出无所畏惧的伟大实践精神，表现出浴火重生的伟大创造精神，在血与火中趟出了一条走向新生、走向胜利的革命道路。</p>
<p>长征途中，我们党通过艰苦卓绝的实践探索，成功把解决生存危机同拯救民族危亡联系在一起，把长征的大方向同建立抗日前进阵地联系在一起，实现了国内革命战争向抗日民族战争的转变，为夺取中国人民抗日战争胜利、进而夺取新民主主义革命胜利打下了坚实基础。</p>
<p>长征的胜利，不仅保存了革命力量，而且使我们党找到了中国革命力量生存发展新的落脚点，找到了中国革命事业胜利前进新的出发点。从长征的终点出发，我们党领导中国人民展开了中国革命波澜壮阔的新画卷。</p>
<p>长征的胜利，使我们党以陕甘宁革命根据地为中心，推动一大批革命根据地如雨后春笋般建立和发展起来，革命的火种在神州大地渐成燎原之势，有力推动了新的革命高潮到来。</p>
<p>同志们！</p>
<p>“艰难困苦，玉汝于成。”长征历时之长、规模之大、行程之远、环境之险恶、战斗之惨烈，在中国历史上是绝无仅有的，在世界战争史乃至人类文明史上也是极为罕见的。</p>
<p>在漫漫征途中，红军将士同敌人进行了600余次战役战斗，跨越近百条江河，攀越40余座高山险峰，其中海拔4000米以上的雪山就有20余座，穿越了被称为“死亡陷阱”的茫茫草地，用顽强意志征服了人类生存极限。红军将士上演了世界军事史上威武雄壮的战争活剧，创造了气吞山河的人间奇迹。</p>
<p>80年来，世界范围内关于红军长征的报道和研究层出不穷，慕名前来寻访长征路的人络绎不绝。国际社会越来越多的人认为，红军长征是20世纪最能影响世界前途的重要事件之一，是充满理想和献身精神、用意志和勇气谱写的人类史诗。长征迸发出的激荡人心的强大力量，跨越时空，跨越民族，是人类为追求真理和光明而不懈努力的伟大史诗。</p>
<p>同志们！</p>
<p>长征这一人类历史上的伟大壮举，留给我们最可宝贵的精神财富，就是中国共产党人和红军将士用生命和热血铸就的伟大长征精神。</p>
<p>伟大长征精神，就是把全国人民和中华民族的根本利益看得高于一切，坚定革命的理想和信念，坚信正义事业必然胜利的精神；就是为了救国救民，不怕任何艰难险阻，不惜付出一切牺牲的精神；就是坚持独立自主、实事求是，一切从实际出发的精神；就是顾全大局、严守纪律、紧密团结的精神；就是紧紧依靠人民群众，同人民群众生死相依、患难与共、艰苦奋斗的精神。</p>
<p>伟大长征精神，是中国共产党人及其领导的人民军队革命风范的生动反映，是中华民族自强不息的民族品格的集中展示，是以爱国主义为核心的民族精神的最高体现。</p>
<p>人无精神则不立，国无精神则不强。精神是一个民族赖以长久生存的灵魂，唯有精神上达到一定的高度，这个民族才能在历史的洪流中屹立不倒、奋勇向前。伟大长征精神，作为中国共产党人红色基因和精神族谱的重要组成部分，已经深深融入中华民族的血脉和灵魂，成为社会主义核心价值观的丰富滋养，成为鼓舞和激励中国人民不断攻坚克难、从胜利走向胜利的强大精神动力。</p>
<p>同志们！</p>
<p>历史是人民创造的，英雄的人民创造英雄的历史。今天中国的进步和发展，就是从长征中走出来的。</p>
<p>早在新中国成立前夕，毛泽东同志就告诫我们：“夺取全国胜利，这只是万里长征走完了第一步。”新中国成立后，经过艰苦摸索和曲折实践，我们开启了改革开放新时代，迈上了建设中国特色社会主义新长征之路。</p>
<p>改革开放30多年来，在中国共产党领导下，全国各族人民团结一心、艰苦奋斗，我国改革开放和社会主义现代化事业加速发展，人民生活得到根本改善，我国社会主义制度极大巩固和发展，我们迎来了中华民族实现伟大复兴的光明前景。</p>
<p>坚持和发展中国特色社会主义是一项长期的艰巨的历史任务。邓小平同志说：“我们搞社会主义才几十年，还处在初级阶段。巩固和发展社会主义制度，还需要一个很长的历史阶段，需要我们几代人、十几代人，甚至几十代人坚持不懈地努力奋斗，决不能掉以轻心。”</p>
<p>历史是不断向前的，要达到理想的彼岸，就要沿着我们确定的道路不断前进。每一代人有每一代人的长征路，每一代人都要走好自己的长征路。今天，我们这一代人的长征，就是要实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦。</p>
<p>今天的长征同当年的红军长征相比，同改革开放以来我们已经走过的新长征之路相比，虽然在环境、条件、任务、力量等方面有一些差异甚至有很大不同，但都是具有开创性、艰巨性、复杂性的事业。</p>
<p>实现伟大的理想，没有平坦的大道可走。夺取坚持和发展中国特色社会主义伟大事业新进展，夺取推进党的建设新的伟大工程新成效，夺取具有许多新的历史特点的伟大斗争新胜利，我们还有许多“雪山”、“草地”需要跨越，还有许多“娄山关”、“腊子口”需要征服，一切贪图安逸、不愿继续艰苦奋斗的想法都是要不得的，一切骄傲自满、不愿继续开拓前进的想法都是要不得的。</p>
<p>长征永远在路上。一个不记得来路的民族，是没有出路的民族。不论我们的事业发展到哪一步，不论我们取得了多大成就，我们都要大力弘扬伟大长征精神，在新的长征路上继续奋勇前进。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须坚定共产主义远大理想和中国特色社会主义共同理想，为崇高理想信念而矢志奋斗。长征胜利启示我们：心中有信仰，脚下有力量；没有牢不可破的理想信念，没有崇高理想信念的有力支撑，要取得长征胜利是不可想象的。邓小平同志说：“过去我们党无论怎样弱小，无论遇到什么困难，一直有强大的战斗力，因为我们有马克思主义和共产主义的信念。有了共同的理想，也就有了铁的纪律。无论过去、现在和将来，这都是我们的真正优势。”</p>
<p>在新的长征路上，我们一定要保持理想信念坚定，不论时代如何变化，不论条件如何变化，都风雨如磐不动摇，自觉做共产主义远大理想和中国特色社会主义共同理想的坚定信仰者、忠实实践者，永远为了真理而斗争，永远为了理想而斗争。</p>
<p>“石可破也，而不可夺坚；丹可磨也，而不可夺赤。”理想信念的坚定，来自思想理论的坚定。认识真理，掌握真理，信仰真理，捍卫真理，是坚定理想信念的精神前提。中国共产党人的理想信念，建立在马克思主义科学真理的基础之上，建立在马克思主义揭示的人类社会发展规律的基础之上，建立在为最广大人民谋利益的崇高价值的基础之上。我们坚定，是因为我们追求的是真理。我们坚定，是因为我们遵循的是规律。我们坚定，是因为我们代表的是最广大人民根本利益。</p>
<p>坚定理想信念，就要深入学习马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观，深入学习党的十八大以来党中央治国理政新理念新思想新战略，让真理武装我们的头脑，让真理指引我们的理想，让真理坚定我们的信仰。要坚持学而信、学而思、学而行，把学习成果转化为不可撼动的理想信念，转化为正确的世界观、人生观、价值观，用理想之光照亮奋斗之路，用信仰之力开创美好未来。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须坚定中国特色社会主义道路自信、理论自信、制度自信、文化自信，为夺取中国特色社会主义伟大事业新胜利而矢志奋斗。长征胜利启示我们：只有掌握科学理论才能把握正确前进方向；只有立足实际、独立自主开辟前进道路，才能不断走向胜利。长征走过的道路，不仅翻越了千山万水，而且翻越了把马克思主义当做一成不变的教条的错误思想障碍。长征给我们的根本经验和启示，就是要坚持马克思主义基本原理同中国具体实际相结合，坚定不移走符合中国国情的革命、建设、改革道路。</p>
<p>在新的长征路上，我们要坚信，中国特色社会主义道路是实现社会主义现代化的必由之路，是指引中国人民创造自己美好生活的必由之路。中国特色社会主义理论体系是指导党和人民沿着中国特色社会主义道路实现中华民族伟大复兴的正确理论，是立于时代前沿、与时俱进的科学理论。中国特色社会主义制度是当代中国发展进步的根本制度保障，是具有鲜明中国特色、明显制度优势、强大自我完善能力的先进制度。中国特色社会主义文化积淀着中华民族最深层的精神追求，代表着中华民族独特的精神标识，是中国人民胜利前行的强大精神力量。这一点，不仅已经在理论上被证明是正确的，而且在实践上也被证明是正确的。</p>
<p>中国特色社会主义，承载着几代中国共产党人的理想和探索，寄托着无数仁人志士的夙愿和期盼，凝聚着亿万人民的奋斗和牺牲，是近代以来中国社会发展的必然选择。我们强调坚定道路自信、理论自信、制度自信、文化自信，不是说就固步自封、不思进取了，我们必须不断有所发现、有所发明、有所创造、有所前进，使中国特色社会主义永远充满蓬勃生机活力。同时，我们要永远记住，我们所进行的一切完善和改进，都是在既定方向上的继续前进，而不是改变方向，更不是要丢掉我们党、国家、人民安身立命的根本。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须把人民放在心中最高位置，坚持一切为了人民、一切依靠人民，为人民过上更加美好生活而矢志奋斗。长征胜利启示我们：人民群众有着无尽的智慧和力量，只有始终相信人民，紧紧依靠人民，充分调动广大人民的积极性、主动性、创造性，才能凝聚起众志成城的磅礴之力。一部红军长征史，就是一部反映军民鱼水情深的历史。在湖南汝城县沙洲村，3名女红军借宿徐解秀老人家中，临走时，把自己仅有的一床被子剪下一半给老人留下了。老人说，什么是共产党？共产党就是自己有一条被子，也要剪下半条给老百姓的人。同人民风雨同舟、血脉相通、生死与共，是中国共产党和红军取得长征胜利的根本保证，也是我们战胜一切困难和风险的根本保证。中国共产党之所以能够发展壮大，中国特色社会主义之所以能够不断前进，正是因为依靠了人民。中国共产党之所以能够得到人民拥护，中国特色社会主义之所以能够得到人民支持，也正是因为造福了人民。</p>
<p>在新的长征路上，全党必须牢记，为什么人、靠什么人的问题，是检验一个政党、一个政权性质的试金石。我们要始终把人民立场作为根本政治立场，把人民利益摆在至高无上的地位，不断把为人民造福事业推向前进。我们要团结带领全体人民，以自己的辛勤劳动和不懈努力，不断保障和改善民生，让改革发展成果更多更公平惠及全体人民，朝着实现全体人民共同富裕的目标稳步迈进。</p>
<p>“水能载舟，亦能覆舟。”这个道理我们必须牢记，任何时候都不能忘却。老百姓是天，老百姓是地。忘记了人民，脱离了人民，我们就会成为无源之水、无本之木，就会一事无成。我们要坚持党的群众路线，始终保持党同人民群众的血肉联系，始终接受人民群众批评和监督，心中常思百姓疾苦，脑中常谋富民之策，使我们党永远赢得人民群众信任和拥护，使我们的事业始终拥有不竭的力量源泉。</p>
<p>团结是战胜一切困难的强大力量，是凝聚人心、成就伟业的重要保证。在为中华民族伟大复兴而奋斗的征程中，我们一定要巩固全国各族人民大团结，增强各党派、各团体、各民族、各阶层以及各方面的团结，坚决维护国家统一和社会和谐稳定，坚决反对任何破坏统一和团结的分裂活动。我们要凝聚起全体人民智慧和力量，激发出全社会创造活力和发展动力，让全体中华儿女万众一心、团结奋斗迸发出来的磅礴力量成为实现中华民族伟大复兴的强大动力。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须把握方向、统揽大局、统筹全局，为实现我们的总任务、总布局、总目标而矢志奋斗。长征胜利启示我们：一个党要立于不败之地，必须立于时代潮头，紧扣新的历史特点，科学谋划全局，牢牢把握战略主动，坚定不移实现我们的战略目标。长征走的是高山峻岭，渡的是大河险滩，过的是草地荒原，但每一个行程、每一次突围、每一场战斗都从战略全局出发，既赢得了战争胜利，也赢得了战略主动。这既是一种精神，也是一种智慧。</p>
<p>在新的长征路上，我们要立足世情国情党情，统筹国内国际两个大局，统筹党和国家事业发展全局，协调推进各项事业发展，抓住战略重点，实现关键突破，赢得战略主动，防范系统性风险，避免颠覆性危机，维护好发展全局。</p>
<p>坚持和发展中国特色社会主义，总任务是实现社会主义现代化和中华民族伟大复兴。我们必须统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，一心一意为实现“两个一百年”奋斗目标而努力工作，不断把完成总任务的历史进程推向前进。发展对坚持和发展中国特色社会主义具有决定性意义，我们必须坚持以经济建设为中心，坚持以新发展理念引领经济发展新常态，破解发展难题，厚植发展优势，不断为坚持和发展中国特色社会主义奠定强大物质基础。改革是决定当代中国命运的关键一招，我们必须坚定不移高举改革旗帜，坚决冲破思想观念束缚，坚决破除利益固化藩篱，坚决清除妨碍生产力发展和社会进步的体制机制障碍，不断推进国家治理体系和治理能力现代化。创新是引领发展的第一动力，我们必须解放思想、实事求是、与时俱进，坚定不移推进理论创新、实践创新、制度创新以及其他各方面创新，让党和国家事业始终充满创造活力、不断打开创新局面。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须建设同我国国际地位相称、同国家安全和发展利益相适应的巩固国防和强大军队，为维护国家安全和世界和平而矢志奋斗。长征胜利启示我们：人民军队是革命的依托、民族的希望，党对军队绝对领导是人民军队赢得胜利的根本保证。长征锻炼了人民军队，长征磨练了人民军队，长征成就了人民军队，长征开启了人民军队发展的新起点。长征是人民军队的光荣，光荣的人民军队必须永远继承红军长征的伟大精神和优良作风。</p>
<p>在新的长征路上，我们要坚持以党在新形势下的强军目标为引领，深入贯彻新形势下军事战略方针，努力建设世界一流军队。</p>
<p>强国必须强军，军强才能国安。要紧紧扭住政治建军不放松，坚持党对军队的绝对领导，永葆人民军队性质、宗旨、本色，永远做红军的传人，着力培养有灵魂、有本事、有血性、有品德的新一代革命军人，努力锻造具有铁一般信仰、铁一般信念、铁一般纪律、铁一般担当的过硬部队。要紧紧扭住改革强军不放松，坚定不移深化国防和军队改革，着力解决制约国防和军队建设的体制性障碍、结构性矛盾、政策性问题，深入推进军队组织形态现代化，加快构建中国特色现代军事力量体系。要紧紧扭住依法治军不放松，着力构建中国特色军事法治体系，推动实现治军方式的根本性转变，提高国防和军队建设法治化水平。要紧紧扭住备战打仗不放松，坚持战斗力这个唯一的根本标准，拓展和深化军事斗争准备，加强实战化军事训练，加快提升打赢信息化战争能力。要深入贯彻军民融合发展战略，更好把国防和军队建设融入国家经济社会发展体系，形成全要素、多领域、高效益的军民融合深度发展格局。要加强国防动员和后备力量建设，巩固和发展军政军民团结。要加强国际军事安全合作，积极履行同中国国际地位相适应的责任和义务，同世界各国一道共同应对全球性安全挑战，为维护世界和平作出更大贡献。全军要增强忧患意识、危机意识、使命意识，以只争朝夕的精神推进国防和军队现代化，担负起维护国家主权、安全、发展利益的重大责任。</p>
<p>——弘扬伟大长征精神，走好今天的长征路，必须加强党的领导，坚持全面从严治党，为推进党的建设新的伟大工程而矢志奋斗。长征胜利启示我们：党的领导是党和人民事业成功的根本保证。毛泽东同志指出：“谁使长征胜利的呢？是共产党。没有共产党，这样的长征是不可能设想的。中国共产党，它的领导机关，它的干部，它的党员，是不怕任何艰难困苦的。”中国共产党的领导，是中国革命、建设、改革不断取得胜利最根本的保证，是中国特色社会主义最本质的特征，也是中国特色社会主义的最大优势，必须毫不动摇坚持和完善。</p>
<p>在新的长征路上，全党同志都要自觉坚持和维护党的领导，自觉站在党和人民立场上，对党忠诚、为党分忧、为党担责、为党尽责，竭尽全力完成党交给的职责和任务，通过全党共同努力，使我们党永远同人民在一起、永远走在时代前列。</p>
<p>“自知者英，自胜者雄。”民族复兴梦想越接近，改革开放任务越繁重，越要加强党的建设。安不忘危，才是生存发展之道。我们党面临的“四大考验”、“四种危险”是长期的、复杂的、严峻的。要坚持党中央集中统一领导，在各级党组织和广大党员、干部中强化政治意识、大局意识、核心意识、看齐意识，确保在思想上政治上行动上始终同党中央保持高度一致。要继续推进全面从严治党，牢牢把握加强党的执政能力建设和先进性建设这条主线，加强和规范新形势下党内政治生活，坚定不移推进党风廉政建设和反腐败斗争，不断增强党自我净化、自我完善、自我革新、自我提高能力，提高党的领导水平和执政水平、增强拒腐防变和抵御风险能力，确保党始终成为中国特色社会主义事业的坚强领导核心。</p>
<p>弘扬伟大长征精神，走好今天的长征路，是新的时代条件下我们面临的一个重大课题。伟大长征精神，是党和人民付出巨大代价、进行伟大斗争获得的宝贵精神财富，我们世世代代都要牢记伟大长征精神、学习伟大长征精神、弘扬伟大长征精神，使之成为我们党、我们国家、我们人民、我们军队、我们民族不断走向未来的强大精神动力。</p>
<p>同志们！</p>
<p>长征胜利80年来，我们党团结带领全国各族人民，不断推进革命、建设、改革伟大事业，进行了一次又一次波澜壮阔的伟大长征，夺取了一个又一个举世瞩目的伟大胜利。</p>
<p>现在，我们比历史上任何时期都更接近中华民族伟大复兴的目标，比历史上任何时期都更有信心、有能力实现这个目标。我们这一代人，继承了前人的事业，进行着今天的奋斗，更要开辟明天的道路。</p>
<p>蓝图已绘就，奋进正当时。前进道路上，我们要大力弘扬伟大长征精神，激励和鼓舞全党全军全国各族人民特别是青年一代发愤图强、奋发有为，继续把革命前辈开创的伟大事业推向前进，在实现“两个一百年”奋斗目标、实现中华民族伟大复兴中国梦新的长征路上续写新的篇章、创造新的辉煌！</p>
<h4 id="在纪念中国人民抗日战争暨世界反法西斯战争胜利75周年座谈会上的讲话">在纪念中国人民抗日战争暨世界反法西斯战争胜利75周年座谈会上的讲话</h4>
<p>同胞们，同志们，朋友们：</p>
<p>今天，我们在这里隆重集会，纪念中国人民抗日战争暨世界反法西斯战争胜利75周年。</p>
<p>75年前的今天，中国人民同世界人民一道，以顽强的意志和英勇的斗争，彻底打败了法西斯主义，取得了正义战胜邪恶、光明战胜黑暗、进步战胜反动的伟大胜利！</p>
<p>75年前的今天，中国人民经过14年不屈不挠的浴血奋战，打败了穷凶极恶的日本军国主义侵略者，取得了中国人民抗日战争的伟大胜利！</p>
<p>这是近代以来中国人民反抗外敌入侵持续时间最长、规模最大、牺牲最多的民族解放斗争，也是第一次取得完全胜利的民族解放斗争。这个伟大胜利，是中华民族从近代以来陷入深重危机走向伟大复兴的历史转折点、也是世界反法西斯战争胜利的重要组成部分，是中国人民的胜利、也是世界人民的胜利。</p>
<p>中国人民抗日战争的伟大胜利，将永远铭刻在中华民族史册上！永远铭刻在人类正义事业史册上！</p>
<p>在这里，我代表中共中央、全国人大、国务院、全国政协、中央军委，向全国参加过抗日战争的老战士、老同志、爱国人士和抗日将领，向为中国人民抗日战争胜利建立了历史功勋的海内外中华儿女，致以崇高的敬意！向支援和帮助过中国人民抗日战争的外国政府和国际友人，表示衷心的感谢！向为了胜利而壮烈牺牲的所有英灵，向惨遭侵略者杀戮的死难者，表示深切的哀悼！</p>
<p>同胞们、同志们、朋友们！</p>
<p>中华文明生生不息5000多年，中国人民以非凡的创造力为人类文明进步作出了不可磨灭的贡献。但是，1840年以后，由于列强的侵略和封建统治的腐朽，中国饱经沧桑磨难，中国人民遭受深重苦难。日本对华持续侵略是近代以来中国历史上最黑暗的一页，日本反动统治者一次次侵略中国，1894年挑起甲午战争，1895年侵占台湾和澎湖列岛，1900年伙同其他帝国主义列强侵入北京，1904年发动日俄战争、侵犯中国东北领土和主权，1914年侵占青岛，1915年提出“二十一条”，1931年策动九一八事变、侵占中国东北全境，1935年制造华北事变，1937年7月7日以炮轰宛平县城和进攻卢沟桥为标志发动全面侵华战争，妄图变中国为其独占的殖民地，进而吞并亚洲、称霸世界。日本军国主义的野蛮侵略给中国人民造成空前巨大的灾难，激起了中国人民的顽强反抗。</p>
<p>九一八事变后，中国人民就在白山黑水间奋起抵抗，成为中国人民抗日战争的起点，同时揭开了世界反法西斯战争的序幕。七七事变后，抗击侵略、救亡图存成为中国各党派、各民族、各阶级、各阶层、各团体以及海外华侨华人的共同意志和行动，中国由此进入全民族抗战阶段，并开辟了世界反法西斯战争的东方主战场。</p>
<p>在艰苦卓绝的抗日战争中，全体中华儿女为国家生存而战、为民族复兴而战、为人类正义而战，社会动员之广泛，民族觉醒之深刻，战斗意志之顽强，必胜信念之坚定，都达到了空前的高度。杨靖宇、赵尚志、左权、彭雪枫、佟麟阁、赵登禹、张自忠、戴安澜等殉国将领，八路军“狼牙山五壮士”、新四军“刘老庄连”、东北抗联八位女战士、国民党军“八百壮士”等众多英雄群体，就是千千万万抗日将士的杰出代表。中国人民以铮铮铁骨战强敌、以血肉之躯筑长城、以前仆后继赴国难，谱写了惊天地、泣鬼神的雄壮史诗。</p>
<p>中国人民抗日战争的伟大胜利，彻底粉碎了日本军国主义殖民奴役中国的图谋，有力捍卫了国家主权和领土完整，彻底洗刷了近代以来抗击外来侵略屡战屡败的民族耻辱！</p>
<p>中国人民抗日战争的伟大胜利，重新确立了中国在世界上的大国地位，中国人民赢得了世界爱好和平人民的尊敬，中华民族赢得了崇高的民族声誉！</p>
<p>中国人民抗日战争的伟大胜利，坚定了中国人民追求民族独立、自由、解放的意志，开启了古老中国凤凰涅槃、浴火重生的历史新征程！</p>
<p>同胞们、同志们、朋友们！</p>
<p>——中国人民抗日战争胜利是以爱国主义为核心的民族精神的伟大胜利。爱国主义是我们民族精神的核心，是中国人民和中华民族同心同德、自强不息的精神纽带。面对国家和民族生死存亡，全体中华儿女同仇敌忾、众志成城，奏响了气吞山河的爱国主义壮歌。爱国主义是激励中国人民维护民族独立和民族尊严、在历史洪流中奋勇向前的强大精神动力，是驱动中华民族这艘航船乘风破浪、奋勇前行的强劲引擎，是引领中国人民和中华民族迸发排山倒海的历史伟力、战胜前进道路上一切艰难险阻的壮丽旗帜！</p>
<p>——中国人民抗日战争胜利是中国共产党发挥中流砥柱作用的伟大胜利。中国共产党自成立之日起就把实现中华民族伟大复兴作为自己的历史使命，捍卫民族独立最坚定，维护民族利益最坚决，反抗外来侵略最勇敢。在抗日战争时期，在民族危亡的历史关头，中国共产党以卓越的政治领导力和正确的战略策略，指引了中国抗战的前进方向，坚定不移推动全民族坚持抗战、团结、进步，反对妥协、分裂、倒退。中国共产党高举抗日民族统一战线的旗帜，坚决维护、巩固、发展统一战线，坚持独立自主、团结抗战，维护了团结抗战大局。中国共产党人勇敢战斗在抗日战争最前线，支撑起中华民族救亡图存的希望，成为全民族抗战的中流砥柱！</p>
<p>——中国人民抗日战争胜利是全民族众志成城奋勇抗战的伟大胜利。中国共产党坚持动员人民、依靠人民，推动形成了全民族抗战的历史洪流。毛泽东同志在全国抗战开始后就明确提出：“我们主张全国人民总动员的完全的民族革命战争，或者叫作全面抗战。因为只有这种抗战，才是群众战争，才能达到保卫祖国的目的。”中国共产党坚持兵民是胜利之本，提出和实施持久战的战略总方针和一整套人民战争的战略战术，敌后根据地军民广泛开展伏击战、破袭战、地雷战、地道战、麻雀战等游击战的战术战法，使日本侵略者陷入了人民战争的汪洋大海之中。中国共产党领导开辟的敌后战场和国民党指挥的正面战场协力合作，形成了共同抗击日本侵略者的战略局面。中国人民抗日战争胜利是全体中华儿女勠力同心、以弱胜强的雄浑史诗，显示了中国人民和中华儿女坚不可摧的磅礴力量！</p>
<p>——中国人民抗日战争胜利是中国人民同反法西斯同盟国以及各国人民并肩战斗的伟大胜利。中国人民永远不会忘记，世界上爱好和平与正义的国家和人民、国际组织等各种反法西斯力量对中国人民抗日战争给予的宝贵援助和支持。苏联给予中国抗战有力的物资支持，美国“飞虎队”冒险开辟驼峰航线，朝鲜、越南、加拿大、印度、新西兰、波兰、丹麦以及德国、奥地利、罗马尼亚、保加利亚、日本等国的一大批反法西斯战士直接投身中国抗战。加拿大医生白求恩、印度医生柯棣华不远万里来华救死扶伤，法国医生贝熙叶开辟运输药品的自行车“驼峰航线”，德国的拉贝、丹麦的辛德贝格在南京大屠杀中千方百计保护中国难民，英国的林迈可、国际主义战士汉斯·希伯等记者积极报道和宣传中国抗战壮举。他们的感人事迹和崇高品格永远铭记在中国人民心中！</p>
<p>中国人民在抗日战争的壮阔进程中孕育出伟大抗战精神，向世界展示了天下兴亡、匹夫有责的爱国情怀，视死如归、宁死不屈的民族气节，不畏强暴、血战到底的英雄气概，百折不挠、坚忍不拔的必胜信念。伟大抗战精神，是中国人民弥足珍贵的精神财富，将永远激励中国人民克服一切艰难险阻、为实现中华民族伟大复兴而奋斗。</p>
<p>同胞们、同志们、朋友们！</p>
<p>中国和日本是近邻。保持中日长期和平友好关系，符合两国人民根本利益，符合维护亚洲和世界和平稳定的需要。在两国2000多年的交往历史上，和平友好是主流。中日友好关系发展到今天的水平，来之不易。我们应该以历史眼光和全球视野思考和谋划两国关系，坚持在相互尊重、求同存异基础上，积极推动构建携手合作、互利双赢的新格局，推动两国关系沿着正确轨道持续向前发展。</p>
<p>正确对待和深刻反省日本军国主义的侵略历史，是建立和发展中日关系的重要政治基础。日本军国主义惨无人道的侵略行径、令人发指的屠杀罪行、野蛮疯狂的掠夺破坏，给中国人民和广大亚洲国家人民带来了惨绝人寰的灾难。事实不容抹杀，也是抹杀不了的。任何否认侵略历史甚至美化侵略战争和殖民统治的言论，都不能不引起中国人民和亚洲国家人民的极大愤慨、严厉谴责、高度警惕。</p>
<p>前事不忘，后事之师。我们纪念中国人民抗日战争和世界反法西斯战争的胜利，谴责侵略者的残暴，强调牢记历史经验和教训，不是要延续仇恨，而是要唤起善良的人们对和平的向往和坚守，是要以史为鉴、面向未来，共同珍爱和平、维护和平，让中日两国人民世世代代友好下去，让世界各国人民永享和平安宁。</p>
<p>同胞们、同志们、朋友们！</p>
<p>中国人民抗日战争胜利75年来，中国发生了翻天覆地的变化。中国共产党团结带领全国各族人民发愤图强、艰苦创业，创造了举世瞩目的发展成就，成功开辟了中国特色社会主义道路，中国特色社会主义进入新时代，脱贫攻坚战、全面建成小康社会胜利在望，中华民族伟大复兴迎来了光明前景。全体中华儿女为之感到无比自豪！</p>
<p>我们也清醒认识到，在前进道路上，我们仍然会面临各种各样的风险挑战，会遇到各种各样的荆棘坎坷。我们要弘扬伟大抗战精神，以压倒一切困难而不为困难所压倒的决心和勇气，敢于斗争，善于创造，锲而不舍为实现中华民族伟大复兴而奋斗，直至取得最后的胜利。</p>
<p>——实现中华民族伟大复兴，必须坚持中国共产党领导。办好中国的事情，关键在党。只要我们深入了解中国近代以来的历史就不难发现，鸦片战争以后的很长时间里，中国呈现各自为政、一盘散沙的乱象，这是日本军国主义敢于发动全面侵华战争的重要原因。如果没有中国共产党领导，完成民族独立和解放的任务就可能拖得更久、付出的代价更大，我们的国家更不可能取得今天这样的发展成就、更不可能具有今天这样的国际地位。坚持党的全面领导，是国家和民族兴旺发达的根本所在，是全国各族人民幸福安康的根本所在。我们要聚精会神抓好党的建设，使我们党越来越成熟、越来越纯洁、越来越强大、越来越有战斗力。全国各党派、各团体、各民族、各阶层、各界人士要紧密团结在党中央周围，万众一心向前进。任何人任何势力企图歪曲中国共产党的历史、丑化中国共产党的性质和宗旨，中国人民都绝不答应！</p>
<p>——实现中华民族伟大复兴，必须坚持走中国特色社会主义道路。道路问题直接关系党和人民事业兴衰成败。中国特色社会主义道路是党和人民历经千辛万苦、克服千难万险取得的宝贵成果。中国特色社会主义道路，开拓于中国人民共同奋斗，扎根于中华大地，是给中国人民带来幸福安宁的正确道路。无论遇到什么风浪，在坚持中国特色社会主义道路这个根本问题上都要一以贯之，决不因各种杂音噪音而改弦更张。随着新时代坚持和发展中国特色社会主义的伟大实践不断向前，我们的道路必将越走越宽广，我们的制度必将越来越成熟。任何人任何势力企图歪曲和改变中国特色社会主义道路、否定和丑化中国人民建设社会主义的伟大成就，中国人民都绝不答应！</p>
<p>——实现中华民族伟大复兴，必须坚持以人民为中心。人民是历史的创造者，是决定党和国家前途命运的根本力量。中国共产党来自人民、植根人民，初心和使命是为中国人民谋幸福、为中华民族谋复兴，根本宗旨是全心全意为人民服务。我们要坚持一切为了人民、一切依靠人民，保持同人民的血肉联系，紧紧依靠人民开拓事业新局面，促进全体人民共同富裕。任何人任何势力企图把中国共产党和中国人民割裂开来、对立起来，中国人民都绝不答应！</p>
<p>——实现中华民族伟大复兴，必须坚持斗争精神。中国共产党和中国人民是在斗争中成长和壮大起来的，斗争精神贯穿于中国革命、建设、改革各个时期。我国正处于实现中华民族伟大复兴关键时期，改革发展正处在攻坚克难的重要阶段，在前进道路上，我们面临的重大斗争不会少。我们必须以越是艰险越向前的精神奋勇搏击、迎难而上。凡是危害中国共产党领导和我国社会主义制度的各种风险挑战，凡是危害我国主权、安全、发展利益的各种风险挑战，凡是危害我国核心利益和重大原则的各种风险挑战，凡是危害我国人民根本利益的各种风险挑战，凡是危害我国实现“两个一百年”奋斗目标、实现中华民族伟大复兴的各种风险挑战，只要来了，我们就必须进行坚决斗争，毫不动摇，毫不退缩，直至取得胜利。历史必将证明，中华民族走向伟大复兴的历史脚步是不可阻挡的。任何人任何势力企图通过霸凌手段把他们的意志强加给中国、改变中国的前进方向、阻挠中国人民创造自己美好生活的努力，中国人民都绝不答应！</p>
<p>——实现中华民族伟大复兴，必须坚定不移走和平发展道路。近代以后，中国人民遭受列强的侵略、凌辱、掠夺达百年以上，但中国人民不是从中学到弱肉强食的强盗逻辑，而是更加坚定了维护和平的决心。人类命运休戚与共，各国人民应该秉持“天下一家”理念，共同推动构建人类命运共同体。中国人民热爱和平、珍惜和平，把维护世界和平、反对霸权主义和强权政治作为自己的神圣职责，坚决反对动辄使用武力或以武力威胁处理国际争端，坚决反对打着所谓“民主”、“自由”、“人权”等幌子肆意干涉别国内政。中国人民将一如既往同各国人民携手努力，为创造人类美好未来而不懈奋斗。任何人任何势力企图破坏中国人民的和平生活和发展权利、破坏中国人民同其他国家人民的交流合作、破坏人类和平与发展的崇高事业，中国人民都绝不答应！</p>
<p>同胞们、同志们、朋友们！</p>
<p>鉴往事，知来者。全党全军全国各族人民，海内外所有中华儿女，要更加紧密地团结起来，弘扬伟大抗战精神，向着中华民族伟大复兴的光辉彼岸奋勇前进。这是对为夺取中国人民抗日战争胜利献出生命的所有先烈、对为中华民族独立和中国人民解放献出生命的所有英灵的最好告慰。</p>
<h4 id="在庆祝中华人民共和国成立70周年大会上的讲话"><strong>在庆祝中华人民共和国成立70周年大会上的讲话</strong></h4>
<p><strong>全国同胞们，</strong></p>
<p><strong>同志们，朋友们：</strong></p>
<p>　　今天，我们隆重集会，庆祝中华人民共和国成立70周年。此时此刻，全国各族人民、海内外中华儿女，都怀着无比喜悦的心情，都为我们伟大的祖国感到自豪，都为我们伟大的祖国衷心祝福。</p>
<p>　　在这里，我代表党中央、全国人大、国务院、全国政协和中央军委，向一切为民族独立和人民解放、国家富强和人民幸福建立了不朽功勋的革命先辈和烈士们，表示深切的怀念！向全国各族人民和海内外爱国同胞，致以热烈的祝贺！向关心和支持中国发展的各国朋友，表示衷心的感谢！</p>
<p>　　70年前的今天，毛泽东同志在这里向世界庄严宣告了中华人民共和国的成立，中国人民从此站起来了。这一伟大事件，彻底改变了近代以后100多年中国积贫积弱、受人欺凌的悲惨命运，中华民族走上了实现伟大复兴的壮阔道路。</p>
<p>　　70年来，全国各族人民同心同德、艰苦奋斗，取得了令世界刮目相看的伟大成就。今天，社会主义中国巍然屹立在世界东方，没有任何力量能够撼动我们伟大祖国的地位，没有任何力量能够阻挡中国人民和中华民族的前进步伐。</p>
<p>　　同志们、朋友们！</p>
<p>　　2019年10月1日，庆祝中华人民共和国成立70周年大会在北京天安门广场隆重举行。中共中央总书记、国家主席、中央军委主席习近平发表重要讲话并检阅受阅部队。这是习近平在天安门城楼上。 新华社记者 黄敬文/摄</p>
<p>　　前进征程上，我们要坚持中国共产党领导，坚持人民主体地位，坚持中国特色社会主义道路，全面贯彻执行党的基本理论、基本路线、基本方略，不断满足人民对美好生活的向往，不断创造新的历史伟业。</p>
<p>　　前进征程上，我们要坚持“和平统一、一国两制”的方针，保持香港、澳门长期繁荣稳定，推动海峡两岸关系和平发展，团结全体中华儿女，继续为实现祖国完全统一而奋斗。</p>
<p>　　前进征程上，我们要坚持和平发展道路，奉行互利共赢的开放战略，继续同世界各国人民一道推动共建人类命运共同体。</p>
<p>　　中国人民解放军和人民武装警察部队要永葆人民军队性质、宗旨、本色，坚决维护国家主权、安全、发展利益，坚决维护世界和平。</p>
<p>　　同志们、朋友们！</p>
<p>　　中国的昨天已经写在人类的史册上，中国的今天正在亿万人民手中创造，中国的明天必将更加美好。全党全军全国各族人民要更加紧密地团结起来，不忘初心，牢记使命，继续把我们的人民共和国巩固好、发展好，继续为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦而努力奋斗！</p>
<p>　　伟大的中华人民共和国万岁！</p>
<p>　　伟大的中国共产党万岁！</p>
<p>　　伟大的中国人民万岁！</p>
<h4 id="在庆祝改革开放40周年大会上的讲话"><strong>在庆祝改革开放40周年大会上的讲话</strong></h4>
<p>同志们，朋友们：</p>
<p>　　1978年12月18日，在中华民族历史上，在中国共产党历史上，在中华人民共和国历史上，都必将是载入史册的重要日子。这一天，我们党召开十一届三中全会，实现新中国成立以来党的历史上具有深远意义的伟大转折，开启了改革开放和社会主义现代化的伟大征程。</p>
<p>　　今天，我们在这里隆重集会，回顾改革开放40年的光辉历程，总结改革开放的伟大成就和宝贵经验，动员全党全国各族人民在新时代继续把改革开放推向前进，为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦不懈奋斗。</p>
<p>　　同志们、朋友们！</p>
<p>　　党的十一届三中全会是在党和国家面临何去何从的重大历史关头召开的。当时，世界经济快速发展，科技进步日新月异，而“文化大革命”十年内乱导致我国经济濒临崩溃的边缘，人民温饱都成问题，国家建设百业待兴。党内外强烈要求纠正“文化大革命”的错误，使党和国家从危难中重新奋起。邓小平同志指出：“如果现在再不实行改革，我们的现代化事业和社会主义事业就会被葬送。”</p>
<p>　　在邓小平同志领导下和老一辈革命家支持下，党的十一届三中全会冲破长期“左”的错误的严重束缚，批评“两个凡是”的错误方针，充分肯定必须完整、准确地掌握毛泽东思想的科学体系，高度评价关于真理标准问题的讨论，果断结束“以阶级斗争为纲”，重新确立马克思主义的思想路线、政治路线、组织路线。从此，我国改革开放拉开了大幕。</p>
<p>　　我们党作出实行改革开放的历史性决策，是基于对党和国家前途命运的深刻把握，是基于对社会主义革命和建设实践的深刻总结，是基于对时代潮流的深刻洞察，是基于对人民群众期盼和需要的深刻体悟。邓小平同志指出：“贫穷不是社会主义”，“我们要赶上时代，这是改革要达到的目的”。</p>
<p>　　历史发展有其规律，但人在其中不是完全消极被动的。只要把握住历史发展大势，抓住历史变革时机，奋发有为，锐意进取，人类社会就能更好前进。</p>
<p>　　改革开放是我们党的一次伟大觉醒，正是这个伟大觉醒孕育了我们党从理论到实践的伟大创造。改革开放是中国人民和中华民族发展史上一次伟大革命，正是这个伟大革命推动了中国特色社会主义事业的伟大飞跃！</p>
<p>　　同志们、朋友们！</p>
<p>　　建立中国共产党、成立中华人民共和国、推进改革开放和中国特色社会主义事业，是五四运动以来我国发生的三大历史性事件，是近代以来实现中华民族伟大复兴的三大里程碑。</p>
<p>　　以毛泽东同志为主要代表的中国共产党人，把马克思列宁主义基本原理同中国革命具体实践结合起来，创立了毛泽东思想，团结带领全党全国各族人民，经过长期浴血奋斗，完成了新民主主义革命，建立了中华人民共和国，确立了社会主义基本制度，成功实现了中国历史上最深刻最伟大的社会变革，为当代中国一切发展进步奠定了根本政治前提和制度基础。在探索过程中，虽然经历了严重曲折，但党在社会主义革命和建设中取得的独创性理论成果和巨大成就，为在新的历史时期开创中国特色社会主义提供了宝贵经验、理论准备、物质基础。</p>
<p>　　党的十一届三中全会以后，以邓小平同志为主要代表的中国共产党人，团结带领全党全国各族人民，深刻总结我国社会主义建设正反两方面经验，借鉴世界社会主义历史经验，创立了邓小平理论，作出把党和国家工作中心转移到经济建设上来、实行改革开放的历史性决策，深刻揭示社会主义本质，确立社会主义初级阶段基本路线，明确提出走自己的路、建设中国特色社会主义，科学回答了建设中国特色社会主义的一系列基本问题，制定了到21世纪中叶分三步走、基本实现社会主义现代化的发展战略，成功开创了中国特色社会主义。</p>
<p>　　党的十三届四中全会以后，以江泽民同志为主要代表的中国共产党人，团结带领全党全国各族人民，坚持党的基本理论、基本路线，加深了对什么是社会主义、怎样建设社会主义和建设什么样的党、怎样建设党的认识，积累了治党治国新的宝贵经验，形成了“三个代表”重要思想。在国内外形势十分复杂、世界社会主义出现严重曲折的严峻考验面前，捍卫了中国特色社会主义，确立了社会主义市场经济体制的改革目标和基本框架，确立了社会主义初级阶段的基本经济制度和分配制度，开创全面改革开放新局面，推进党的建设新的伟大工程，成功把中国特色社会主义推向21世纪。</p>
<p>　　党的十六大以后，以胡锦涛同志为主要代表的中国共产党人，团结带领全党全国各族人民，坚持以邓小平理论和“三个代表”重要思想为指导，根据新的发展要求，深刻认识和回答了新形势下实现什么样的发展、怎样发展等重大问题，形成了科学发展观，抓住重要战略机遇期，在全面建设小康社会进程中推进实践创新、理论创新、制度创新，强调坚持以人为本、全面协调可持续发展，形成中国特色社会主义事业总体布局，着力保障和改善民生，促进社会公平正义，推动建设和谐世界，推进党的执政能力建设和先进性建设，成功在新的历史起点上坚持和发展了中国特色社会主义。</p>
<p>　　党的十八大以来，党中央团结带领全党全国各族人民，全面审视国际国内新的形势，通过总结实践、展望未来，深刻回答了新时代坚持和发展什么样的中国特色社会主义、怎样坚持和发展中国特色社会主义这个重大时代课题，形成了新时代中国特色社会主义思想，坚持统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，坚持稳中求进工作总基调，对党和国家各方面工作提出一系列新理念新思想新战略，推动党和国家事业发生历史性变革、取得历史性成就，中国特色社会主义进入了新时代。我们以巨大的政治勇气和智慧，提出全面深化改革总目标是完善和发展中国特色社会主义制度、推进国家治理体系和治理能力现代化，着力增强改革系统性、整体性、协同性，着力抓好重大制度创新，着力提升人民群众获得感、幸福感、安全感，推出1600多项改革方案，啃下了不少硬骨头，闯过了不少急流险滩，改革呈现全面发力、多点突破、蹄疾步稳、纵深推进的局面。</p>
<p>　　艰难困苦，玉汝于成。40年来，我们解放思想、实事求是，大胆地试、勇敢地改，干出了一片新天地。从实行家庭联产承包、乡镇企业异军突起、取消农业税牧业税和特产税到农村承包地“三权”分置、打赢脱贫攻坚战、实施乡村振兴战略，从兴办深圳等经济特区、沿海沿边沿江沿线和内陆中心城市对外开放到加入世界贸易组织、共建“一带一路”、设立自由贸易试验区、谋划中国特色自由贸易港、成功举办首届中国国际进口博览会，从“引进来”到“走出去”，从搞好国营大中小企业、发展个体私营经济到深化国资国企改革、发展混合所有制经济，从单一公有制到公有制为主体、多种所有制经济共同发展和坚持“两个毫不动摇”，从传统的计划经济体制到前无古人的社会主义市场经济体制再到使市场在资源配置中起决定性作用和更好发挥政府作用，从以经济体制改革为主到全面深化经济、政治、文化、社会、生态文明体制和党的建设制度改革，党和国家机构改革、行政管理体制改革、依法治国体制改革、司法体制改革、外事体制改革、社会治理体制改革、生态环境督察体制改革、国家安全体制改革、国防和军队改革、党的领导和党的建设制度改革、纪检监察制度改革等一系列重大改革扎实推进，各项便民、惠民、利民举措持续实施，使改革开放成为当代中国最显著的特征、最壮丽的气象。</p>
<p>　　同志们、朋友们！</p>
<p>　　改革开放40年来，从开启新时期到跨入新世纪，从站上新起点到进入新时代，40年风雨同舟，40年披荆斩棘，40年砥砺奋进，我们党引领人民绘就了一幅波澜壮阔、气势恢宏的历史画卷，谱写了一曲感天动地、气壮山河的奋斗赞歌。</p>
<p>　　——40年来，我们始终坚持解放思想、实事求是、与时俱进、求真务实，坚持马克思主义指导地位不动摇，坚持科学社会主义基本原则不动摇，勇敢推进理论创新、实践创新、制度创新、文化创新以及各方面创新，不断赋予中国特色社会主义以鲜明的实践特色、理论特色、民族特色、时代特色，形成了中国特色社会主义道路、理论、制度、文化，以不可辩驳的事实彰显了科学社会主义的鲜活生命力，社会主义的伟大旗帜始终在中国大地上高高飘扬！</p>
<p>　　——40年来，我们始终坚持以经济建设为中心，不断解放和发展社会生产力，我国国内生产总值由3679亿元增长到2017年的82.7万亿元，年均实际增长9.5%，远高于同期世界经济2.9%左右的年均增速。我国国内生产总值占世界生产总值的比重由改革开放之初的1.8%上升到15.2%，多年来对世界经济增长贡献率超过30%。我国货物进出口总额从206亿美元增长到超过4万亿美元，累计使用外商直接投资超过2万亿美元，对外投资总额达到1.9万亿美元。我国主要农产品产量跃居世界前列，建立了全世界最完整的现代工业体系，科技创新和重大工程捷报频传。我国基础设施建设成就显著，信息畅通，公路成网，铁路密布，高坝矗立，西气东输，南水北调，高铁飞驰，巨轮远航，飞机翱翔，天堑变通途。现在，我国是世界第二大经济体、制造业第一大国、货物贸易第一大国、商品消费第二大国、外资流入第二大国，我国外汇储备连续多年位居世界第一，中国人民在富起来、强起来的征程上迈出了决定性的步伐！</p>
<p>　　——40年来，我们始终坚持中国特色社会主义政治发展道路，不断深化政治体制改革，发展社会主义民主政治，党和国家领导体制日益完善，全面依法治国深入推进，中国特色社会主义法律体系日益健全，人民当家作主的制度保障和法治保障更加有力，人权事业全面发展，爱国统一战线更加巩固，人民依法享有和行使民主权利的内容更加丰富、渠道更加便捷、形式更加多样，掌握着自己命运的中国人民焕发出前所未有的积极性、主动性、创造性，在改革开放和社会主义现代化建设中展现出气吞山河的强大力量！</p>
<p>　　——40年来，我们始终坚持发展社会主义先进文化，加强社会主义精神文明建设，培育和践行社会主义核心价值观，传承和弘扬中华优秀传统文化，坚持以科学理论引路指向，以正确舆论凝心聚力，以先进文化塑造灵魂，以优秀作品鼓舞斗志，爱国主义、集体主义、社会主义精神广为弘扬，时代楷模、英雄模范不断涌现，文化艺术日益繁荣，网信事业快速发展，全民族理想信念和文化自信不断增强，国家文化软实力和中华文化影响力大幅提升。改革开放铸就的伟大改革开放精神，极大丰富了民族精神内涵，成为当代中国人民最鲜明的精神标识！</p>
<p>　　——40年来，我们始终坚持在发展中保障和改善民生，全面推进幼有所育、学有所教、劳有所得、病有所医、老有所养、住有所居、弱有所扶，不断改善人民生活、增进人民福祉。全国居民人均可支配收入由171元增加到2.6万元，中等收入群体持续扩大。我国贫困人口累计减少7.4亿人，贫困发生率下降94.4个百分点，谱写了人类反贫困史上的辉煌篇章。教育事业全面发展，九年义务教育巩固率达93.8%。我国建成了包括养老、医疗、低保、住房在内的世界最大的社会保障体系，基本养老保险覆盖超过9亿人，医疗保险覆盖超过13亿人。常住人口城镇化率达到58.52%，上升40.6个百分点。居民预期寿命由1981年的67.8岁提高到2017年的76.7岁。我国社会大局保持长期稳定，成为世界上最有安全感的国家之一。粮票、布票、肉票、鱼票、油票、豆腐票、副食本、工业券等百姓生活曾经离不开的票证已经进入了历史博物馆，忍饥挨饿、缺吃少穿、生活困顿这些几千年来困扰我国人民的问题总体上一去不复返了！</p>
<p>　　——40年来，我们始终坚持保护环境和节约资源，坚持推进生态文明建设，生态文明制度体系加快形成，主体功能区制度逐步健全，节能减排取得重大进展，重大生态保护和修复工程进展顺利，生态环境治理明显加强，积极参与和引导应对气候变化国际合作，中国人民生于斯、长于斯的家园更加美丽宜人！</p>
<p>　　——40年来，我们始终坚持党对军队的绝对领导，不断推进国防和军队现代化，推进人民军队实现革命性重塑，武器装备取得历史性突破，治军方式发生根本性转变，革命化现代化正规化水平显著提高，人民军队维护国家主权、安全、发展利益的能力显著增强，成为保卫人民幸福生活、保卫祖国和世界和平牢不可破的强大力量！</p>
<p>　　——40年来，我们始终坚持推进祖国和平统一大业，实施“一国两制”基本方针，相继恢复对香港、澳门行使主权，洗雪了中华民族百年屈辱。我们坚持一个中国原则和“九二共识”，加强两岸经济文化交流合作，推动两岸关系和平发展，坚决反对和遏制“台独”分裂势力，牢牢掌握两岸关系发展主导权和主动权。海内外全体中华儿女的民族认同感、文化认同感大大增强，同心共筑中国梦的意志更加坚强！</p>
<p>　　——40年来，我们始终坚持独立自主的和平外交政策，始终不渝走和平发展道路、奉行互利共赢的开放战略，坚定维护国际关系基本准则，维护国际公平正义。我们实现由封闭半封闭到全方位开放的历史转变，积极参与经济全球化进程，为推动人类共同发展作出了应有贡献。我们积极推动建设开放型世界经济、构建人类命运共同体，促进全球治理体系变革，旗帜鲜明反对霸权主义和强权政治，为世界和平与发展不断贡献中国智慧、中国方案、中国力量。我国日益走近世界舞台中央，成为国际社会公认的世界和平的建设者、全球发展的贡献者、国际秩序的维护者！</p>
<p>　　——40年来，我们始终坚持加强和改善党的领导，积极应对在长期执政和改革开放条件下党面临的各种风险考验，持续推进党的建设新的伟大工程，保持党的先进性和纯洁性，保持党同人民群众的血肉联系。我们积极探索共产党执政规律、社会主义建设规律、人类社会发展规律，不断开辟马克思主义中国化新境界。我们坚持党要管党、从严治党，净化党内政治生态，持之以恒正风肃纪，大力整治形式主义、官僚主义、享乐主义和奢靡之风，以零容忍态度严厉惩治腐败，反腐败斗争取得压倒性胜利。我们党在革命性锻造中坚定走在时代前列，始终是中国人民和中华民族的主心骨！</p>
<p>　　40年春风化雨、春华秋实，改革开放极大改变了中国的面貌、中华民族的面貌、中国人民的面貌、中国共产党的面貌。中华民族迎来了从站起来、富起来到强起来的伟大飞跃！中国特色社会主义迎来了从创立、发展到完善的伟大飞跃！中国人民迎来了从温饱不足到小康富裕的伟大飞跃！中华民族正以崭新姿态屹立于世界的东方！</p>
<p>　　40年来取得的成就不是天上掉下来的，更不是别人恩赐施舍的，而是全党全国各族人民用勤劳、智慧、勇气干出来的！我们用几十年时间走完了发达国家几百年走过的工业化历程。在中国人民手中，不可能成为了可能。我们为创造了人间奇迹的中国人民感到无比自豪、无比骄傲！</p>
<p>　　在这里，我代表党中央，向各条战线为改革开放和社会主义现代化建设贡献了智慧和力量的广大工人、农民、知识分子、干部、解放军指战员、武警部队官兵、公安干警，向各民主党派和无党派人士、各人民团体和各界爱国人士，致以崇高的敬意！向为祖国改革开放和现代化建设作出积极努力的香港特别行政区同胞、澳门特别行政区同胞、台湾同胞和海外侨胞，致以诚挚的问候！向一切关心和支持中国改革开放和现代化建设的外国朋友和世界各国人民，表示衷心的感谢！</p>
<p>　　同志们、朋友们！</p>
<p>　　40年的实践充分证明，党的十一届三中全会以来我们党团结带领全国各族人民开辟的中国特色社会主义道路、理论、制度、文化是完全正确的，形成的党的基本理论、基本路线、基本方略是完全正确的。</p>
<p>　　40年的实践充分证明，中国发展为广大发展中国家走向现代化提供了成功经验、展现了光明前景，是促进世界和平与发展的强大力量，是中华民族对人类文明进步作出的重大贡献。</p>
<p>　　40年的实践充分证明，改革开放是党和人民大踏步赶上时代的重要法宝，是坚持和发展中国特色社会主义的必由之路，是决定当代中国命运的关键一招，也是决定实现“两个一百年”奋斗目标、实现中华民族伟大复兴的关键一招。</p>
<p>　　只有顺应历史潮流，积极应变，主动求变，才能与时代同行。“行之力则知愈进，知之深则行愈达。”改革开放40年积累的宝贵经验是党和人民弥足珍贵的精神财富，对新时代坚持和发展中国特色社会主义有着极为重要的指导意义，必须倍加珍惜、长期坚持，在实践中不断丰富和发展。</p>
<p>　　第一，必须坚持党对一切工作的领导，不断加强和改善党的领导。改革开放40年的实践启示我们：中国共产党领导是中国特色社会主义最本质的特征，是中国特色社会主义制度的最大优势。党政军民学，东西南北中，党是领导一切的。正是因为始终坚持党的集中统一领导，我们才能实现伟大历史转折、开启改革开放新时期和中华民族伟大复兴新征程，才能成功应对一系列重大风险挑战、克服无数艰难险阻，才能有力应变局、平风波、战洪水、防非典、抗地震、化危机，才能既不走封闭僵化的老路也不走改旗易帜的邪路，而是坚定不移走中国特色社会主义道路。坚持党的领导，必须不断改善党的领导，让党的领导更加适应实践、时代、人民的要求。在坚持党的领导这个决定党和国家前途命运的重大原则问题上，全党全国必须保持高度的思想自觉、政治自觉、行动自觉，丝毫不能动摇。</p>
<p>　　前进道路上，我们必须增强“四个意识”、坚定“四个自信”，坚决维护党中央权威和集中统一领导，把党的领导贯彻和体现到改革发展稳定、内政外交国防、治党治国治军等各个领域。改革开放每一步都不是轻而易举的，未来必定会面临这样那样的风险挑战，甚至会遇到难以想象的惊涛骇浪。我们党要总揽全局、协调各方，坚持科学执政、民主执政、依法执政，完善党的领导方式和执政方式，提高党的执政能力和领导水平，不断提高党把方向、谋大局、定政策、促改革的能力和定力，确保改革开放这艘航船沿着正确航向破浪前行。</p>
<p>　　第二，必须坚持以人民为中心，不断实现人民对美好生活的向往。改革开放40年的实践启示我们：为中国人民谋幸福，为中华民族谋复兴，是中国共产党人的初心和使命，也是改革开放的初心和使命。我们党来自人民、扎根人民、造福人民，全心全意为人民服务是党的根本宗旨，必须以最广大人民根本利益为我们一切工作的根本出发点和落脚点，坚持把人民拥护不拥护、赞成不赞成、高兴不高兴作为制定政策的依据，顺应民心、尊重民意、关注民情、致力民生，既通过提出并贯彻正确的理论和路线方针政策带领人民前进，又从人民实践创造和发展要求中获得前进动力，让人民共享改革开放成果，激励人民更加自觉地投身改革开放和社会主义现代化建设事业。</p>
<p>　　前进道路上，我们必须始终把人民对美好生活的向往作为我们的奋斗目标，践行党的根本宗旨，贯彻党的群众路线，尊重人民主体地位，尊重人民群众在实践活动中所表达的意愿、所创造的经验、所拥有的权利、所发挥的作用，充分激发蕴藏在人民群众中的创造伟力。我们要健全民主制度、拓宽民主渠道、丰富民主形式、完善法治保障，确保人民依法享有广泛充分、真实具体、有效管用的民主权利。我们要着力解决人民群众所需所急所盼，让人民共享经济、政治、文化、社会、生态等各方面发展成果，有更多、更直接、更实在的获得感、幸福感、安全感，不断促进人的全面发展、全体人民共同富裕。</p>
<p>　　第三，必须坚持马克思主义指导地位，不断推进实践基础上的理论创新。改革开放40年的实践启示我们：创新是改革开放的生命。实践发展永无止境，解放思想永无止境。恩格斯说：“一切社会变迁和政治变革的终极原因，不应当到人们的头脑中，到人们对永恒的真理和正义的日益增进的认识中去寻找，而应当到生产方式和交换方式的变更中去寻找”。我们坚持理论联系实际，及时回答时代之问、人民之问，廓清困扰和束缚实践发展的思想迷雾，不断推进马克思主义中国化时代化大众化，不断开辟马克思主义发展新境界。</p>
<p>　　前进道路上，我们必须坚持以马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观、新时代中国特色社会主义思想为指导，坚持解放思想和实事求是有机统一。发展21世纪马克思主义、当代中国马克思主义，是当代中国共产党人责无旁贷的历史责任。我们要强化问题意识、时代意识、战略意识，用深邃的历史眼光、宽广的国际视野把握事物发展的本质和内在联系，紧密跟踪亿万人民的创造性实践，借鉴吸收人类一切优秀文明成果，不断回答时代和实践给我们提出的新的重大课题，让当代中国马克思主义放射出更加灿烂的真理光芒。</p>
<p>　　第四，必须坚持走中国特色社会主义道路，不断坚持和发展中国特色社会主义。改革开放40年的实践启示我们：方向决定前途，道路决定命运。我们要把命运掌握在自己手中，就要有志不改、道不变的坚定。改革开放40年来，我们党全部理论和实践的主题是坚持和发展中国特色社会主义。在中国这样一个有着5000多年文明史、13亿多人口的大国推进改革发展，没有可以奉为金科玉律的教科书，也没有可以对中国人民颐指气使的教师爷。鲁迅先生说过：“什么是路？就是从没路的地方践踏出来的，从只有荆棘的地方开辟出来的。”中国特色社会主义道路是当代中国大踏步赶上时代、引领时代发展的康庄大道，必须毫不动摇走下去。</p>
<p>　　前进道路上，我们必须坚持以新时代中国特色社会主义思想和党的十九大精神为指导，增强“四个自信”，牢牢把握改革开放的前进方向。改什么、怎么改必须以是否符合完善和发展中国特色社会主义制度、推进国家治理体系和治理能力现代化的总目标为根本尺度，该改的、能改的我们坚决改，不该改的、不能改的坚决不改。我们要坚持党的基本路线，把以经济建设为中心同坚持四项基本原则、坚持改革开放这两个基本点统一于新时代中国特色社会主义伟大实践，长期坚持，决不动摇。</p>
<p>　　第五，必须坚持完善和发展中国特色社会主义制度，不断发挥和增强我国制度优势。改革开放40年的实践启示我们：制度是关系党和国家事业发展的根本性、全局性、稳定性、长期性问题。我们扭住完善和发展中国特色社会主义制度这个关键，为解放和发展社会生产力、解放和增强社会活力、永葆党和国家生机活力提供了有力保证，为保持社会大局稳定、保证人民安居乐业、保障国家安全提供了有力保证，为放手让一切劳动、知识、技术、管理、资本等要素的活力竞相迸发，让一切创造社会财富的源泉充分涌流不断建立了充满活力的体制机制。</p>
<p>　　前进道路上，我们必须毫不动摇巩固和发展公有制经济，毫不动摇鼓励、支持、引导非公有制经济发展，充分发挥市场在资源配置中的决定性作用，更好发挥政府作用，激发各类市场主体活力。我们要坚持党的领导、人民当家作主、依法治国有机统一，坚持和完善人民代表大会制度、中国共产党领导的多党合作和政治协商制度、民族区域自治制度、基层群众自治制度，全面推进依法治国，巩固和发展最广泛的爱国统一战线，发展社会主义协商民主，用制度体系保证人民当家作主。我们要加强文化领域制度建设，举旗帜、聚民心、育新人、兴文化、展形象，积极培育和践行社会主义核心价值观，推动中华优秀传统文化创造性转化、创新性发展，传承革命文化、发展先进文化，努力创造光耀时代、光耀世界的中华文化。我们要加强社会治理制度建设，不断促进社会公平正义，保持社会安定有序。我们要加强生态文明制度建设，实行最严格的生态环境保护制度。我们要坚决破除一切妨碍发展的体制机制障碍和利益固化藩篱，加快形成系统完备、科学规范、运行有效的制度体系，推动中国特色社会主义制度更加成熟更加定型。</p>
<p>　　第六，必须坚持以发展为第一要务，不断增强我国综合国力。改革开放40年的实践启示我们：解放和发展社会生产力，增强社会主义国家的综合国力，是社会主义的本质要求和根本任务。只有牢牢扭住经济建设这个中心，毫不动摇坚持发展是硬道理、发展应该是科学发展和高质量发展的战略思想，推动经济社会持续健康发展，才能全面增强我国经济实力、科技实力、国防实力、综合国力，才能为坚持和发展中国特色社会主义、实现中华民族伟大复兴奠定雄厚物质基础。</p>
<p>　　前进道路上，我们必须围绕解决好人民日益增长的美好生活需要和不平衡不充分的发展之间的矛盾这个社会主要矛盾，坚决贯彻创新、协调、绿色、开放、共享的发展理念，统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，推动高质量发展，推动新型工业化、信息化、城镇化、农业现代化同步发展，加快建设现代化经济体系，努力实现更高质量、更有效率、更加公平、更可持续的发展。我们要坚持以供给侧结构性改革为主线，积极转变发展方式、优化经济结构、转换增长动力，积极扩大内需，实施区域协调发展战略，实施乡村振兴战略，坚决打好防范化解重大风险、精准脱贫、污染防治的攻坚战。我们要坚持创新是第一动力、人才是第一资源的理念，实施创新驱动发展战略，完善国家创新体系，加快关键核心技术自主创新，为经济社会发展打造新引擎。我们要加强生态文明建设，牢固树立绿水青山就是金山银山的理念，形成绿色发展方式和生活方式，把我们伟大祖国建设得更加美丽，让人民生活在天更蓝、山更绿、水更清的优美环境之中。</p>
<p>　　第七，必须坚持扩大开放，不断推动共建人类命运共同体。改革开放40年的实践启示我们：开放带来进步，封闭必然落后。中国的发展离不开世界，世界的繁荣也需要中国。我们统筹国内国际两个大局，坚持对外开放的基本国策，实行积极主动的开放政策，形成全方位、多层次、宽领域的全面开放新格局，为我国创造了良好国际环境、开拓了广阔发展空间。</p>
<p>　　前进道路上，我们必须高举和平、发展、合作、共赢的旗帜，恪守维护世界和平、促进共同发展的外交政策宗旨，推动建设相互尊重、公平正义、合作共赢的新型国际关系。我们要尊重各国人民自主选择发展道路的权利，维护国际公平正义，倡导国际关系民主化，反对把自己的意志强加于人，反对干涉别国内政，反对以强凌弱。我们要发挥负责任大国作用，支持广大发展中国家发展，积极参与全球治理体系改革和建设，共同为建设持久和平、普遍安全、共同繁荣、开放包容、清洁美丽的世界而奋斗。我们要支持开放、透明、包容、非歧视性的多边贸易体制，促进贸易投资自由化便利化，推动经济全球化朝着更加开放、包容、普惠、平衡、共赢的方向发展。我们要以共建“一带一路”为重点，同各方一道打造国际合作新平台，为世界共同发展增添新动力。中国决不会以牺牲别国利益为代价来发展自己，也决不放弃自己的正当权益。中国奉行防御性的国防政策，中国发展不对任何国家构成威胁。中国无论发展到什么程度都永远不称霸。</p>
<p>　　第八，必须坚持全面从严治党，不断提高党的创造力、凝聚力、战斗力。改革开放40年的实践启示我们：打铁必须自身硬。办好中国的事情，关键在党，关键在坚持党要管党、全面从严治党。我们党只有在领导改革开放和社会主义现代化建设伟大社会革命的同时，坚定不移推进党的伟大自我革命，敢于清除一切侵蚀党的健康肌体的病毒，使党不断自我净化、自我完善、自我革新、自我提高，不断增强党的政治领导力、思想引领力、群众组织力、社会号召力，才能确保党始终保持同人民群众的血肉联系。</p>
<p>　　前进道路上，我们必须按照新时代党的建设总要求，以政治建设为统领，不断推进党的建设新的伟大工程，不断增强全党团结统一和创造活力，不断增强全党执政本领，把党建设得更加坚强、更加有力。我们要坚持用时代发展要求审视自己，以强烈忧患意识警醒自己，以改革创新精神加强和完善自己，在应对风险挑战中锻炼提高，在解决党内存在的突出矛盾和问题中净化纯洁，不断提高管党治党水平。我们要坚持德才兼备、以德为先、任人唯贤，着力培养忠诚干净担当的高素质干部队伍和宏大的人才队伍。我们要以反腐败永远在路上的坚韧和执着，深化标本兼治，坚决清除一切腐败分子，保证干部清正、政府清廉、政治清明，为继续推进改革开放营造海晏河清的政治生态。</p>
<p>　　第九，必须坚持辩证唯物主义和历史唯物主义世界观和方法论，正确处理改革发展稳定关系。改革开放40年的实践启示我们：我国是一个大国，决不能在根本性问题上出现颠覆性错误。我们坚持加强党的领导和尊重人民首创精神相结合，坚持“摸着石头过河”和顶层设计相结合，坚持问题导向和目标导向相统一，坚持试点先行和全面推进相促进，既鼓励大胆试、大胆闯，又坚持实事求是、善作善成，确保了改革开放行稳致远。</p>
<p>　　前进道路上，我们要增强战略思维、辩证思维、创新思维、法治思维、底线思维，加强宏观思考和顶层设计，坚持问题导向，聚焦我国发展面临的突出矛盾和问题，深入调查研究，鼓励基层大胆探索，坚持改革决策和立法决策相衔接，不断提高改革决策的科学性。我们要拿出抓铁有痕、踏石留印的韧劲，以钉钉子精神抓好落实，确保各项重大改革举措落到实处。我们既要敢为天下先、敢闯敢试，又要积极稳妥、蹄疾步稳，把改革发展稳定统一起来，坚持方向不变、道路不偏、力度不减，推动新时代改革开放走得更稳、走得更远。</p>
<p>　　同志们、朋友们！</p>
<p>　　坚持富国和强军相统一，建设同我国国际地位相称、同国家安全和发展利益相适应的巩固国防和强大军队，是我国社会主义现代化建设的战略任务。我们要全面贯彻新时代党的强军思想，坚持党对军队的绝对领导，把握世界新军事革命发展大势，坚持走中国特色强军之路，全面深化国防和军队改革，推进政治建军、改革强军、科技兴军、依法治军，建设一支听党指挥、能打胜仗、作风优良的人民军队，努力建设世界一流军队，为维护国家主权、安全、发展利益，为维护世界和平稳定，为实现中华民族伟大复兴提供坚强后盾。</p>
<p>　　“一国两制”伟大构想具有强大生命力。我们要全面准确贯彻“一国两制”、“港人治港”、“澳人治澳”、高度自治的方针，严格按照宪法和基本法办事，完善与基本法实施相关的制度和机制，保持香港、澳门长期繁荣稳定，支持和推动香港、澳门更好融入国家发展大局，让香港、澳门同胞同祖国人民共担民族复兴的历史责任、共享祖国繁荣富强的伟大荣光。</p>
<p>　　实现祖国完全统一，是全体中华儿女共同心愿，是中华民族根本利益所在。我们要坚持一个中国原则和“九二共识”，巩固和发展两岸关系和平发展的基础，深化两岸经济文化交流合作，造福两岸同胞。我们有坚定的政治决心和强大能力维护国家主权和领土完整，祖国的神圣领土一寸都不能分裂出去！</p>
<p>　　同志们、朋友们！</p>
<p>　　中国人民具有伟大梦想精神，中华民族充满变革和开放精神。几千年前，中华民族的先民们就秉持“周虽旧邦，其命维新”的精神，开启了缔造中华文明的伟大实践。自古以来，中国大地上发生了无数变法变革图强运动，留下了“治世不一道，便国不法古”等豪迈宣言。自古以来，中华民族就以“天下大同”、“协和万邦”的宽广胸怀，自信而又大度地开展同域外民族交往和文化交流，曾经谱写了万里驼铃万里波的浩浩丝路长歌，也曾经创造了万国衣冠会长安的盛唐气象。正是这种“天行健，君子以自强不息”、“地势坤，君子以厚德载物”的变革和开放精神，使中华文明成为人类历史上唯一一个绵延5000多年至今未曾中断的灿烂文明。以数千年大历史观之，变革和开放总体上是中国的历史常态。中华民族以改革开放的姿态继续走向未来，有着深远的历史渊源、深厚的文化根基。</p>
<p>　　我们这么大一个国家，就应该有雄心壮志。毛泽东同志说：“夺取全国胜利，这只是万里长征走完了第一步。如果这一步也值得骄傲，那是比较渺小的，更值得骄傲的还在后头。在过了几十年之后来看中国人民民主革命的胜利，就会使人们感觉那好像只是一出长剧的一个短小的序幕。剧是必须从序幕开始的，但序幕还不是高潮。”“我们不但善于破坏一个旧世界，我们还将善于建设一个新世界。”</p>
<p>　　改革开放之初，虽然我们国家大、人口多、底子薄，面对着重重困难和挑战，但我们对未来充满信心，设计了用70多年、分三步走基本实现社会主义现代化的宏伟蓝图，没有非凡的胆略、坚定的自信是作不出这样宏远的构想和决策的。</p>
<p>　　40年来，我们咬定青山不放松，风雨无阻朝着这个伟大目标前进。党的十九大对我国发展提出了更高的奋斗目标，形成了从全面建成小康社会到基本实现现代化、再到全面建成社会主义现代化强国的战略安排，发出了实现中华民族伟大复兴中国梦的最强音。</p>
<p>　　古人说：“事者，生于虑，成于务，失于傲。”伟大梦想不是等得来、喊得来的，而是拼出来、干出来的。我们现在所处的，是一个船到中流浪更急、人到半山路更陡的时候，是一个愈进愈难、愈进愈险而又不进则退、非进不可的时候。改革开放已走过千山万水，但仍需跋山涉水，摆在全党全国各族人民面前的使命更光荣、任务更艰巨、挑战更严峻、工作更伟大。在这个千帆竞发、百舸争流的时代，我们绝不能有半点骄傲自满、固步自封，也绝不能有丝毫犹豫不决、徘徊彷徨，必须统揽伟大斗争、伟大工程、伟大事业、伟大梦想，勇立潮头、奋勇搏击。</p>
<p>　　信仰、信念、信心，任何时候都至关重要。小到一个人、一个集体，大到一个政党、一个民族、一个国家，只要有信仰、信念、信心，就会愈挫愈奋、愈战愈勇，否则就会不战自败、不打自垮。无论过去、现在还是将来，对马克思主义的信仰，对中国特色社会主义的信念，对实现中华民族伟大复兴中国梦的信心，都是指引和支撑中国人民站起来、富起来、强起来的强大精神力量。</p>
<p>　　同志们、朋友们！</p>
<p>　　四十载惊涛拍岸，九万里风鹏正举。江河之所以能冲开绝壁夺隘而出，是因其积聚了千里奔涌、万壑归流的洪荒伟力。在近代以来漫长的历史进程中，中国人民经历了太多太多的磨难，付出了太多太多的牺牲，进行了太多太多的拼搏。现在，中国人民和中华民族在历史进程中积累的强大能量已经充分爆发出来了，为实现中华民族伟大复兴提供了势不可挡的磅礴力量。</p>
<p>　　建成社会主义现代化强国，实现中华民族伟大复兴，是一场接力跑，我们要一棒接着一棒跑下去，每一代人都要为下一代人跑出一个好成绩。</p>
<p>　　全党全国各族人民要更加紧密地团结在党中央周围，高举中国特色社会主义伟大旗帜，不忘初心，牢记使命，将改革开放进行到底，不断实现人民对美好生活的向往，在新时代创造中华民族新的更大奇迹！创造让世界刮目相看的新的更大奇迹！</p>
<h4 id="在纪念中国人民志愿军抗美援朝出国作战70周年大会上的讲话">在纪念中国人民志愿军抗美援朝出国作战70周年大会上的讲话</h4>
<p>同志们，朋友们：</p>
<p>今天，我们在这里隆重集会，纪念中国人民志愿军抗美援朝出国作战70周年。</p>
<p>70年前，由中华优秀儿女组成的中国人民志愿军，肩负着人民的重托、民族的期望，高举保卫和平、反抗侵略的正义旗帜，雄赳赳、气昂昂，跨过鸭绿江，发扬伟大的爱国主义精神和革命英雄主义精神，同朝鲜人民和军队一道，历经两年零9个月艰苦卓绝的浴血奋战，赢得了抗美援朝战争伟大胜利。</p>
<p>伟大的抗美援朝战争，抵御了帝国主义侵略扩张，捍卫了新中国安全，保卫了中国人民和平生活，稳定了朝鲜半岛局势，维护了亚洲和世界和平。</p>
<p>抗美援朝战争伟大胜利，将永远铭刻在中华民族的史册上！永远铭刻在人类和平、发展、进步的史册上！</p>
<p>——70年来，我们始终没有忘记老一辈革命家为维护国际正义、捍卫世界和平、保卫新生共和国所建立的不朽功勋，始终没有忘记党中央和毛泽东同志当年作出中国人民志愿军出国作战重大决策的深远意义。此时此刻，我们要向老一辈革命家，表示最深切的怀念！</p>
<p>——70年来，我们始终没有忘记谱写了气壮山河英雄赞歌的中国人民志愿军将士，以及所有为这场战争胜利作出贡献的人们。我代表党中央、国务院和中央军委，向所有健在的中国人民志愿军老战士、老同志、伤残荣誉军人，向当年支援抗美援朝战争的全国各族人民特别是参战支前人员，向中国人民志愿军烈属、军属，致以最诚挚的问候！</p>
<p>——70年来，我们始终没有忘记在抗美援朝战争中英勇牺牲的烈士们。19万7千多名英雄儿女为了祖国、为了人民、为了和平献出了宝贵生命。烈士们的功绩彪炳千秋，烈士们的英名万古流芳！</p>
<p>在抗美援朝战争中，朝鲜党、政府、人民关心、爱护、支援中国人民志愿军，中朝两国人民和军队休戚与共、生死相依，用鲜血凝结成了伟大战斗友谊。世界上一切爱好和平的国家和人民、友好组织和友好人士，对中国人民志愿军入朝作战给予了有力支援和支持。我代表中国党、政府、军队，向他们表示衷心的感谢！</p>
<p>同志们、朋友们！</p>
<p>中华民族是爱好和平的民族，中国人民是爱好和平的人民。近代以后，中国人民饱受列强侵略之害、饱经战火蹂躏之苦，更是深深懂得战争的残酷、和平的宝贵。新中国成立之初，百废待兴，百业待举，中国人民无比渴望和平安宁。但是，中国人民的这个愿望却受到了粗暴挑战，帝国主义侵略者将战争强加在了中国人民头上。</p>
<p>1950年6月25日，朝鲜内战爆发。美国政府从其全球战略和冷战思维出发，作出武装干涉朝鲜内战的决定，并派遣第七舰队侵入台湾海峡。1950年10月初，美军不顾中国政府一再警告，悍然越过三八线，把战火烧到中朝边境。侵朝美军飞机多次轰炸中国东北边境地区，给人民生命财产造成严重损失，我国安全面临严重威胁。</p>
<p>值此危急关头，应朝鲜党和政府请求，中国党和政府以非凡气魄和胆略作出抗美援朝、保家卫国的历史性决策。1950年10月19日，中国人民志愿军在彭德怀司令员兼政治委员率领下进入朝鲜战场。这是以正义之师行正义之举。</p>
<p>抗美援朝战争，是在交战双方力量极其悬殊条件下进行的一场现代化战争。当时，中美两国国力相差巨大。在这样极不对称、极为艰难的情况下，中国人民志愿军同朝鲜军民密切配合，首战两水洞、激战云山城、会战清川江、鏖战长津湖等，连续进行5次战役，此后又构筑起铜墙铁壁般的纵深防御阵地，实施多次进攻战役，粉碎“绞杀战”、抵御“细菌战”、血战上甘岭，创造了威武雄壮的战争伟业。全国各族人民由衷称赞志愿军将士为“最可爱的人”！经过艰苦卓绝的战斗，中朝军队打败了武装到牙齿的对手，打破了美军不可战胜的神话，迫使不可一世的侵略者于1953年7月27日在停战协定上签字。</p>
<p>在抗美援朝战争期间，党中央统揽全局，实施有力的战争动员和正确的战争指导，采取边打、边稳、边建的方针，开展了波澜壮阔的抗美援朝运动，全国各族人民举国同心支撑起这场事关国家和民族前途命运的伟大抗争，最终用伟大胜利向世界宣告“西方侵略者几百年来只要在东方一个海岸上架起几尊大炮就可霸占一个国家的时代是一去不复返了”！</p>
<p>同志们、朋友们！</p>
<p>抗美援朝战争伟大胜利，是中国人民站起来后屹立于世界东方的宣言书，是中华民族走向伟大复兴的重要里程碑，对中国和世界都有着重大而深远的意义。</p>
<p>经此一战，中国人民粉碎了侵略者陈兵国门、进而将新中国扼杀在摇篮之中的图谋，可谓“打得一拳开，免得百拳来”，帝国主义再也不敢作出武力进犯新中国的尝试，新中国真正站稳了脚跟。这一战，拼来了山河无恙、家国安宁，充分展示了中国人民不畏强暴的钢铁意志！</p>
<p>经此一战，中国人民彻底扫除了近代以来任人宰割、仰人鼻息的百年耻辱，彻底扔掉了“东亚病夫”的帽子，中国人民真正扬眉吐气了。这一战，打出了中国人民的精气神，充分展示了中国人民万众一心的顽强品格！</p>
<p>经此一战，中国人民打败了侵略者，震动了全世界，奠定了新中国在亚洲和国际事务中的重要地位，彰显了新中国的大国地位。这一战，让全世界对中国刮目相看，充分展示了中国人民维护世界和平的坚定决心！</p>
<p>经此一战，人民军队在战争中学习战争，愈战愈勇，越打越强，取得了重要军事经验，实现了由单一军种向诸军兵种合成军队转变，极大促进了国防和军队现代化。这一战，人民军队战斗力威震世界，充分展示了敢打必胜的血性铁骨！</p>
<p>经此一战，第二次世界大战结束后亚洲乃至世界的战略格局得到深刻塑造，全世界被压迫民族和人民争取民族独立和人民解放的正义事业受到极大鼓舞，有力推动了世界和平与人类进步事业。它用铁一般的事实告诉世人，任何一个国家、任何一支军队，不论多么强大，如果站在世界发展潮流的对立面，恃强凌弱、倒行逆施、侵略扩张，必然会碰得头破血流。这一战，再次证明正义必定战胜强权，和平发展是不可阻挡的历史潮流！</p>
<p>同志们、朋友们！</p>
<p>在波澜壮阔的抗美援朝战争中，英雄的中国人民志愿军始终发扬祖国和人民利益高于一切、为了祖国和民族的尊严而奋不顾身的爱国主义精神，英勇顽强、舍生忘死的革命英雄主义精神，不畏艰难困苦、始终保持高昂士气的革命乐观主义精神，为完成祖国和人民赋予的使命、慷慨奉献自己一切的革命忠诚精神，为了人类和平与正义事业而奋斗的国际主义精神，锻造了伟大抗美援朝精神。</p>
<p>伟大抗美援朝精神跨越时空、历久弥新，必须永续传承、世代发扬。</p>
<p>——无论时代如何发展，我们都要砥砺不畏强暴、反抗强权的民族风骨。70年前，帝国主义侵略者将战火烧到了新中国的家门口。中国人民深知，对待侵略者，就得用他们听得懂的语言同他们对话，这就是以战止战、以武止戈，用胜利赢得和平、赢得尊重。中国人民不惹事也不怕事，在任何困难和风险面前，腿肚子不会抖，腰杆子不会弯，中华民族是吓不倒、压不垮的！</p>
<p>——无论时代如何发展，我们都要汇聚万众一心、勠力同心的民族力量。在抗美援朝战争中，中国人民在爱国主义旗帜感召下，同仇敌忾、同心协力，让世界见证了蕴含在中国人民之中的磅礴力量，让世界知道了“现在中国人民已经组织起来了，是惹不得的。如果惹翻了，是不好办的”！</p>
<p>——无论时代如何发展，我们都要锻造舍生忘死、向死而生的民族血性。在朝鲜战场上，志愿军将士面对强大而凶狠的作战对手，身处恶劣而残酷的战场环境，抛头颅、洒热血，以“钢少气多”力克“钢多气少”，谱写了惊天地、泣鬼神的雄壮史诗。志愿军将士冒着枪林弹雨勇敢冲锋，顶着狂轰滥炸坚守阵地，用胸膛堵枪眼，以身躯作人梯，抱起炸药包、手握爆破筒冲入敌群，忍饥受冻绝不退缩，烈火烧身岿然不动，敢于“空中拼刺刀”。在他们中涌现出杨根思、黄继光、邱少云等30多万名英雄功臣和近6000个功臣集体。英雄们说：我们的身后就是祖国，为了祖国人民的和平，我们不能后退一步！这种血性令敌人胆寒，让天地动容！</p>
<p>——无论时代如何发展，我们都要激发守正创新、奋勇向前的民族智慧。勇于创新者进，善于创造者胜。志愿军将士面对陌生的战场、陌生的敌人，坚持“你打你的，我打我的，你打原子弹，我打手榴弹”，把灵活机动战略战术发挥得淋漓尽致。面对来自各方面的风险挑战，面对各种阻力压力，中国人民总能逢山开路、遇水架桥，总能展现大智大勇、锐意开拓进取，“杀出一条血路”！</p>
<p>同志们、朋友们！</p>
<p>抗美援朝战争胜利60多年来，在中国共产党坚强领导下，中国发生了前所未有的历史巨变，中国特色社会主义进入了新时代，中华民族迎来了从站起来、富起来到强起来的伟大飞跃。</p>
<p>今天，我们正站在实现“两个一百年”奋斗目标的历史交汇点上，全面建成小康社会胜利在望，全面建设社会主义现代化国家前景光明。前进道路不会一帆风顺。我们要铭记抗美援朝战争的艰辛历程和伟大胜利，敢于斗争、善于斗争，知难而进、坚韧向前，把新时代中国特色社会主义伟大事业不断推向前进。</p>
<p>——铭记伟大胜利，推进伟大事业，必须坚持中国共产党领导，把党锻造得更加坚强有力。抗美援朝战争伟大胜利再次证明，没有任何一支政治力量能像中国共产党这样，为了民族复兴、人民幸福，不惜流血牺牲，不懈努力奋斗，团结凝聚亿万群众不断走向胜利。只要我们不忘初心、牢记使命，以自我革命精神全面推进党的建设新的伟大工程，不断增强党的政治领导力、思想引领力、群众组织力、社会号召力，就一定能够使党始终成为中国人民最可靠、最坚强的主心骨！</p>
<p>——铭记伟大胜利，推进伟大事业，必须坚持以人民为中心，一切为了人民、一切依靠人民。历史是人民创造的。中国共产党的力量，人民军队的力量，根基在人民。我们要坚持全心全意为人民服务的根本宗旨，为民谋利，为民尽责，为民担当，把人民对美好生活的向往作为始终不渝的奋斗目标，始终保持党同人民群众的血肉联系。只要我们始终坚持人民立场、人民至上，就一定能够激发出无往而不胜的强大力量，就一定能够不断书写中华民族伟大复兴的精彩华章！</p>
<p>——铭记伟大胜利，推进伟大事业，必须坚持推进经济社会发展，不断壮大我国综合国力。落后就要挨打，发展才能自强。新中国成立70多年来，我国用几十年时间走完了发达国家几百年走过的发展历程，创造了举世瞩目的发展奇迹。当前，我国将进入新发展阶段，面对新机遇新挑战，只要我们统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，坚定不移贯彻新发展理念，构建新发展格局，就一定能够实现更高质量、更有效率、更加公平、更可持续、更为安全的发展，不断创造让世界惊叹的更大奇迹！</p>
<p>——铭记伟大胜利，推进伟大事业，必须加快推进国防和军队现代化，把人民军队全面建成世界一流军队。没有一支强大的军队，就不可能有强大的祖国。坚持和发展中国特色社会主义，必须统筹发展和安全、富国和强军。要贯彻新时代党的强军思想，贯彻新时代军事战略方针，毫不动摇坚持党对人民军队的绝对领导，坚持政治建军、改革强军、科技强军、人才强军、依法治军，全面提高捍卫国家主权、安全、发展利益的战略能力，更好履行新时代人民军队使命任务。只要我们与时俱进加强国防和军队建设，向着党在新时代的强军目标阔步前行，就一定能够为实现中华民族伟大复兴提供更为坚强的战略支撑！</p>
<p>——铭记伟大胜利，推进伟大事业，必须维护世界和平和正义，推动构建人类命运共同体。中华民族历来秉持“亲仁善邻”的理念。作为负责任大国，中国坚守和平、发展、公平、正义、民主、自由的全人类共同价值，坚持共商共建共享的全球治理观，坚定不移走和平发展、开放发展、合作发展、共同发展道路。只要坚持走和平发展道路，同各国人民一道推动构建人类命运共同体，就一定能够迎来人类和平与发展的美好未来！</p>
<p>同志们、朋友们！</p>
<p>世界是各国人民的世界，世界面临的困难和挑战需要各国人民同舟共济、携手应对，和平发展、合作共赢才是人间正道。当今世界，任何单边主义、保护主义、极端利己主义，都是根本行不通的！任何讹诈、封锁、极限施压的方式，都是根本行不通的！任何我行我素、唯我独尊的行径，任何搞霸权、霸道、霸凌的行径，都是根本行不通的！不仅根本行不通，最终必然是死路一条！</p>
<p>中国一贯奉行防御性国防政策，中国军队始终是维护世界和平的坚定力量。中国永远不称霸、不扩张，坚决反对霸权主义和强权政治。我们决不会坐视国家主权、安全、发展利益受损，决不会允许任何人任何势力侵犯和分裂祖国的神圣领土。一旦发生这样的严重情况，中国人民必将予以迎头痛击！</p>
<p>同志们、朋友们！</p>
<p>回望70年前伟大的抗美援朝战争，进行具有许多新的历史特点的伟大斗争，瞻望中华民族伟大复兴的光明前景，我们无比坚定、无比自信。让我们更加紧密地团结在党中央周围，弘扬伟大抗美援朝精神，雄赳赳、气昂昂，向着全面建设社会主义现代化国家新征程，向着实现中华民族伟大复兴的中国梦，继续奋勇前进！</p>
]]></content>
  </entry>
</search>
